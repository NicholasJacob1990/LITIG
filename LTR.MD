## üöÄ‚ÄØImplementa√ß√£o LTR‚ÄØ100‚ÄØ%‚ÄØAutomatizada ‚Äî vis√£o ponta‚Äëa‚Äëponta

**Parte‚ÄØ1‚ÄØ/‚ÄØ2‚ÄØ‚Äì‚ÄØDados, Pipeline de Treino e Publica√ß√£o**

> **Objetivo:** colocar um LightGBM‚ÄØ(LambdaMART) em produ√ß√£o, treinado diariamente, servindo em *shadow* para‚ÄØ10‚ÄØ% do tr√°fego, com **fallback** autom√°tico para a soma de pesos.

---

### 1. Instrumenta√ß√£o de Eventos (dia‚ÄØ0)

| Evento            | Quando disparar     | Campos m√≠nimos                                  |
| ----------------- | ------------------- | ----------------------------------------------- |
| `impression`      | API devolve ranking | `case_id`, lista `[lawyer_ids]`, `weights_used` |
| `click_profile`   | Usu√°rio abre perfil | `case_id`, `lawyer_id`, `rank_pos`              |
| `contact_made`    | Cria chat/liga√ß√£o   | idem acima                                      |
| `contract_signed` | Contrato digital    | idem acima                                      |

*Logar em **Kafka topic** `match_events`; fallback direto em Postgres se ainda n√£o tiver Kafka.*

---

### 2. Data‚ÄØLake & ETL (dia‚ÄØ1‚ÄØ‚Üí‚ÄØ‚àû)

1. **Flink** l√™ o t√≥pico, grava Parquet em
   `s3://datalake/ltr/raw/YYYY/MM/DD/*.parquet`.
2. **Airflow‚ÄØDAG** (`etl_ltr_daily`) consolida o dia‚ÄØT‚Äë1:

   * Carrega Parquet, enriquece com KPIs do advogado, diversity, etc.
   * Gera dataset tabular com:

     * coluna `qid`‚ÄØ=‚ÄØ`case_id`
     * coluna `label` (0/0.3/0.6/1)
     * 11‚ÄØfeatures normalizadas
   * Salva em `s3://datalake/ltr/processed/{date}/matrix.parquet`.

---

### 3. Pipeline de Treinamento‚ÄØ(Airflow DAG `train_ltr_daily`)

```mermaid
graph LR
A[Download matrix.parquet] --> B[Split temporal<br>(train/valid/test)]
B --> C[Scaler fit & save<br>(feature_map.json)]
C --> D[Train LightGBM<br>‚Äî¬†LambdaMART]
D --> E[Eval nDCG@5 & MRR]
E --> F{Pass thresholds?}
F -- NO --> G[Fail DAG¬†& alert]
F -- YES --> H[Register in¬†MLflow]
H --> I[Upload model & feature_map<br>to S3 / litgo-models/ltr/{ts}/]
```

**Par√¢metros LightGBM b√°sicos**

```python
params = {
    "objective":      "lambdarank",
    "metric":         "ndcg",
    "ndcg_eval_at":   [5],
    "learning_rate":  0.05,
    "num_leaves":     48,
    "min_data_in_leaf": 20,
    "feature_fraction": 0.9,
    "lambda_l1": 0.2,          # regulariza√ß√£o para poucos dados
    "lambda_l2": 0.2,
    "early_stopping_round": 100,
    "seed": 42
}
```

*Com \~500 linhas o treino leva <‚ÄØ30‚ÄØs em CPU.*

---

### 4. Gate de Qualidade (offline)

| M√©trica            | Alvo                | Implementa√ß√£o                         |
| ------------------ | ------------------- | ------------------------------------- |
| nDCG\@5            | ‚â•‚ÄØbaseline‚ÄØ+‚ÄØ3‚ÄØp.p. | `lgb.cv`¬†ou fun√ß√£o manual             |
| MRR\@5             | ‚Üë‚ÄØvs baseline       | idem                                  |
| Fair‚ÄëGap¬†Œî         | ‚â§‚ÄØ0.05              | comparar `fair_base` por g√™nero/etnia |
| Lat√™ncia¬†p95¬†(inf) | <‚ÄØ15‚ÄØms CPU         | teste local `timeit`                  |

Se **qualquer** m√©trica falhar¬†‚Üí DAG falha ‚Üí modelo **n√£o** √© publicado.

---

### 5. Publica√ß√£o & Versionamento

* Se aprovado, o step `publish_model` faz:

  1. copia `ltr_model.txt` + `feature_map.json` para
     `s3://litgo-models/ltr/{ts}/`
  2. grava registro em **MLflow** (`stage=staging`, tag `ts`).
  3. dispara webhook para o cluster K8s (Helm¬†chart) indicando ‚Äúnovo modelo pronto‚Äù.

---

### 6. Deploy no Servi√ßo `/ltr/score`

| Pasta no container         | Valor                                                         |
| -------------------------- | ------------------------------------------------------------- |
| `/opt/models/ltr_current/` | c√≥pia do √∫ltimo **aprovado** (`model.txt`, `feature_map.pkl`) |

O container reinicia via Rolling‚ÄØUpdate (Argo¬†Rollouts) e carrega o arquivo‚ÄØTXT:

```python
MODEL = lgb.Booster(model_file="/opt/models/ltr_current/model.txt")
FEATURES = pickle.load(open("/opt/models/ltr_current/feature_map.pkl", "rb"))
```

Lat√™ncia t√≠pica: **\~3‚ÄØms** p95 em CPU¬†AVX2.

---

### 7. Integra√ß√£o no `MatchmakingAlgorithm`

```python
async def rank_with_fallback(case, lawyers):
    try:
        feat_matrix = build_feature_matrix(case, lawyers, FEATURES)
        ltr_scores = await call_ltr_service(feat_matrix, timeout=0.2)
        for lw, sc in zip(lawyers, ltr_scores):
            lw.scores["ltr"] = sc
            lw.scores["source"] = "ltr"
        return rerank_fairness(lawyers)
    except Exception as e:
        logger.warning("LTR fail (%s) ‚Äì fallback to weights", e)
        matcher = MatchmakingAlgorithm()
        return await matcher.rank(case, lawyers, preset="balanced")
```

*Timeout curto garante **fail‚Äëfast**; fallback preserva UX.*

## üöÄ‚ÄØImplementa√ß√£o LTR‚ÄØ100‚ÄØ%‚ÄØAutomatizada ‚Äî vis√£o ponta‚Äëa‚Äëponta

**Parte‚ÄØ2‚ÄØ/‚ÄØ2‚ÄØ‚Äì‚ÄØShadow¬†Traffic, Observabilidade, Rollback & Governan√ßa**

---

### 8. Roteamento de Tr√°fego (10‚ÄØ% Shadow)

| Camada                            | Como fazer                                                                                                                                                                     | Observa√ß√£o                                                 |
| --------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ---------------------------------------------------------- |
| **API Gateway** (FastAPI)         | Middleware inspeciona `X‚ÄëShadow‚ÄëLTR=1` no header; se presente, faz **duas** chamadas: <br>‚ë† ranking legacy (retorna ao usu√°rio) <br>‚ë° ranking LTR (ignora resposta, mas loga). | Header injetado a partir de um *flag* redis distribu√≠do.   |
| **Load‚ÄëBalancer** (NGINX‚ÄëIngress) | Regra `map $request_id $shadow`¬†(10‚ÄØ% hash) ‚Üí duplica requisi√ß√£o para `ltr-shadow-svc`.                                                                                        | Serve para linguagens ou times sem controle de middleware. |

*Implementa√ß√£o escolhida depende do stack de rede; o padr√£o mais simples √© **middleware no Gateway**.*

---

### 9. Persist√™ncia de Resultados Shadow

```sql
CREATE TABLE ltr_shadow_log (
    shadow_id      UUID PRIMARY KEY,
    ts_utc         TIMESTAMPTZ,
    case_id        UUID,
    user_id        UUID,
    lawyer_id      TEXT,
    rank_legacy    SMALLINT,
    rank_ltr       SMALLINT,
    label          REAL      -- 0/0.3/0.6/1 (preenchido dias depois via ETL)
);
```

*Os ETLs di√°rios atualizam `label` quando eventos de click/contrato forem gerados.*

---

### 10. M√©tricas de Compara√ß√£o

| M√©trica online           | C√°lculo                                                             | Painel Grafana            |
| ------------------------ | ------------------------------------------------------------------- | ------------------------- |
| **Hit\@3 Shadow**        | %¬†de casos em que advogado contratado teria ficado no Top‚ÄØ3 do LTR. | Linha di√°ria vs baseline. |
| **MRR Gap**              | `MRR_ltr ‚Äì MRR_legacy` (em shadow).                                 | Verde se >‚ÄØ0.             |
| **Lat√™ncia p95 LTR svc** | Prometheus histogram.                                               | Alerta >‚ÄØ20‚ÄØms.           |
| **Fallback rate**        | `ltr_fallback_total / requests`                                     | Alerta >‚ÄØ2‚ÄØ%.             |

*Scripts PySpark geram **relat√≥rios semanais** (`shadow_eval_{iso_week}.csv`) colocados no Data‚ÄØLake.*

---

### 11. Crit√©rios de Promo√ß√£o

1. **Dura√ß√£o m√≠nima:** ‚â•‚ÄØ14‚ÄØdias **ou** ‚â•‚ÄØ3‚ÄØ000 casos.
2. **Hit\@3 Shadow:** melhoria ‚â•‚ÄØ5‚ÄØp.p. sobre legacy.
3. **MRR Gap:** >‚ÄØ0 com 95‚ÄØ%‚ÄØCI.
4. **Fair‚ÄëGap‚ÄØŒî:** n√£o piora (>‚ÄØ0.02) vs legacy.
5. **Lat√™ncia p95:** <‚ÄØ15‚ÄØms CPU.

> Se **todos** ok ‚Üí *Argo Rollouts*‚ÄØpromove tr√°fego LTR para 100‚ÄØ% atrav√©s de `set-weight 100`.
> Caso contr√°rio, permanece em shadow e o ciclo de re‚Äëtreino continua.

---

### 12. Rollback Autom√°tico

```yaml
spec:
  analysis:
    rollback:
      steps:
        - analysisTemplate: latency-check
          threshold: 25ms
        - analysisTemplate: hitrate-check
          threshold: -1pp   # caiu 1 ponto ou mais
```

*Qualquer viola√ß√£o de SLA aciona **automatic rollback** ‚Üí peso volta a‚ÄØ0‚ÄØ%.*

---

### 13. Monitoramento & Alertas

| Ferramenta     | Painel / Alerta                                                         |
| -------------- | ----------------------------------------------------------------------- |
| **Grafana**    | ‚ÄúLTR‚ÄØShadow Performance‚Äù ‚Äì 4 m√©tricas chave.                            |
| **Prometheus** | Alertmanager envia Slack: `LTR_FALLBACK_RATE_HIGH`, `LTR_LATENCY_HIGH`. |
| **Sentry**     | Captura exce√ß√µes no endpoint `/ltr/score`.                              |

---

### 14. Seguran√ßa & Conformidade

* **LGPD opt‚Äëout**: se usu√°rio solicitar exclus√£o ‚Üí `DELETE FROM match_events WHERE user_id = ‚Ä¶`.
* **Pseudonimiza√ß√£o**: hash(user\_id, salt) antes de gravar em tabelas shadow.
* **Model¬†Card**: PDF gerado via script, armazenado na Wiki interna, descreve dados, m√©tricas, limita√ß√µes.

---

### 15. Linha do Tempo (‚ÄúCritical¬†Path‚Äù)

| Semana | Tarefas                                                    |
| ------ | ---------------------------------------------------------- |
| 1      | Instrumentar eventos + topic Kafka                         |
| 2      | ETL Parquet, tabela `match_events`                         |
| 3      | Implementar pipeline `train_ltr_daily`, thresholds offline |
| 4      | Deploy servi√ßo `/ltr/score` com fallback                   |
| 5      | Ativar 10‚ÄØ% shadow via header ou Ingress                   |
| 6‚Äë7    | Coleta de m√©tricas, dashboards, alertas                    |
| 8      | Go/No‚ÄëGo ‚Äì promo√ß√£o a 100‚ÄØ% se crit√©rios cumpridos         |

---

### 16. Checklist de‚ÄØGo‚ÄëLive

* [x] Fallback testado (desligar servi√ßo LTR ‚Üí ranking legacy ok)
* [x] Dashboards preenchendo em tempo real
* [x] Alertmanager dispara Slack em fallback‚ÄØ>‚ÄØ2‚ÄØ%
* [x] Script de rollback manual documentado
* [x] Model¬†Card publicado
* [x] DPIA LGPD atualizado

---

### üì¶ Exemplos de implementa√ß√£o (Parte‚ÄØ3‚ÄØ/‚ÄØ3)

> A seguir, blocos completos prontos para copiar‚Äëcolar: DAG do Airflow, servi√ßo FastAPI, Helm¬†Chart simplificado, regra Prometheus e consulta SQL Hit\@3.

---

## 17. DAG completo¬†(`dags/train_ltr_daily.py`)

```python
"""
Airflow DAG: Treinamento di√°rio do LightGBM¬†LambdaMART
Agendado para 02:15‚ÄØUTC (23:15 BRT).
"""
from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.utils.task_group import TaskGroup
from datetime import datetime, timedelta
from src import etl, preprocess, train, evaluate, registry

default_args = {
    "owner": "mlops",
    "depends_on_past": False,
    "email": ["ml-alerts@litgo.com"],
    "email_on_failure": True,
    "retries": 1,
    "retry_delay": timedelta(minutes=15),
}

with DAG(
    dag_id="train_ltr_daily",
    description="LightGBM LambdaMART ‚Äì re‚Äëtreino autom√°tico",
    start_date=datetime(2025, 7, 1),
    schedule_interval="15 2 * * *",
    catchup=False,
    tags=["ltr", "retrain"],
    default_args=default_args,
) as dag:

    with TaskGroup("etl") as tg_etl:
        extract = PythonOperator(
            task_id="extract",
            python_callable=etl.extract_raw_parquet,
        )
        enrich = PythonOperator(
            task_id="enrich",
            python_callable=etl.enrich_kpi_features,
        )
        extract >> enrich

    preprocess_task = PythonOperator(
        task_id="preprocess",
        python_callable=preprocess.build_matrix,
    )

    train_task = PythonOperator(
        task_id="train",
        python_callable=train.train_lgbm,
    )

    eval_task = PythonOperator(
        task_id="evaluate",
        python_callable=evaluate.eval_lgbm,
    )

    publish_task = PythonOperator(
        task_id="publish",
        python_callable=registry.publish_model,
        trigger_rule="all_success",
    )

    tg_etl >> preprocess_task >> train_task >> eval_task >> publish_task
```

---

## 18. Servi√ßo `/ltr/score` ‚Äì FastAPI minimal

```python
# app_ltr/main.py
from fastapi import FastAPI, HTTPException
import lightgbm as lgb
import numpy as np, pickle, json, os

MODEL_PATH = os.getenv("MODEL_PATH", "/opt/models/ltr_current/model.txt")
MAP_PATH   = os.getenv("FEATURE_MAP", "/opt/models/ltr_current/feature_map.pkl")

app = FastAPI(title="LitGo LTR Scoring Service")

MODEL = lgb.Booster(model_file=MODEL_PATH)
FEATURE_ORDER = pickle.load(open(MAP_PATH, "rb"))

@app.post("/ltr/score")
async def ltr_score(payload: dict):
    try:
        x = np.array([[payload["features"][f] for f in FEATURE_ORDER]])
        score = MODEL.predict(x, num_iteration=MODEL.best_iteration)[0]
        return {"score": float(score)}
    except KeyError as e:
        raise HTTPException(status_code=422, detail=f"missing feature {e}")
```

*Conteinerize em `Dockerfile` simples (python:3.11‚Äëslim) +¬†`uvicorn app_ltr.main:app --host 0.0.0.0 --port 8080`.*

---

## 19. Helm Chart‚ÄØ(resumo)

```yaml
# charts/ltr/values.yaml
image:
  repository: registry.gitlab.com/litgo/ltr-service
  tag: "v0.3.2"
replicaCount: 3

resources:
  limits:
    cpu: "500m"
    memory: "512Mi"

env:
  MODEL_PATH: /models/model.txt
  FEATURE_MAP: /models/feature_map.pkl

shadow:
  weight: 10    # 10‚ÄØ% tr√°fego duplicado

# charts/ltr/templates/deployment.yaml (excerto)
...
        volumeMounts:
          - name: model-volume
            mountPath: /models
      volumes:
        - name: model-volume
          persistentVolumeClaim:
            claimName: ltr-model-pvc
```

*Argo¬†Rollouts manipula `shadow.weight` alterando route no Ingress.*

---

## 20. Regra Prometheus ‚Äì Lat√™ncia & Fallback

```yaml
# prometheus/alert-rules-ltr.yml
groups:
- name: ltr-service
  rules:
  - alert: LTRServiceHighLatency
    expr: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{job="ltr-service"}[5m])) by (le))
          > 0.020   # 20‚ÄØms
    for: 10m
    labels:
      severity: warning
    annotations:
      summary: "Lat√™ncia p95 do LTR >¬†20‚ÄØms"
      runbook: https://wiki.litgo.com/latency-incident

  - alert: LTRFallbackRateHigh
    expr: rate(ltr_fallback_total[10m]) / rate(api_requests_total[10m]) > 0.02
    for: 15m
    labels:
      severity: critical
    annotations:
      summary: "Fallback para algoritmo legado >‚ÄØ2‚ÄØ%"
      runbook: https://wiki.litgo.com/fallback-incident
```

---

## 21. Consulta SQL ‚Äì Hit\@3 Shadow vs Legacy

```sql
WITH success AS (
  SELECT case_id,
         lawyer_id,
         MAX(label) AS outcome      -- 1.0 se contratado
  FROM   ltr_shadow_log
  WHERE  label = 1.0
  GROUP BY case_id, lawyer_id
),
positions AS (
  SELECT s.case_id,
         s.lawyer_id,
         MIN(s.rank_legacy) FILTER (WHERE s.rank_legacy IS NOT NULL) AS pos_legacy,
         MIN(s.rank_ltr)    FILTER (WHERE s.rank_ltr    IS NOT NULL) AS pos_ltr
  FROM   ltr_shadow_log s
  JOIN   success        u USING (case_id, lawyer_id)
  GROUP BY s.case_id, s.lawyer_id
)
SELECT
  COUNT(*) FILTER (WHERE pos_legacy <= 3) * 1.0 / COUNT(*) AS hit3_legacy,
  COUNT(*) FILTER (WHERE pos_ltr    <= 3) * 1.0 / COUNT(*) AS hit3_ltr
FROM positions;
```

---
### Sim, voc√™ consegue montar **todo o fluxo autom√°tico** dentro do‚ÄØCursor‚ÄØIDE ‚Äî mas √© importante lembrar que a‚ÄØIDE em si apenas orquestra o c√≥digo e os cont√™ineres; quem executa a automa√ß√£o cont√≠nua √© a stack Docker/Airflow/K8s que voc√™ vai subir a partir do projeto. Abaixo segue um roteiro pragm√°tico:

---

## 1‚ÄØ‚ñ™Ô∏é Preparar o ambiente de desenvolvimento no Cursor

1. **Clone o reposit√≥rio**‚ÄØ`ltr_pipeline/` na workspace do Cursor.
2. Crie um **`.devcontainer/`** ou **`docker-compose.yml`** na raiz com:

   * **airflow-scheduler**, **airflow-webserver**, **postgres**
   * **kafka + zookeeper** (ou Redpanda para dev)
   * **minio** (mock S3)
   * **ltr-service** (FastAPI)
3. No Cursor, abra o painel ‚ÄúContainers‚Äù ‚Üí `Compose Up`.

   * Isso j√° levanta Airflow na porta‚ÄØ8080 e o servi√ßo LTR na‚ÄØ8081.

> **Dica:** o Cursor monta seus volumes locais dentro dos cont√™ineres, ent√£o qualquer altera√ß√£o de c√≥digo √© ‚Äúhot‚Äëreload‚Äù.

---

## 2‚ÄØ‚ñ™Ô∏é Criar os alvos de automa√ß√£o

### `Makefile` minimal

```make
setup:  ## Instala depend√™ncias Python
	pip install -r requirements.txt

etl:    ## Roda ETL local usando os Parquets mockados
	python -m src.etl

train:  ## Treina LightGBM com warm‚Äëstart
	python -m src.train

evaluate:
	python -m src.evaluate

publish:
	python -m src.registry
```

No Cursor, pressione **‚åò‚áßP ‚Üí ‚ÄúRun Make Target‚Ä¶‚Äù** e escolha `train` para ver se tudo roda sem sair da IDE.

---

## 3‚ÄØ‚ñ™Ô∏é Subir o Airflow local

1. No painel de Terminais do Cursor, rode:

   ```bash
   docker compose up -d airflow-init
   docker compose up airflow-scheduler airflow-webserver
   ```

2. Abra `http://localhost:8080` ‚Üí ative a DAG `train_ltr_daily`.

> Quando salvar o arquivo `dags/train_ltr_daily.py`, o Cursor detecta e recarrega o cont√™iner Airflow automaticamente.

---

## 4‚ÄØ‚ñ™Ô∏é Testar o servi√ßo `/ltr/score`

* Dentro do Cursor: `curl -X POST localhost:8081/ltr/score -d @sample.json`
* Ajuste os **paths** de modelo apontando para `./models/dev/`.

Quando voc√™ altera o modelo e roda `publish`, o script copia o novo artefato para a pasta bind‚Äëmountada `/models`; o FastAPI faz **watch** via `watchgod` e recarrega.

---

## 5‚ÄØ‚ñ™Ô∏é Shadow‚ÄØTraffic local‚ÄØ(simulado)

```python
# tests/test_shadow.py
from src.shadow import simulate_shadow
simulate_shadow(n_cases=50)
```

Rode pelo painel de testes do Cursor ‚Üí veja o log JSON em tempo real no console embutido.

---

## 6‚ÄØ‚ñ™Ô∏é Commit, CI e Deploy

* Configure **GitHub¬†Actions** ou **GitLab¬†CI** para:

  1. `docker build` da imagem `ltr-service`.
  2. Push para o registry.
  3. Deploy via **Argo¬†Rollouts** manifest armazenado em `deploy/`.

O Cursor j√° mostra os pipelines Git em uma aba lateral, permitindo acompanhar o deploy sem sair da IDE.

---

## 7‚ÄØ‚ñ™Ô∏é Agendar em produ√ß√£o

* Crie um arquivo Helm `values-prod.yaml` com `shadow.weight: 10`.
* No Cursor, abra o terminal remoto do cluster (`kubectl`) e rode:

  ```bash
  helm upgrade --install ltr charts/ltr -f deploy/values-prod.yaml
  ```

O Cursor exibe os logs dos pods em tempo real, ent√£o voc√™ consegue verificar fallback ou lat√™ncia sem sair do editor.

---

### Checklist r√°pido

* [x] Cont√™ineres sobem via **Compose** no Cursor
* [x] DAG √© detectada e executa no Airflow local
* [x] Scripts `etl ‚Üí train ‚Üí evaluate ‚Üí publish` rodam via Make
* [x] Servi√ßo LTR responde em `/ltr/score`
* [x] Fallback testado manualmente (parar cont√™iner LTR ‚Üí ranking legacy)

Se todos os itens acima passarem no ambiente local da IDE, basta ‚Äúpromover‚Äù a mesma stack para o cluster de staging/produ√ß√£o.

---

**Conclus√£o:** o Cursor n√£o substitui Airflow nem Kubernetes, mas facilita **codar, versionar e observar** todo o pipeline sem trocar de ferramenta. Uma vez que Docker‚ÄØ+‚ÄØAirflow estejam configurados, o treinamento e o shadow j√° acontecem de forma **100‚ÄØ% autom√°tica** ‚Äî seu papel passa a ser apenas revisar dashboards e *mergear* pull‚Äërequests.




