# Sprints para Melhorias da Triagem Inteligente

## Vis√£o Geral dos Sprints

### Sprint 1: Persist√™ncia e Resili√™ncia (2 semanas)
**Foco**: Redis para persist√™ncia de conversas e recupera√ß√£o de estado

### Sprint 2: Performance e Experi√™ncia do Usu√°rio (2 semanas)  
**Foco**: Streaming de respostas e processamento em background

### Sprint 3: Observabilidade e Valida√ß√£o (2 semanas)
**Foco**: Monitoramento de custos e A/B testing

---

## üöÄ **SPRINT 1: PERSIST√äNCIA E RESILI√äNCIA**
**Dura√ß√£o**: 2 semanas  
**Objetivo**: Garantir que conversas n√£o sejam perdidas e permitir escalabilidade horizontal

### **√âpico 1.1: Configura√ß√£o do Redis**
**Estimativa**: 2 dias

#### **Tarefas**:
1. **Configurar Redis no Docker Compose**
   - Adicionar servi√ßo Redis ao `docker-compose.yml`
   - Configurar volumes para persist√™ncia
   - Definir configura√ß√µes de mem√≥ria e TTL

2. **Instalar Depend√™ncias**
   - Adicionar `aioredis` ao `requirements.txt`
   - Configurar vari√°veis de ambiente para Redis

3. **Criar Servi√ßo Base Redis**
   - Implementar `backend/services/redis_service.py`
   - Configurar conex√£o com retry e health check
   - Implementar m√©todos base (get, set, delete, exists)

#### **Entreg√°veis**:
- [ ] Redis rodando no Docker
- [ ] Conex√£o Redis configurada
- [ ] Servi√ßo base Redis implementado

### **√âpico 1.2: Migra√ß√£o de Conversas para Redis**
**Estimativa**: 5 dias

#### **Tarefas**:
1. **Criar ConversationStateManager**
   ```python
   # backend/services/conversation_state_manager.py
   class ConversationStateManager:
       async def save_conversation_state(case_id, state)
       async def get_conversation_state(case_id)
       async def delete_conversation_state(case_id)
       async def list_active_conversations()
   ```

2. **Migrar IntelligentInterviewerService**
   - Substituir `self.active_conversations` por Redis
   - Implementar serializa√ß√£o/deserializa√ß√£o de estado
   - Adicionar TTL para limpeza autom√°tica

3. **Migrar IntelligentTriageOrchestrator**
   - Substituir `self.active_orchestrations` por Redis
   - Implementar recupera√ß√£o de estado ap√≥s restart
   - Adicionar logs de recupera√ß√£o

4. **Implementar Migra√ß√£o de Dados**
   - Script para migrar conversas ativas para Redis
   - Estrat√©gia de rollback se necess√°rio

#### **Entreg√°veis**:
- [ ] ConversationStateManager implementado
- [ ] Servi√ßos migrados para Redis
- [ ] Scripts de migra√ß√£o criados
- [ ] Testes de persist√™ncia funcionando

### **√âpico 1.3: Testes e Valida√ß√£o**
**Estimativa**: 3 dias

#### **Tarefas**:
1. **Testes de Persist√™ncia**
   - Teste de restart do servidor
   - Teste de recupera√ß√£o de conversas
   - Teste de TTL e limpeza autom√°tica

2. **Testes de Escalabilidade**
   - Teste com m√∫ltiplas inst√¢ncias
   - Valida√ß√£o de sincroniza√ß√£o entre inst√¢ncias
   - Teste de load balancing

3. **Documenta√ß√£o**
   - Atualizar documenta√ß√£o de deploy
   - Criar guia de troubleshooting Redis
   - Documentar estrat√©gias de backup

#### **Entreg√°veis**:
- [ ] Suite de testes completa
- [ ] Valida√ß√£o de m√∫ltiplas inst√¢ncias
- [ ] Documenta√ß√£o atualizada

---

## ‚ö° **SPRINT 2: PERFORMANCE E EXPERI√äNCIA DO USU√ÅRIO**
**Dura√ß√£o**: 2 semanas  
**Objetivo**: Implementar streaming de respostas e processamento em background

### **√âpico 2.1: Streaming de Respostas**
**Estimativa**: 4 dias

#### **Tarefas**:
1. **Backend - Streaming API**
   ```python
   # backend/routes/intelligent_triage_routes.py
   @router.post("/continue-stream")
   async def continue_conversation_stream(request, payload):
       # Implementar StreamingResponse
   ```

2. **Modificar Servi√ßos de IA**
   - Adicionar suporte a streaming no OpenAI
   - Implementar streaming no Anthropic
   - Criar wrapper unificado para streaming

3. **Frontend - Processamento de Stream**
   ```typescript
   // lib/services/intelligentTriage.ts
   async function* continueConversationStream(caseId, message) {
       // Implementar processamento de stream
   }
   ```

4. **UI - Atualiza√ß√£o em Tempo Real**
   - Componente de typing indicator melhorado
   - Atualiza√ß√£o palavra por palavra
   - Fallback para modo n√£o-stream

#### **Entreg√°veis**:
- [ ] API de streaming implementada
- [ ] Servi√ßos de IA com streaming
- [ ] Frontend processando stream
- [ ] UI atualizada em tempo real

### **√âpico 2.2: Processamento em Background**
**Estimativa**: 5 dias

#### **Tarefas**:
1. **Configurar Celery para Triagem**
   - Adicionar worker espec√≠fico para triagem
   - Configurar queues separadas por complexidade
   - Implementar retry policies

2. **Criar Tarefas Celery**
   ```python
   # backend/jobs/intelligent_triage_tasks.py
   @celery.task(bind=True)
   def process_completed_conversation_task(self, case_id):
       # Implementar processamento ass√≠ncrono
   ```

3. **Modificar Endpoints**
   - `/continue` retorna imediatamente para casos complexos
   - Adicionar endpoint `/status` melhorado
   - Implementar webhook para notifica√ß√£o de conclus√£o

4. **Frontend - Polling Inteligente**
   - Implementar polling adaptativo
   - UI de "processando an√°lise"
   - Notifica√ß√µes push quando pronto

#### **Entreg√°veis**:
- [ ] Celery configurado para triagem
- [ ] Tarefas ass√≠ncronas implementadas
- [ ] Endpoints modificados
- [ ] Frontend com polling inteligente

### **√âpico 2.3: Otimiza√ß√£o de Performance**
**Estimativa**: 1 dia

#### **Tarefas**:
1. **Cache de Resultados**
   - Cache Redis para an√°lises similares
   - Hash de contexto para identificar duplicatas
   - TTL configur√°vel por tipo de an√°lise

2. **Otimiza√ß√£o de Queries**
   - Implementar connection pooling
   - Otimizar queries do banco
   - Adicionar √≠ndices necess√°rios

#### **Entreg√°veis**:
- [ ] Sistema de cache implementado
- [ ] Queries otimizadas
- [ ] Performance melhorada

---

## üìä **SPRINT 3: OBSERVABILIDADE E VALIDA√á√ÉO**
**Dura√ß√£o**: 2 semanas  
**Objetivo**: Monitorar custos, lat√™ncia e validar melhorias via A/B testing

### **√âpico 3.1: Monitoramento de Custos e Lat√™ncia**
**Estimativa**: 4 dias

#### **Tarefas**:
1. **Instrumenta√ß√£o de APIs de IA**
   ```python
   # backend/services/ai_monitoring_service.py
   class AIMonitoringService:
       async def track_openai_call(self, model, tokens, cost, latency)
       async def track_anthropic_call(self, model, tokens, cost, latency)
       async def get_daily_costs(self)
   ```

2. **M√©tricas Prometheus**
   - Contador de chamadas por modelo
   - Histograma de lat√™ncia
   - Gauge de custo por dia/hora
   - M√©tricas de taxa de sucesso

3. **Dashboards Grafana**
   - Dashboard de custos de IA
   - Dashboard de performance
   - Alertas para custos elevados
   - Alertas para lat√™ncia alta

4. **Relat√≥rios Automatizados**
   - Relat√≥rio di√°rio de custos
   - Relat√≥rio semanal de performance
   - Notifica√ß√µes Slack para alertas

#### **Entreg√°veis**:
- [ ] Servi√ßo de monitoramento implementado
- [ ] M√©tricas Prometheus configuradas
- [ ] Dashboards Grafana criados
- [ ] Relat√≥rios automatizados

### **√âpico 3.2: A/B Testing da Nova Arquitetura**
**Estimativa**: 5 dias

#### **Tarefas**:
1. **Configurar Experimento A/B**
   ```python
   # backend/services/ab_testing_service.py
   experiment_config = {
       "name": "intelligent_triage_v2",
       "variants": {
           "control": {"weight": 50, "version": "v1"},
           "treatment": {"weight": 50, "version": "v2"}
       }
   }
   ```

2. **Modificar Frontend**
   - Integrar com servi√ßo A/B testing
   - Roteamento baseado em variante
   - Tracking de eventos por variante

3. **M√©tricas de Compara√ß√£o**
   - Taxa de conclus√£o de triagem
   - Tempo m√©dio de triagem
   - Satisfa√ß√£o do usu√°rio (NPS)
   - Precis√£o da classifica√ß√£o

4. **An√°lise Estat√≠stica**
   - Implementar testes de signific√¢ncia
   - Dashboard de resultados A/B
   - Relat√≥rios de conclus√£o

#### **Entreg√°veis**:
- [ ] Experimento A/B configurado
- [ ] Frontend com roteamento A/B
- [ ] M√©tricas de compara√ß√£o
- [ ] An√°lise estat√≠stica implementada

### **√âpico 3.3: Documenta√ß√£o e Treinamento**
**Estimativa**: 1 dia

#### **Tarefas**:
1. **Documenta√ß√£o T√©cnica**
   - Arquitetura atualizada
   - Guias de troubleshooting
   - Runbooks para produ√ß√£o

2. **Treinamento da Equipe**
   - Workshop sobre nova arquitetura
   - Guia de monitoramento
   - Procedimentos de incident response

#### **Entreg√°veis**:
- [ ] Documenta√ß√£o completa
- [ ] Equipe treinada
- [ ] Procedimentos documentados

---

## üìã **CRIT√âRIOS DE ACEITA√á√ÉO GERAIS**

### **Sprint 1 - Persist√™ncia**
- [ ] Conversas persistem ap√≥s restart do servidor
- [ ] M√∫ltiplas inst√¢ncias funcionam corretamente
- [ ] TTL limpa conversas antigas automaticamente
- [ ] Tempo de recupera√ß√£o < 2 segundos

### **Sprint 2 - Performance**
- [ ] Streaming funciona em 95% dos casos
- [ ] Tempo de primeira resposta < 500ms
- [ ] An√°lises complexas processam em background
- [ ] UI atualiza em tempo real

### **Sprint 3 - Observabilidade**
- [ ] Custos de IA s√£o monitorados em tempo real
- [ ] Alertas funcionam corretamente
- [ ] A/B testing mostra resultados significativos
- [ ] Dashboards est√£o atualizados

---

## üîß **CONFIGURA√á√ÉO DE DESENVOLVIMENTO**

### **Prepara√ß√£o dos Sprints**

```bash
# Sprint 1 - Setup Redis
docker-compose up -d redis
pip install aioredis

# Sprint 2 - Setup Celery
celery -A backend.celery worker --loglevel=info

# Sprint 3 - Setup Monitoring
docker-compose up -d prometheus grafana
```

### **Estrutura de Testes**

```python
# tests/test_sprint_1_redis.py
# tests/test_sprint_2_streaming.py
# tests/test_sprint_3_monitoring.py
```

---

## üìà **M√âTRICAS DE SUCESSO**

### **Objetivos Quantitativos**
- **Disponibilidade**: 99.9% uptime
- **Performance**: Tempo de resposta < 2s (P95)
- **Custo**: Redu√ß√£o de 20% no custo por triagem
- **Satisfa√ß√£o**: NPS > 8.0

### **Objetivos Qualitativos**
- Experi√™ncia do usu√°rio mais fluida
- Maior confiabilidade do sistema
- Melhor observabilidade operacional
- Valida√ß√£o cient√≠fica das melhorias

---

## üöÄ **PR√ìXIMOS PASSOS**

1. **Prioriza√ß√£o**: Definir ordem dos sprints baseado em necessidades do neg√≥cio
2. **Recursos**: Alocar desenvolvedores para cada √©pico
3. **Ambiente**: Preparar ambientes de desenvolvimento e staging
4. **Monitoramento**: Configurar m√©tricas baseline antes das mudan√ßas

**Recomenda√ß√£o**: Come√ßar com Sprint 1 (Persist√™ncia) por ser fundamental para estabilidade, seguir com Sprint 2 (Performance) para melhorar UX, e finalizar com Sprint 3 (Observabilidade) para validar os resultados. 