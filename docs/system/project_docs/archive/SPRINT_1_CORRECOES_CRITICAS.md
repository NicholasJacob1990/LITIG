# üöÄ SPRINT 1: CORRE√á√ïES CR√çTICAS - PLANO DETALHADO

> **Dura√ß√£o:** 2 semanas (10 dias √∫teis)  
> **Objetivo:** Fazer o sistema funcionar ponta-a-ponta  
> **Prioridade:** P0 - Cr√≠tico para produ√ß√£o  

## üìã VIS√ÉO GERAL

Este sprint foca nas **corre√ß√µes cr√≠ticas** que impedem o sistema de funcionar completamente. Ap√≥s este sprint, o pipeline completo deve funcionar do in√≠cio ao fim: Triagem ‚Üí Matching ‚Üí Ofertas ‚Üí Contratos.

## üéØ OBJETIVOS DO SPRINT

### Principais Entregas
1. **Sistema Funcionando Ponta-a-Ponta**: Pipeline completo operacional
2. **Notifica√ß√µes Funcionando**: Advogados recebem ofertas via push/email
3. **Jobs Automatizados**: Execu√ß√£o autom√°tica de tarefas cr√≠ticas
4. **Testes Atualizados**: Cobertura de testes sincronizada com c√≥digo

### M√©tricas de Sucesso
- [ ] Pipeline completo funciona sem erro
- [ ] Notifica√ß√µes chegam aos advogados
- [ ] Jobs rodam automaticamente
- [ ] Testes principais passando (>80%)

## üìä √âPICOS E USER STORIES

### üîß EPIC 1.1: Corre√ß√£o Schema-C√≥digo
**Problema:** C√≥digo usa campos que n√£o existem na tabela `lawyers`

#### US-1.1.1: Criar migra√ß√£o para adicionar campos faltantes
**Como** desenvolvedor  
**Quero** adicionar os campos necess√°rios na tabela lawyers  
**Para que** o algoritmo de matching funcione corretamente  

**Crit√©rios de Aceita√ß√£o:**
- [ ] Campo `tags_expertise` adicionado como array de strings
- [ ] Campo `cases_30d` adicionado como integer com default 0
- [ ] Campo `capacidade_mensal` adicionado como integer com default 10
- [ ] Campo `geo_latlon` adicionado como point para queries geogr√°ficas
- [ ] √çndices criados para performance
- [ ] Migra√ß√£o testada em ambiente de desenvolvimento

**Implementa√ß√£o:**
```sql
-- supabase/migrations/20250125000000_add_matching_fields.sql
ALTER TABLE public.lawyers 
ADD COLUMN IF NOT EXISTS tags_expertise TEXT[] DEFAULT '{}',
ADD COLUMN IF NOT EXISTS cases_30d INTEGER DEFAULT 0,
ADD COLUMN IF NOT EXISTS capacidade_mensal INTEGER DEFAULT 10,
ADD COLUMN IF NOT EXISTS geo_latlon POINT;

-- Criar √≠ndices
CREATE INDEX IF NOT EXISTS idx_lawyers_tags_expertise ON public.lawyers USING GIN(tags_expertise);
CREATE INDEX IF NOT EXISTS idx_lawyers_geo_latlon ON public.lawyers USING GIST(geo_latlon);
CREATE INDEX IF NOT EXISTS idx_lawyers_cases_30d ON public.lawyers(cases_30d);
```

**Estimativa:** 1 dia

#### US-1.1.2: Implementar mapeamento de campos existentes
**Como** desenvolvedor  
**Quero** migrar dados existentes para os novos campos  
**Para que** n√£o haja perda de dados hist√≥ricos  

**Crit√©rios de Aceita√ß√£o:**
- [ ] Dados de `specialties` migrados para `tags_expertise`
- [ ] Coordenadas `lat`/`lng` convertidas para `geo_latlon`
- [ ] Fun√ß√£o de mapeamento criada e testada
- [ ] Dados validados ap√≥s migra√ß√£o

**Implementa√ß√£o:**
```sql
-- Migrar dados existentes
UPDATE public.lawyers 
SET tags_expertise = CASE 
    WHEN specialties IS NOT NULL THEN string_to_array(specialties, ',')
    ELSE '{}'
END;

UPDATE public.lawyers 
SET geo_latlon = CASE 
    WHEN lat IS NOT NULL AND lng IS NOT NULL THEN point(lng, lat)
    ELSE NULL
END;
```

**Estimativa:** 1 dia

#### US-1.1.3: Testar integra√ß√£o ponta-a-ponta
**Como** desenvolvedor  
**Quero** validar que o algoritmo funciona com os novos campos  
**Para que** o matching seja executado corretamente  

**Crit√©rios de Aceita√ß√£o:**
- [ ] Teste de matching completo executado
- [ ] Filtros geogr√°ficos funcionando
- [ ] Features calculadas corretamente
- [ ] Scores gerados sem erro

**Implementa√ß√£o:**
```python
# tests/test_integration_matching.py
@pytest.mark.asyncio
async def test_full_matching_pipeline():
    # Criar caso de teste
    case_data = {
        "area": "Trabalhista",
        "embedding": [0.1, 0.2, ...],
        "urgency": "high"
    }
    
    # Executar matching
    matches = await MatchService.find_matches(case_data)
    
    # Validar resultados
    assert len(matches) > 0
    assert all(m['fair_score'] > 0 for m in matches)
```

**Estimativa:** 1 dia

---

### üì± EPIC 1.2: Implementa√ß√£o de Notifica√ß√µes
**Problema:** Fun√ß√µes de notifica√ß√£o n√£o est√£o implementadas

#### US-1.2.1: Implementar send_push_notification
**Como** sistema  
**Quero** enviar notifica√ß√µes push via OneSignal  
**Para que** advogados sejam notificados sobre novas ofertas  

**Crit√©rios de Aceita√ß√£o:**
- [ ] Fun√ß√£o `send_push_notification` implementada
- [ ] Integra√ß√£o OneSignal funcionando
- [ ] Tratamento de erros implementado
- [ ] Retry com backoff exponencial
- [ ] Testes unit√°rios passando

**Implementa√ß√£o:**
```python
# backend/services/notify_service.py
async def send_push_notification(user_id: str, title: str, message: str, data: dict = None):
    """Envia notifica√ß√£o push via OneSignal"""
    try:
        onesignal_client = OneSignalClient(
            app_id=ONESIGNAL_APP_ID,
            rest_api_key=ONESIGNAL_REST_API_KEY
        )
        
        notification = {
            "include_external_user_ids": [user_id],
            "headings": {"en": title},
            "contents": {"en": message},
            "data": data or {}
        }
        
        response = await onesignal_client.send_notification(notification)
        logger.info(f"Push notification sent to {user_id}: {response}")
        return True
        
    except Exception as e:
        logger.error(f"Failed to send push notification: {e}")
        return False
```

**Estimativa:** 1.5 dias

#### US-1.2.2: Implementar send_email_notification
**Como** sistema  
**Quero** enviar notifica√ß√µes por email via SendGrid  
**Para que** haja fallback quando push notification falha  

**Crit√©rios de Aceita√ß√£o:**
- [ ] Fun√ß√£o `send_email_notification` implementada
- [ ] Integra√ß√£o SendGrid funcionando
- [ ] Template de email criado
- [ ] Tratamento de erros implementado
- [ ] Testes unit√°rios passando

**Implementa√ß√£o:**
```python
async def send_email_notification(email: str, subject: str, content: str):
    """Envia notifica√ß√£o por email via SendGrid"""
    try:
        sg = SendGridAPIClient(api_key=SENDGRID_API_KEY)
        
        message = Mail(
            from_email=FROM_EMAIL,
            to_emails=email,
            subject=subject,
            html_content=content
        )
        
        response = await sg.send(message)
        logger.info(f"Email sent to {email}: {response.status_code}")
        return True
        
    except Exception as e:
        logger.error(f"Failed to send email: {e}")
        return False
```

**Estimativa:** 1 dia

#### US-1.2.3: Configurar credenciais e testar envio
**Como** desenvolvedor  
**Quero** configurar as credenciais das APIs  
**Para que** as notifica√ß√µes sejam enviadas corretamente  

**Crit√©rios de Aceita√ß√£o:**
- [ ] Credenciais OneSignal configuradas
- [ ] Credenciais SendGrid configuradas
- [ ] Teste de envio real executado
- [ ] Notifica√ß√µes chegando aos destinat√°rios

**Implementa√ß√£o:**
```bash
# .env
ONESIGNAL_APP_ID=your_app_id
ONESIGNAL_REST_API_KEY=your_rest_api_key
SENDGRID_API_KEY=your_sendgrid_key
FROM_EMAIL=noreply@litgo.com
```

**Estimativa:** 0.5 dias

---

### ‚è∞ EPIC 1.3: Configura√ß√£o de Agendamento
**Problema:** Jobs n√£o rodam automaticamente

#### US-1.3.1: Adicionar Celery Beat ao docker-compose
**Como** desenvolvedor  
**Quero** configurar o scheduler Celery Beat  
**Para que** jobs sejam executados automaticamente  

**Crit√©rios de Aceita√ß√£o:**
- [ ] Servi√ßo celery-beat adicionado ao docker-compose
- [ ] Configura√ß√£o correta de depend√™ncias
- [ ] Volumes mapeados corretamente
- [ ] Servi√ßo iniciando sem erro

**Implementa√ß√£o:**
```yaml
# docker-compose.yml
services:
  # ... servi√ßos existentes ...
  
  celery-beat:
    build:
      context: .
      dockerfile: backend/Dockerfile
    volumes:
      - ./backend:/app/backend
    env_file:
      - .env
    depends_on:
      - db
      - redis
    command: celery -A backend.celery_app beat --loglevel=info
```

**Estimativa:** 0.5 dias

#### US-1.3.2: Configurar periodic tasks
**Como** desenvolvedor  
**Quero** configurar tarefas peri√≥dicas no Celery  
**Para que** jobs cr√≠ticos sejam executados regularmente  

**Crit√©rios de Aceita√ß√£o:**
- [ ] Job `expire_offers` configurado para rodar de hora em hora
- [ ] Job `jusbrasil_sync` configurado para rodar diariamente √†s 3h
- [ ] Job `update_review_kpi` configurado para rodar diariamente √†s 4h
- [ ] Configura√ß√£o testada e funcionando

**Implementa√ß√£o:**
```python
# backend/celery_app.py
from celery.schedules import crontab

celery_app.conf.beat_schedule = {
    'expire-offers': {
        'task': 'backend.jobs.expire_offers.expire_offers_task',
        'schedule': crontab(minute=0),  # Toda hora
    },
    'jusbrasil-sync': {
        'task': 'backend.jobs.jusbrasil_sync.sync_all_lawyers_task',
        'schedule': crontab(hour=3, minute=0),  # 3:00 AM di√°rio
    },
    'update-review-kpi': {
        'task': 'backend.jobs.update_review_kpi.update_kpi_task',
        'schedule': crontab(hour=4, minute=0),  # 4:00 AM di√°rio
    },
}
```

**Estimativa:** 1 dia

#### US-1.3.3: Testar execu√ß√£o autom√°tica
**Como** desenvolvedor  
**Quero** validar que jobs s√£o executados automaticamente  
**Para que** o sistema funcione sem interven√ß√£o manual  

**Crit√©rios de Aceita√ß√£o:**
- [ ] Jobs executando nos hor√°rios configurados
- [ ] Logs de execu√ß√£o sendo gerados
- [ ] Resultados dos jobs validados
- [ ] Monitoramento b√°sico funcionando

**Estimativa:** 0.5 dias

---

### üß™ EPIC 1.4: Corre√ß√£o de Testes
**Problema:** Testes desatualizados com c√≥digo atual

#### US-1.4.1: Atualizar testes da Fase 1 (triagem)
**Como** desenvolvedor  
**Quero** corrigir testes da triagem  
**Para que** reflitam a implementa√ß√£o atual  

**Crit√©rios de Aceita√ß√£o:**
- [ ] Refer√™ncias a `run_triage_async_task` removidas
- [ ] Testes usando `run_full_triage_flow_task`
- [ ] Todos os testes da triagem passando
- [ ] Cobertura de testes mantida

**Implementa√ß√£o:**
```python
# tests/test_triage.py
@pytest.mark.asyncio
async def test_triage_full_flow():
    # Atualizar para usar a task correta
    result = await run_full_triage_flow_task.apply_async(
        args=["Preciso de ajuda com processo trabalhista"]
    )
    
    assert result.status == 'SUCCESS'
    assert 'area' in result.result
```

**Estimativa:** 1 dia

#### US-1.4.2: Atualizar testes da Fase 7 (offers)
**Como** desenvolvedor  
**Quero** sincronizar testes das ofertas  
**Para que** reflitam a implementa√ß√£o atual  

**Crit√©rios de Aceita√ß√£o:**
- [ ] Testes de expira√ß√£o de ofertas funcionando
- [ ] Testes de cria√ß√£o de ofertas atualizados
- [ ] Todos os testes das ofertas passando
- [ ] Cobertura de testes mantida

**Estimativa:** 1 dia

## üìÖ CRONOGRAMA DETALHADO

### Semana 1 (Dias 1-5)
| Dia | Atividade | Respons√°vel | Status |
|:---:|:---|:---|:---:|
| 1 | US-1.1.1: Criar migra√ß√£o campos | Dev Backend | ‚è≥ |
| 1 | US-1.1.2: Mapear campos existentes | Dev Backend | ‚è≥ |
| 2 | US-1.1.3: Testar integra√ß√£o | Dev Backend | ‚è≥ |
| 2 | US-1.2.1: Implementar push notification | Dev Backend | ‚è≥ |
| 3 | US-1.2.1: Continuar push notification | Dev Backend | ‚è≥ |
| 3 | US-1.2.2: Implementar email notification | Dev Backend | ‚è≥ |
| 4 | US-1.2.3: Configurar credenciais | Dev Backend | ‚è≥ |
| 4 | US-1.3.1: Configurar Celery Beat | DevOps | ‚è≥ |
| 5 | US-1.3.2: Configurar periodic tasks | Dev Backend | ‚è≥ |

### Semana 2 (Dias 6-10)
| Dia | Atividade | Respons√°vel | Status |
|:---:|:---|:---|:---:|
| 6 | US-1.3.3: Testar execu√ß√£o autom√°tica | Dev Backend | ‚è≥ |
| 7 | US-1.4.1: Atualizar testes triagem | Dev Backend | ‚è≥ |
| 8 | US-1.4.2: Atualizar testes offers | Dev Backend | ‚è≥ |
| 9 | Testes de integra√ß√£o completos | QA | ‚è≥ |
| 10 | Valida√ß√£o final e documenta√ß√£o | Tech Lead | ‚è≥ |

## üß™ ESTRAT√âGIA DE TESTES

### Testes Unit√°rios
- [ ] Cada fun√ß√£o implementada tem testes unit√°rios
- [ ] Cobertura m√≠nima de 80%
- [ ] Mocks para APIs externas (OneSignal, SendGrid)

### Testes de Integra√ß√£o
- [ ] Pipeline completo testado ponta-a-ponta
- [ ] Notifica√ß√µes testadas com contas reais
- [ ] Jobs testados com dados reais

### Testes de Aceita√ß√£o
- [ ] Cen√°rios de usu√°rio validados
- [ ] Performance b√°sica validada
- [ ] Logs e m√©tricas funcionando

## üöÄ CRIT√âRIOS DE ACEITA√á√ÉO DO SPRINT

### Funcionalidades B√°sicas
- [ ] **Pipeline Completo**: Triagem ‚Üí Matching ‚Üí Ofertas ‚Üí Contratos funcionando
- [ ] **Notifica√ß√µes**: Advogados recebem push notifications e emails
- [ ] **Jobs Autom√°ticos**: Ofertas expiram automaticamente, KPIs s√£o atualizados
- [ ] **Dados Corretos**: Algoritmo usa campos corretos da tabela lawyers

### Qualidade
- [ ] **Testes Passando**: >80% dos testes unit√°rios passando
- [ ] **Logs Estruturados**: Todas as opera√ß√µes logadas em JSON
- [ ] **Tratamento de Erros**: Fallbacks funcionando corretamente
- [ ] **Performance**: Lat√™ncia <5s para opera√ß√µes cr√≠ticas

### Opera√ß√£o
- [ ] **Docker Compose**: Todos os servi√ßos sobem corretamente
- [ ] **Configura√ß√£o**: Vari√°veis de ambiente documentadas
- [ ] **Monitoramento**: Logs dispon√≠veis para debug
- [ ] **Rollback**: Processo de rollback documentado

## üîß CONFIGURA√á√ÉO DE AMBIENTE

### Vari√°veis de Ambiente Necess√°rias
```bash
# APIs de Notifica√ß√£o
ONESIGNAL_APP_ID=your_app_id
ONESIGNAL_REST_API_KEY=your_rest_api_key
SENDGRID_API_KEY=your_sendgrid_key
FROM_EMAIL=noreply@litgo.com

# Celery
CELERY_BROKER_URL=redis://localhost:6379
CELERY_RESULT_BACKEND=redis://localhost:6379

# Banco de Dados
SUPABASE_URL=your_supabase_url
SUPABASE_SERVICE_KEY=your_service_key
```

### Comandos de Deploy
```bash
# Executar migra√ß√µes
supabase db push

# Iniciar servi√ßos
docker-compose up -d

# Verificar jobs
celery -A backend.celery_app inspect active

# Monitorar logs
docker-compose logs -f celery-beat
```

## üìä M√âTRICAS DE SUCESSO

### M√©tricas T√©cnicas
- **Uptime**: >99% dos servi√ßos funcionando
- **Lat√™ncia**: <5s para opera√ß√µes cr√≠ticas
- **Taxa de Erro**: <1% nas opera√ß√µes
- **Cobertura de Testes**: >80%

### M√©tricas de Neg√≥cio
- **Notifica√ß√µes Entregues**: >95% das notifica√ß√µes chegam
- **Ofertas Processadas**: 100% das ofertas s√£o processadas
- **Jobs Executados**: 100% dos jobs executam no hor√°rio
- **Pipeline Completo**: 100% dos casos passam pelo pipeline

## üéØ DEFINI√á√ÉO DE PRONTO

Uma user story est√° pronta quando:
- [ ] C√≥digo implementado e testado
- [ ] Testes unit√°rios passando
- [ ] Testes de integra√ß√£o validados
- [ ] Documenta√ß√£o atualizada
- [ ] Code review aprovado
- [ ] Deploy em staging validado
- [ ] Crit√©rios de aceita√ß√£o atendidos

## üìû PR√ìXIMOS PASSOS

### Ap√≥s Sprint 1
1. **Valida√ß√£o em Produ√ß√£o**: Deploy gradual e monitoramento
2. **Sprint 2**: Melhorias operacionais e observabilidade
3. **Otimiza√ß√µes**: Baseadas no feedback do Sprint 1

### Riscos e Mitiga√ß√µes
- **Risco**: Migra√ß√£o de dados falha
  - **Mitiga√ß√£o**: Backup completo antes da migra√ß√£o
- **Risco**: APIs externas indispon√≠veis
  - **Mitiga√ß√£o**: Implementar fallbacks desde o in√≠cio
- **Risco**: Performance degradada
  - **Mitiga√ß√£o**: Monitoramento cont√≠nuo e rollback r√°pido

---

**üéØ Este sprint √© cr√≠tico para o sucesso do projeto. Foco total na execu√ß√£o e qualidade das entregas.** 