# üîß SPRINT 2: MELHORIAS OPERACIONAIS - PLANO DETALHADO

> **Dura√ß√£o:** 3 semanas (15 dias √∫teis)  
> **Objetivo:** Otimizar opera√ß√£o e adicionar observabilidade  
> **Prioridade:** P1 - Melhorias operacionais  

## üìã VIS√ÉO GERAL

Este sprint foca em **melhorias operacionais** e **observabilidade** para garantir que o sistema rode de forma est√°vel e aut√¥noma em produ√ß√£o. Inclui implementa√ß√£o de equidade, monitoramento, fallbacks e valida√ß√£o A/B.

## üéØ OBJETIVOS DO SPRINT

### Principais Entregas
1. **Sistema Aut√¥nomo**: Funciona 24/7 sem interven√ß√£o manual
2. **Distribui√ß√£o Justa**: Equidade entre advogados implementada
3. **Observabilidade Completa**: M√©tricas, alertas e dashboards
4. **Resili√™ncia**: Fallbacks para todas as depend√™ncias externas

### M√©tricas de Sucesso
- [ ] Sistema roda 24/7 sem interven√ß√£o manual
- [ ] Distribui√ß√£o justa de casos funcionando
- [ ] Alertas funcionando para problemas cr√≠ticos
- [ ] M√©tricas coletadas e visualizadas
- [ ] Fallbacks testados e funcionando

## üìä √âPICOS E USER STORIES

### ‚öñÔ∏è EPIC 2.1: Jobs de Equidade
**Problema:** Campos de equidade n√£o s√£o calculados automaticamente

#### US-2.1.1: Implementar job de c√°lculo de equidade
**Como** sistema  
**Quero** calcular automaticamente os campos de equidade  
**Para que** a distribui√ß√£o de casos seja justa  

**Crit√©rios de Aceita√ß√£o:**
- [ ] Job `calculate_equity_metrics` implementado
- [ ] Calcula `cases_30d` para cada advogado
- [ ] Calcula `capacidade_mensal` baseado no perfil
- [ ] Atualiza `last_offered_at` quando necess√°rio
- [ ] Executa diariamente √†s 2:00 AM

**Implementa√ß√£o:**
```python
# backend/jobs/calculate_equity.py
async def calculate_equity_metrics():
    """Calcula m√©tricas de equidade para todos os advogados"""
    supabase = get_supabase_client()
    
    # Buscar todos os advogados ativos
    lawyers = supabase.table("lawyers").select("*").eq("status", "active").execute()
    
    for lawyer in lawyers.data:
        # Contar casos dos √∫ltimos 30 dias
        cases_30d = supabase.table("contracts")\
            .select("id", count="exact")\
            .eq("lawyer_id", lawyer["id"])\
            .gte("created_at", (datetime.now() - timedelta(days=30)).isoformat())\
            .execute()
        
        # Calcular capacidade mensal baseada no perfil
        capacidade_mensal = calculate_monthly_capacity(lawyer)
        
        # Atualizar advogado
        supabase.table("lawyers").update({
            "cases_30d": cases_30d.count,
            "capacidade_mensal": capacidade_mensal
        }).eq("id", lawyer["id"]).execute()
```

**Estimativa:** 2 dias

#### US-2.1.2: Testar distribui√ß√£o justa
**Como** desenvolvedor  
**Quero** validar que a distribui√ß√£o de casos √© justa  
**Para que** advogados com menos casos recebam mais ofertas  

**Crit√©rios de Aceita√ß√£o:**
- [ ] Teste automatizado de distribui√ß√£o
- [ ] Advogados com menos casos recebem mais ofertas
- [ ] Round-robin funcionando em caso de empate
- [ ] M√©tricas de distribui√ß√£o coletadas

**Implementa√ß√£o:**
```python
# tests/test_equity_distribution.py
@pytest.mark.asyncio
async def test_fair_distribution():
    # Criar advogados com diferentes cargas
    lawyer_low_load = create_lawyer(cases_30d=2, capacidade_mensal=10)
    lawyer_high_load = create_lawyer(cases_30d=8, capacidade_mensal=10)
    
    # Executar matching m√∫ltiplas vezes
    for _ in range(10):
        matches = await MatchService.find_matches(case_data)
        # Advogado com menor carga deve aparecer mais vezes
        assert count_lawyer_in_matches(lawyer_low_load, matches) > \
               count_lawyer_in_matches(lawyer_high_load, matches)
```

**Estimativa:** 1 dia

#### US-2.1.3: Agendar execu√ß√£o di√°ria
**Como** sistema  
**Quero** que o c√°lculo de equidade rode automaticamente  
**Para que** os dados estejam sempre atualizados  

**Crit√©rios de Aceita√ß√£o:**
- [ ] Job agendado para 2:00 AM diariamente
- [ ] Logs de execu√ß√£o estruturados
- [ ] Alertas em caso de falha
- [ ] M√©tricas de tempo de execu√ß√£o

**Implementa√ß√£o:**
```python
# backend/celery_app.py
celery_app.conf.beat_schedule.update({
    'calculate-equity': {
        'task': 'backend.jobs.calculate_equity.calculate_equity_task',
        'schedule': crontab(hour=2, minute=0),  # 2:00 AM di√°rio
    },
})
```

**Estimativa:** 0.5 dias

---

### üìä EPIC 2.2: Monitoramento e Observabilidade
**Problema:** Falta visibilidade sobre o funcionamento do sistema

#### US-2.2.1: Implementar m√©tricas Prometheus
**Como** desenvolvedor  
**Quero** coletar m√©tricas do sistema  
**Para que** possa monitorar performance e sa√∫de  

**Crit√©rios de Aceita√ß√£o:**
- [ ] M√©tricas de contadores implementadas
- [ ] M√©tricas de lat√™ncia implementadas
- [ ] M√©tricas de neg√≥cio implementadas
- [ ] Endpoint `/metrics` funcionando

**Implementa√ß√£o:**
```python
# backend/metrics.py
from prometheus_client import Counter, Histogram, Gauge

# Contadores
triage_requests_total = Counter('triage_requests_total', 'Total triage requests')
matches_found_total = Counter('matches_found_total', 'Total matches found')
offers_created_total = Counter('offers_created_total', 'Total offers created')
contracts_signed_total = Counter('contracts_signed_total', 'Total contracts signed')
notifications_sent_total = Counter('notifications_sent_total', 'Total notifications sent', ['type', 'status'])

# Histogramas para lat√™ncia
triage_duration = Histogram('triage_duration_seconds', 'Triage processing time')
matching_duration = Histogram('matching_duration_seconds', 'Matching processing time')
notification_duration = Histogram('notification_duration_seconds', 'Notification processing time')

# Gauges para estado atual
active_offers = Gauge('active_offers_count', 'Number of active offers')
pending_contracts = Gauge('pending_contracts_count', 'Number of pending contracts')
system_health = Gauge('system_health_score', 'Overall system health score')
```

**Estimativa:** 2 dias

#### US-2.2.2: Configurar alertas
**Como** operador  
**Quero** receber alertas sobre problemas cr√≠ticos  
**Para que** possa reagir rapidamente a falhas  

**Crit√©rios de Aceita√ß√£o:**
- [ ] Alertas para falha de jobs cr√≠ticos
- [ ] Alertas para alta lat√™ncia
- [ ] Alertas para muitas ofertas expirando
- [ ] Alertas para baixa taxa de sucesso

**Implementa√ß√£o:**
```yaml
# prometheus/alerts.yml
groups:
- name: litgo_alerts
  rules:
  - alert: HighErrorRate
    expr: rate(triage_requests_total{status="error"}[5m]) > 0.1
    for: 2m
    labels:
      severity: critical
    annotations:
      summary: "High error rate in triage service"
      
  - alert: JobFailure
    expr: increase(celery_task_failures_total[5m]) > 0
    for: 1m
    labels:
      severity: warning
    annotations:
      summary: "Celery job failed"
```

**Estimativa:** 1 dia

#### US-2.2.3: Dashboard Grafana
**Como** operador  
**Quero** visualizar m√©tricas em dashboards  
**Para que** possa monitorar o sistema visualmente  

**Crit√©rios de Aceita√ß√£o:**
- [ ] Dashboard de vis√£o geral implementado
- [ ] Dashboard de m√©tricas de neg√≥cio
- [ ] Dashboard de performance t√©cnica
- [ ] Dashboard de jobs e sa√∫de do sistema

**Implementa√ß√£o:**
```json
{
  "dashboard": {
    "title": "LITGO5 - Vis√£o Geral",
    "panels": [
      {
        "title": "Requests por Minuto",
        "targets": [
          {
            "expr": "rate(triage_requests_total[1m])"
          }
        ]
      },
      {
        "title": "Lat√™ncia M√©dia",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, triage_duration_seconds_bucket)"
          }
        ]
      }
    ]
  }
}
```

**Estimativa:** 2 dias

---

### üîÑ EPIC 2.3: Valida√ß√£o A/B para LTR
**Problema:** Novos modelos n√£o s√£o testados antes do deploy

#### US-2.3.1: Implementar framework A/B
**Como** sistema  
**Quero** testar novos modelos com uma porcentagem do tr√°fego  
**Para que** possa validar melhorias antes do deploy completo  

**Crit√©rios de Aceita√ß√£o:**
- [ ] Framework A/B implementado
- [ ] Divis√£o de tr√°fego configur√°vel
- [ ] M√©tricas coletadas por grupo
- [ ] Compara√ß√£o autom√°tica de performance

**Implementa√ß√£o:**
```python
# backend/services/ab_testing.py
class ABTestingService:
    def __init__(self):
        self.experiments = {}
    
    def should_use_variant(self, experiment_name: str, user_id: str) -> bool:
        """Decide se deve usar variante baseado no hash do user_id"""
        experiment = self.experiments.get(experiment_name)
        if not experiment:
            return False
        
        hash_value = hash(f"{experiment_name}_{user_id}") % 100
        return hash_value < experiment["traffic_percentage"]
    
    def track_metric(self, experiment_name: str, user_id: str, metric_name: str, value: float):
        """Registra m√©trica para an√°lise A/B"""
        variant = "B" if self.should_use_variant(experiment_name, user_id) else "A"
        
        # Registrar no Prometheus
        ab_test_metrics.labels(
            experiment=experiment_name,
            variant=variant,
            metric=metric_name
        ).observe(value)
```

**Estimativa:** 2 dias

#### US-2.3.2: Automatizar retreino
**Como** sistema  
**Quero** retreinar modelos automaticamente  
**Para que** o sistema melhore continuamente  

**Crit√©rios de Aceita√ß√£o:**
- [ ] Trigger de retreino baseado em volume de dados
- [ ] Valida√ß√£o autom√°tica de novos modelos
- [ ] Deploy autom√°tico se modelo for melhor
- [ ] Rollback autom√°tico se houver degrada√ß√£o

**Implementa√ß√£o:**
```python
# backend/jobs/auto_retrain.py
async def auto_retrain_ltr():
    """Retreina modelo LTR automaticamente"""
    # Verificar se h√° dados suficientes
    new_reviews_count = count_new_reviews_since_last_training()
    
    if new_reviews_count < MIN_REVIEWS_FOR_RETRAIN:
        logger.info(f"Not enough new reviews: {new_reviews_count}")
        return
    
    # Treinar novo modelo
    new_model = await train_ltr_model()
    
    # Validar modelo
    validation_score = await validate_model(new_model)
    current_score = get_current_model_score()
    
    if validation_score > current_score * 1.05:  # 5% melhoria m√≠nima
        # Deploy novo modelo
        await deploy_model(new_model)
        logger.info(f"New model deployed: {validation_score} vs {current_score}")
    else:
        logger.info(f"New model not better: {validation_score} vs {current_score}")
```

**Estimativa:** 3 dias

#### US-2.3.3: Rollback autom√°tico
**Como** sistema  
**Quero** detectar degrada√ß√£o e fazer rollback  
**Para que** o sistema mantenha qualidade mesmo com modelos ruins  

**Crit√©rios de Aceita√ß√£o:**
- [ ] Monitoramento de m√©tricas de qualidade
- [ ] Detec√ß√£o autom√°tica de degrada√ß√£o
- [ ] Rollback autom√°tico para modelo anterior
- [ ] Alertas para equipe t√©cnica

**Implementa√ß√£o:**
```python
# backend/services/model_monitoring.py
class ModelMonitoringService:
    def __init__(self):
        self.quality_threshold = 0.85
        self.degradation_window = timedelta(hours=1)
    
    async def check_model_quality(self):
        """Verifica qualidade do modelo atual"""
        recent_scores = get_recent_match_scores(self.degradation_window)
        avg_score = sum(recent_scores) / len(recent_scores)
        
        if avg_score < self.quality_threshold:
            logger.warning(f"Model quality degraded: {avg_score}")
            await self.rollback_model()
    
    async def rollback_model(self):
        """Faz rollback para modelo anterior"""
        previous_model = get_previous_model()
        await deploy_model(previous_model)
        
        # Enviar alerta
        await send_alert("Model rolled back due to quality degradation")
```

**Estimativa:** 2 dias

---

### üõ°Ô∏è EPIC 2.4: Fallbacks e Resili√™ncia
**Problema:** Sistema falha quando depend√™ncias externas est√£o indispon√≠veis

#### US-2.4.1: Implementar fallback para embeddings
**Como** sistema  
**Quero** usar modelo local quando OpenAI falha  
**Para que** o sistema continue funcionando mesmo com APIs externas indispon√≠veis  

**Crit√©rios de Aceita√ß√£o:**
- [ ] Modelo sentence-transformers configurado
- [ ] Fallback autom√°tico implementado
- [ ] Qualidade do fallback validada
- [ ] M√©tricas de uso do fallback

**Implementa√ß√£o:**
```python
# backend/services/embedding_service.py
from sentence_transformers import SentenceTransformer

class EmbeddingService:
    def __init__(self):
        self.openai_client = OpenAI()
        self.local_model = SentenceTransformer('all-MiniLM-L6-v2')
    
    async def generate_embedding(self, text: str) -> List[float]:
        """Gera embedding com fallback local"""
        try:
            # Tentar OpenAI primeiro
            response = await self.openai_client.embeddings.create(
                model="text-embedding-3-small",
                input=text
            )
            embedding_source.labels(source="openai").inc()
            return response.data[0].embedding
            
        except Exception as e:
            logger.warning(f"OpenAI failed, using local model: {e}")
            
            # Fallback para modelo local
            embedding = self.local_model.encode(text).tolist()
            embedding_source.labels(source="local").inc()
            return embedding
```

**Estimativa:** 2 dias

#### US-2.4.2: Fallback para contratos
**Como** sistema  
**Quero** permitir assinatura manual quando DocuSign falha  
**Para que** contratos n√£o sejam bloqueados por falhas externas  

**Crit√©rios de Aceita√ß√£o:**
- [ ] Op√ß√£o de assinatura manual implementada
- [ ] Processo de backup documentado
- [ ] Notifica√ß√£o autom√°tica em caso de falha
- [ ] M√©tricas de uso do fallback

**Implementa√ß√£o:**
```python
# backend/services/contract_service.py
async def create_contract(case_id: str, lawyer_id: str, client_id: str):
    """Cria contrato com fallback para assinatura manual"""
    try:
        # Tentar DocuSign primeiro
        envelope = await create_docusign_envelope(case_id, lawyer_id, client_id)
        contract_creation_method.labels(method="docusign").inc()
        return envelope
        
    except Exception as e:
        logger.warning(f"DocuSign failed, creating manual contract: {e}")
        
        # Fallback para processo manual
        contract = await create_manual_contract(case_id, lawyer_id, client_id)
        contract_creation_method.labels(method="manual").inc()
        
        # Notificar equipe
        await notify_manual_contract_needed(contract)
        return contract
```

**Estimativa:** 1.5 dias

#### US-2.4.3: Timeouts configur√°veis
**Como** desenvolvedor  
**Quero** configurar timeouts para APIs externas  
**Para que** o sistema n√£o trave esperando respostas  

**Crit√©rios de Aceita√ß√£o:**
- [ ] Timeouts configur√°veis via vari√°veis de ambiente
- [ ] Timeouts aplicados a todas as APIs externas
- [ ] Retry com backoff exponencial
- [ ] M√©tricas de timeout coletadas

**Implementa√ß√£o:**
```python
# backend/config.py
class APIConfig:
    OPENAI_TIMEOUT = int(os.getenv("OPENAI_TIMEOUT", "30"))
    DOCUSIGN_TIMEOUT = int(os.getenv("DOCUSIGN_TIMEOUT", "45"))
    ONESIGNAL_TIMEOUT = int(os.getenv("ONESIGNAL_TIMEOUT", "15"))
    SENDGRID_TIMEOUT = int(os.getenv("SENDGRID_TIMEOUT", "15"))

# backend/services/base_service.py
class BaseAPIService:
    def __init__(self, timeout: int):
        self.timeout = timeout
        self.session = httpx.AsyncClient(timeout=timeout)
    
    async def call_with_retry(self, func, *args, **kwargs):
        """Chama fun√ß√£o com retry e timeout"""
        for attempt in range(3):
            try:
                return await func(*args, **kwargs)
            except httpx.TimeoutException:
                api_timeouts.labels(service=self.__class__.__name__).inc()
                if attempt == 2:
                    raise
                await asyncio.sleep(2 ** attempt)
```

**Estimativa:** 1 dia

## üìÖ CRONOGRAMA DETALHADO

### Semana 1 (Dias 1-5)
| Dia | Atividade | Respons√°vel | Status |
|:---:|:---|:---|:---:|
| 1 | US-2.1.1: Implementar job de equidade | Dev Backend | ‚è≥ |
| 2 | US-2.1.1: Continuar job de equidade | Dev Backend | ‚è≥ |
| 2 | US-2.1.2: Testar distribui√ß√£o justa | Dev Backend | ‚è≥ |
| 3 | US-2.1.3: Agendar execu√ß√£o di√°ria | Dev Backend | ‚è≥ |
| 3 | US-2.2.1: Implementar m√©tricas Prometheus | Dev Backend | ‚è≥ |
| 4 | US-2.2.1: Continuar m√©tricas | Dev Backend | ‚è≥ |
| 5 | US-2.2.2: Configurar alertas | DevOps | ‚è≥ |

### Semana 2 (Dias 6-10)
| Dia | Atividade | Respons√°vel | Status |
|:---:|:---|:---|:---:|
| 6 | US-2.2.3: Dashboard Grafana | DevOps | ‚è≥ |
| 7 | US-2.2.3: Continuar dashboard | DevOps | ‚è≥ |
| 7 | US-2.3.1: Implementar framework A/B | Dev Backend | ‚è≥ |
| 8 | US-2.3.1: Continuar framework A/B | Dev Backend | ‚è≥ |
| 9 | US-2.3.2: Automatizar retreino | Dev Backend | ‚è≥ |
| 10 | US-2.3.2: Continuar retreino | Dev Backend | ‚è≥ |

### Semana 3 (Dias 11-15)
| Dia | Atividade | Respons√°vel | Status |
|:---:|:---|:---|:---:|
| 11 | US-2.3.2: Finalizar retreino | Dev Backend | ‚è≥ |
| 11 | US-2.3.3: Rollback autom√°tico | Dev Backend | ‚è≥ |
| 12 | US-2.3.3: Continuar rollback | Dev Backend | ‚è≥ |
| 13 | US-2.4.1: Fallback embeddings | Dev Backend | ‚è≥ |
| 14 | US-2.4.1: Continuar fallback | Dev Backend | ‚è≥ |
| 14 | US-2.4.2: Fallback contratos | Dev Backend | ‚è≥ |
| 15 | US-2.4.3: Timeouts configur√°veis | Dev Backend | ‚è≥ |

## üß™ ESTRAT√âGIA DE TESTES

### Testes de Resili√™ncia
- [ ] Testes de falha de APIs externas
- [ ] Testes de timeout e retry
- [ ] Testes de fallback autom√°tico
- [ ] Testes de carga e stress

### Testes de Equidade
- [ ] Testes de distribui√ß√£o justa
- [ ] Testes de round-robin
- [ ] Testes de c√°lculo de m√©tricas
- [ ] Testes de performance do job

### Testes de Monitoramento
- [ ] Testes de coleta de m√©tricas
- [ ] Testes de alertas
- [ ] Testes de dashboards
- [ ] Testes de A/B testing

## üöÄ CRIT√âRIOS DE ACEITA√á√ÉO DO SPRINT

### Opera√ß√£o Aut√¥noma
- [ ] **24/7 sem interven√ß√£o**: Sistema roda sem interven√ß√£o manual
- [ ] **Jobs autom√°ticos**: Todos os jobs executam conforme agendado
- [ ] **Fallbacks funcionando**: Sistema resiliente a falhas externas
- [ ] **Alertas ativos**: Problemas s√£o detectados e notificados

### Distribui√ß√£o Justa
- [ ] **Equidade implementada**: Advogados com menos casos recebem mais ofertas
- [ ] **M√©tricas atualizadas**: `cases_30d` e `capacidade_mensal` calculados
- [ ] **Round-robin**: Desempate funcionando corretamente
- [ ] **Testes validados**: Distribui√ß√£o justa comprovada

### Observabilidade
- [ ] **M√©tricas coletadas**: Prometheus funcionando
- [ ] **Dashboards ativos**: Grafana com visualiza√ß√µes
- [ ] **Alertas configurados**: Notifica√ß√µes para problemas cr√≠ticos
- [ ] **A/B testing**: Framework para testes de modelo

### Resili√™ncia
- [ ] **Fallbacks testados**: Todos os fallbacks funcionando
- [ ] **Timeouts configurados**: APIs externas com timeout
- [ ] **Retry implementado**: Tentativas autom√°ticas
- [ ] **Monitoramento**: M√©tricas de falhas coletadas

## üîß CONFIGURA√á√ÉO DE AMBIENTE

### Vari√°veis de Ambiente Adicionais
```bash
# Timeouts
OPENAI_TIMEOUT=30
DOCUSIGN_TIMEOUT=45
ONESIGNAL_TIMEOUT=15
SENDGRID_TIMEOUT=15

# Monitoramento
PROMETHEUS_PORT=9090
GRAFANA_PORT=3000
GRAFANA_ADMIN_PASSWORD=admin

# A/B Testing
AB_TESTING_ENABLED=true
DEFAULT_TRAFFIC_PERCENTAGE=10

# Fallbacks
LOCAL_EMBEDDING_MODEL=all-MiniLM-L6-v2
FALLBACK_ENABLED=true
```

### Docker Compose Atualizado
```yaml
# docker-compose.yml
services:
  # ... servi√ßos existentes ...
  
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - ./prometheus/alerts.yml:/etc/prometheus/alerts.yml
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--web.enable-lifecycle'
  
  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana-storage:/var/lib/grafana
      - ./grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./grafana/datasources:/etc/grafana/provisioning/datasources

volumes:
  grafana-storage:
```

## üìä M√âTRICAS DE SUCESSO

### M√©tricas Operacionais
- **Uptime**: >99.9% dos servi√ßos funcionando
- **MTTR**: <15 minutos para resolver problemas
- **Alertas**: <5% de falsos positivos
- **Jobs**: 100% executados conforme agendado

### M√©tricas de Equidade
- **Distribui√ß√£o**: Coeficiente de Gini <0.3
- **Utiliza√ß√£o**: >80% dos advogados recebem ofertas
- **Balanceamento**: Diferen√ßa m√°xima de 20% entre advogados

### M√©tricas de Resili√™ncia
- **Fallback Usage**: <10% do tempo total
- **Timeout Rate**: <1% das requisi√ß√µes
- **Recovery Time**: <30 segundos para fallbacks

## üéØ DEFINI√á√ÉO DE PRONTO

Uma user story est√° pronta quando:
- [ ] C√≥digo implementado e testado
- [ ] Testes unit√°rios e integra√ß√£o passando
- [ ] M√©tricas implementadas
- [ ] Alertas configurados
- [ ] Documenta√ß√£o atualizada
- [ ] Code review aprovado
- [ ] Deploy em staging validado
- [ ] Monitoramento funcionando

## üìû PR√ìXIMOS PASSOS

### Ap√≥s Sprint 2
1. **Monitoramento Cont√≠nuo**: Acompanhar m√©tricas em produ√ß√£o
2. **Sprint 3**: Otimiza√ß√µes e features avan√ßadas
3. **Refinamentos**: Baseados no feedback operacional

### Riscos e Mitiga√ß√µes
- **Risco**: Overhead de monitoramento afeta performance
  - **Mitiga√ß√£o**: Sampling e otimiza√ß√£o de coleta
- **Risco**: Fallbacks com qualidade inferior
  - **Mitiga√ß√£o**: Testes extensivos e m√©tricas de qualidade
- **Risco**: Complexidade do A/B testing
  - **Mitiga√ß√£o**: Implementa√ß√£o gradual e documenta√ß√£o

---

**üîß Este sprint estabelece as bases para opera√ß√£o est√°vel e aut√¥noma do sistema em produ√ß√£o.** 