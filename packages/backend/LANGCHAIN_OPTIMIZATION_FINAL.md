# LangChain: Otimiza√ß√£o Conservadora - Plano Final

## üéØ **OBJETIVO CLARO**
Usar LangChain como **interface melhorada** para os modelos j√° configurados, sem adicionar novos provedores.

---

## üìã **MODELOS EXISTENTES NO APP**

| Fun√ß√£o | Modelo Atual | LangChain Interface |
|---------|-------------|-------------------|
| **OCR** | `openai/gpt-4o-mini` | `ChatOpenAI(model="gpt-4o-mini")` |
| **Caso** | `anthropic/claude-sonnet-4` | `ChatAnthropic(model="claude-4.0-sonnet")` |
| **Perfil** | `google/gemini-2.5-flash` | `ChatGoogleGenerativeAI(model="gemini-2.5-flash")` |
| **LEX9000** | `xai/grok-4` | `ChatXAI(model="grok-4")` |
| **Triagem** | `meta-llama/Llama-4-Scout` | `ChatOpenAI(base_url="together", model="llama-4-scout")` |
| **Autorouter** | `openrouter/auto` | `ChatOpenAI(base_url="openrouter", model="auto")` |

---

## üöÄ **IMPLEMENTA√á√ÉO SIMPLES**

### **1. Interface LangChain Unificada**
```python
class SimpleLangChainOrchestrator:
    def __init__(self):
        # Usar APENAS modelos j√° configurados
        self.models = {
            "ocr": ChatOpenAI(model="gpt-4o-mini"),
            "case": ChatAnthropic(model="claude-4.0-sonnet-20250401"),
            "profile": ChatGoogleGenerativeAI(model="gemini-2.5-flash"),
            "lex9000": ChatXAI(model="grok-4"),
            "triage": ChatOpenAI(
                base_url="https://api.together.xyz/v1",
                model="meta-llama/Llama-4-Scout"
            )
        }
    
    async def route_by_function(self, function: str, prompt: str):
        """Roteamento simples por fun√ß√£o."""
        if function in self.models:
            return await self.models[function].ainvoke(prompt)
        
        # Fallback para sistema existente
        return await self.openrouter_client.chat_completion_with_fallback(
            primary_model="openrouter/auto",
            messages=[{"role": "user", "content": prompt}]
        )
```

### **2. Agente Jur√≠dico com Mem√≥ria**
```python
from langchain.agents import AgentExecutor, create_openai_functions_agent
from langchain.memory import ConversationBufferMemory

class SimpleLegalAgent:
    def __init__(self):
        # Usar GPT-4o (j√° configurado) como base
        self.llm = ChatOpenAI(model="gpt-4o")
        
        # Mem√≥ria persistente
        self.memory = ConversationBufferMemory(return_messages=True)
        
        # Tools jur√≠dicas b√°sicas
        self.tools = [
            Tool(
                name="analyze_case",
                func=lambda q: self.orchestrator.route_by_function("case", q),
                description="Analisa caso jur√≠dico usando Claude"
            ),
            Tool(
                name="extract_document", 
                func=lambda q: self.orchestrator.route_by_function("ocr", q),
                description="Extrai texto de documentos usando GPT-4o-mini"
            )
        ]
        
        # Agente simples
        self.agent = create_openai_functions_agent(
            llm=self.llm,
            tools=self.tools,
            memory=self.memory
        )
```

### **3. RAG Jur√≠dico B√°sico**
```python
from langchain.vectorstores import Chroma
from langchain.embeddings import OpenAIEmbeddings

class SimpleLegalRAG:
    def __init__(self):
        # Usar OpenAI embeddings (j√° configurado)
        self.embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
        
        # Vector store simples
        self.legal_db = Chroma(
            collection_name="legal_docs_br",
            embedding_function=self.embeddings
        )
        
        # LLM para respostas (j√° configurado)
        self.llm = ChatOpenAI(model="gpt-4o")
    
    async def answer_with_context(self, question: str):
        """Resposta com contexto jur√≠dico."""
        # Buscar documentos relevantes
        docs = self.legal_db.similarity_search(question, k=3)
        context = "\n".join([doc.page_content for doc in docs])
        
        # Prompt com contexto
        prompt = f"Contexto jur√≠dico:\n{context}\n\nPergunta: {question}"
        return await self.llm.ainvoke(prompt)
```

---

## üìä **BENEF√çCIOS PR√ÅTICOS**

| Aspecto | Antes | Depois |
|---------|-------|--------|
| **Interface** | APIs separadas | LangChain unificado |
| **Mem√≥ria** | Stateless | Persistente entre sess√µes |
| **Tools** | Hardcoded | Agentes com function calling |
| **RAG** | Sem contexto | Base jur√≠dica especializada |
| **Modelos** | Fixos | Roteamento inteligente |
| **Complexidade** | Alta | Simplificada |

---

## üõ†Ô∏è **PLANO DE IMPLEMENTA√á√ÉO (5 SEMANAS)**

### **Semana 1-2: Interface LangChain**
- ‚úÖ Implementar `SimpleLangChainOrchestrator`
- ‚úÖ Testar com modelos existentes
- ‚úÖ Validar compatibilidade

### **Semana 3: Agentes com Mem√≥ria**
- ‚úÖ Implementar `SimpleLegalAgent`
- ‚úÖ Configurar tools jur√≠dicas
- ‚úÖ Testar function calling

### **Semana 4: RAG Jur√≠dico**
- ‚úÖ Implementar `SimpleLegalRAG`
- ‚úÖ Configurar base de documentos
- ‚úÖ Testar respostas com contexto

### **Semana 5: Integra√ß√£o e Testes**
- ‚úÖ Integrar com sistema existente
- ‚úÖ Testes A/B vs. implementa√ß√£o atual
- ‚úÖ Valida√ß√£o de performance

---

## ‚úÖ **CONCLUS√ÉO**

**Esta √© a abordagem mais inteligente:**
- **Zero risco** - usar apenas modelos j√° testados
- **Funcionalidades avan√ßadas** - agentes, mem√≥ria, RAG
- **Implementa√ß√£o simples** - sem over-engineering
- **Compatibilidade total** - mant√©m sistema existente

**Resultado: LangChain otimiza o que j√° funciona, sem adicionar complexidade desnecess√°ria.** üéØ 