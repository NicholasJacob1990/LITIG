# ğŸš€ Melhorias do Algoritmo: Aproveitando Embeddings V2 (1024D)

## ğŸ“‹ AnÃ¡lise do Estado Atual

### **ImplementaÃ§Ã£o Atual de Similaridade SemÃ¢ntica**

**1. LimitaÃ§Ãµes Identificadas:**
```python
# ATUAL - Muito bÃ¡sico (linha 1313)
def firm_semantic_similarity(self) -> float:
    return cosine_similarity(self.case.summary_embedding, firm.embedding)

# PROBLEMA: Usa apenas 1 embedding do caso vs 1 embedding do firm
# PERDA: NÃ£o aproveita contexto mÃºltiplo, pesos dinÃ¢micos, nem especializaÃ§Ã£o jurÃ­dica
```

**2. Peso Atual da Similaridade SemÃ¢ntica:**
```python
# ATUAL - Peso fixo de 30% (linha 1342)
final_score = (0.7 * reputation_score) + (0.3 * semantic_similarity)
# PROBLEMA: Peso estÃ¡tico nÃ£o considera complexidade do caso ou especializaÃ§Ã£o
```

---

## ğŸ¯ **SUGESTÃƒO 1: Similaridade SemÃ¢ntica Multi-Contexto**

### **Problema Atual**
- Algoritmo usa apenas `case.summary_embedding` vs `firm.embedding`
- Ignora contexto especializado (tipo de caso, urgÃªncia, complexidade)
- NÃ£o aproveita os embeddings V2 especializados por contexto jurÃ­dico

### **Melhoria Proposta: FunÃ§Ã£o `enhanced_semantic_similarity()`**

```python
async def enhanced_semantic_similarity(self) -> Dict[str, float]:
    """
    ğŸ†• Similaridade semÃ¢ntica aprimorada com mÃºltiplos contextos.
    
    Aproveita embeddings V2 especializados para diferentes aspectos do matching:
    1. Similaridade principal (caso vs perfil geral)
    2. EspecializaÃ§Ã£o jurÃ­dica (Ã¡rea especÃ­fica do direito)
    3. Complexidade processual (tipo de procedimento)
    4. Contexto histÃ³rico (casos similares passados)
    
    Returns:
        Dict com scores de similaridade por contexto
    """
    from services.embedding_service_v2 import legal_embedding_service_v2
    
    results = {
        "case_profile_similarity": 0.0,
        "specialization_similarity": 0.0, 
        "procedural_similarity": 0.0,
        "historical_similarity": 0.0,
        "weighted_final": 0.0
    }
    
    # 1. Gerar embedding especializado do caso para diferentes contextos
    case_summary = self.case.summary or ""
    
    # Embeddings especializados V2 (1024D)
    case_general, _ = await legal_embedding_service_v2.generate_legal_embedding(
        case_summary, "case"
    )
    
    case_specialized, _ = await legal_embedding_service_v2.generate_legal_embedding(
        f"Ãrea: {self.case.area}. {case_summary}", "precedent"
    )
    
    case_procedural, _ = await legal_embedding_service_v2.generate_legal_embedding(
        f"Procedimento: {self.case.procedimento}. {case_summary}", "contract"
    )
    
    # 2. Similaridade com perfil geral do advogado
    if hasattr(self.lawyer, 'cv_embedding_v2') and self.lawyer.cv_embedding_v2:
        results["case_profile_similarity"] = legal_embedding_service_v2.get_similarity(
            case_general, self.lawyer.cv_embedding_v2
        )
    
    # 3. Similaridade de especializaÃ§Ã£o (tags_expertise + experiÃªncia)
    lawyer_specialization = " ".join([
        f"Especialista em {tag}" for tag in (self.lawyer.tags_expertise or [])
    ])
    
    if lawyer_specialization:
        lawyer_spec_embedding, _ = await legal_embedding_service_v2.generate_legal_embedding(
            lawyer_specialization, "lawyer_cv"
        )
        results["specialization_similarity"] = legal_embedding_service_v2.get_similarity(
            case_specialized, lawyer_spec_embedding
        )
    
    # 4. Similaridade procedural (experiÃªncia em procedimentos similares)
    # Usar dados de casos histÃ³ricos se disponÃ­veis
    if hasattr(self.lawyer, 'casos_historicos_embeddings') and self.lawyer.casos_historicos_embeddings:
        historical_sims = [
            legal_embedding_service_v2.get_similarity(case_procedural, hist_emb)
            for hist_emb in self.lawyer.casos_historicos_embeddings[-5:]  # Ãšltimos 5 casos
        ]
        results["historical_similarity"] = max(historical_sims) if historical_sims else 0.0
    
    # 5. CÃ¡lculo ponderado final baseado no tipo de caso
    weights = self._get_adaptive_similarity_weights()
    
    results["weighted_final"] = (
        weights["profile"] * results["case_profile_similarity"] +
        weights["specialization"] * results["specialization_similarity"] +
        weights["procedural"] * results["procedural_similarity"] +
        weights["historical"] * results["historical_similarity"]
    )
    
    return results

def _get_adaptive_similarity_weights(self) -> Dict[str, float]:
    """Pesos adaptativos baseados no tipo e complexidade do caso."""
    
    # Pesos padrÃ£o
    weights = {
        "profile": 0.35,
        "specialization": 0.35, 
        "procedural": 0.20,
        "historical": 0.10
    }
    
    # Ajustes baseados no caso
    case_area = self.case.area.lower() if self.case.area else ""
    
    # Casos complexos (direito empresarial, tributÃ¡rio) priorizam especializaÃ§Ã£o
    if any(area in case_area for area in ["empresarial", "tributÃ¡rio", "internacional"]):
        weights["specialization"] = 0.45
        weights["profile"] = 0.25
        weights["procedural"] = 0.20
        weights["historical"] = 0.10
    
    # Casos procedimentais (trabalhista, previdenciÃ¡rio) priorizam experiÃªncia histÃ³rica
    elif any(area in case_area for area in ["trabalhista", "previdenciÃ¡rio", "administrativo"]):
        weights["procedural"] = 0.35
        weights["historical"] = 0.25
        weights["specialization"] = 0.25
        weights["profile"] = 0.15
    
    # Casos novos/Ãºnicos priorizam perfil geral
    elif self.case.urgency_level and self.case.urgency_level == "alta":
        weights["profile"] = 0.50
        weights["specialization"] = 0.30
        weights["procedural"] = 0.15
        weights["historical"] = 0.05
    
    return weights
```

---

## ğŸ¯ **SUGESTÃƒO 2: Peso DinÃ¢mico da Similaridade SemÃ¢ntica**

### **Problema Atual**
- Peso fixo de 30% para similaridade semÃ¢ntica
- NÃ£o considera que casos mais complexos precisam de maior peso semÃ¢ntico
- KPIs podem ser enganosos para casos muito especÃ­ficos

### **Melhoria Proposta: Peso Adaptativo**

```python
def calculate_adaptive_semantic_weight(self) -> float:
    """
    ğŸ†• Calcula peso dinÃ¢mico da similaridade semÃ¢ntica baseado no caso.
    
    Casos mais especializados/complexos recebem maior peso semÃ¢ntico.
    Casos rotineiros confiam mais em KPIs histÃ³ricos.
    
    Returns:
        float: Peso entre 0.2 e 0.8 para similaridade semÃ¢ntica
    """
    base_weight = 0.3  # Peso padrÃ£o atual
    
    # Fatores que aumentam peso semÃ¢ntico
    complexity_factors = 0.0
    
    # 1. Complexidade da Ã¡rea jurÃ­dica
    specialized_areas = {
        "direito empresarial": 0.15,
        "direito tributÃ¡rio": 0.15,
        "direito internacional": 0.20,
        "propriedade intelectual": 0.20,
        "direito digital": 0.15,
        "compliance": 0.15,
        "fusÃµes e aquisiÃ§Ãµes": 0.20
    }
    
    case_area = self.case.area.lower() if self.case.area else ""
    for area, weight_boost in specialized_areas.items():
        if area in case_area:
            complexity_factors += weight_boost
            break
    
    # 2. Valor do caso (casos altos precisam de expertise especÃ­fica)
    if hasattr(self.case, 'valor_causa') and self.case.valor_causa:
        if self.case.valor_causa > 1000000:  # > 1M
            complexity_factors += 0.10
        elif self.case.valor_causa > 500000:  # > 500K
            complexity_factors += 0.05
    
    # 3. UrgÃªncia (casos urgentes precisam de especialista certo)
    if hasattr(self.case, 'urgency_level'):
        if self.case.urgency_level == "alta":
            complexity_factors += 0.10
        elif self.case.urgency_level == "crÃ­tica":
            complexity_factors += 0.15
    
    # 4. Tipo de procedimento (procedimentos raros = mais peso semÃ¢ntico)
    rare_procedures = [
        "mandado de seguranÃ§a", "habeas corpus", "aÃ§Ã£o rescisÃ³ria",
        "reclamaÃ§Ã£o constitucional", "arguiÃ§Ã£o de descumprimento"
    ]
    
    case_procedure = self.case.procedimento.lower() if hasattr(self.case, 'procedimento') and self.case.procedimento else ""
    if any(proc in case_procedure for proc in rare_procedures):
        complexity_factors += 0.10
    
    # Calcular peso final (limitado entre 0.2 e 0.8)
    final_weight = base_weight + complexity_factors
    return np.clip(final_weight, 0.2, 0.8)

def enhanced_firm_reputation(self) -> float:
    """ğŸ†• ReputaÃ§Ã£o do firm com peso semÃ¢ntico adaptativo."""
    
    firm = getattr(self.lawyer, "firm", None)
    if not firm or not hasattr(firm, 'kpi_firm'):
        return 0.5
    
    k = firm.kpi_firm
    
    # KPIs tradicionais
    reputation_score = np.clip(
        0.35 * k.success_rate +
        0.20 * k.nps +
        0.15 * k.reputation_score +
        0.10 * k.diversity_index +
        0.20 * k.maturity_index,
        0, 1
    )
    
    # Similaridade semÃ¢ntica aprimorada
    semantic_results = await self.enhanced_semantic_similarity()
    semantic_score = semantic_results["weighted_final"]
    
    # Peso adaptativo baseado no caso
    semantic_weight = self.calculate_adaptive_semantic_weight()
    reputation_weight = 1.0 - semantic_weight
    
    # Score final adaptativo
    final_score = (reputation_weight * reputation_score) + (semantic_weight * semantic_score)
    
    return np.clip(final_score, 0, 1)
```

---

## ğŸ¯ **SUGESTÃƒO 3: Embeddings Contextuais para Features EspecÃ­ficas**

### **Melhoria nos Scores Existentes**

#### **A. Academic Score com Embeddings V2**

```python
async def enhanced_academic_score(self) -> float:
    """
    ğŸ†• Academic score usando embeddings V2 para relevÃ¢ncia contextual.
    
    NÃ£o apenas conta publicaÃ§Ãµes, mas avalia relevÃ¢ncia para o caso especÃ­fico.
    """
    if not self.lawyer.pareceres:
        return 0.0
    
    # Score quantitativo tradicional
    num_pubs = len(self.lawyer.pareceres)
    score_qty = min(1.0, math.log1p(num_pubs) / math.log1p(20))
    
    # ğŸ†• Score qualitativo com relevÃ¢ncia semÃ¢ntica
    case_context = f"Caso sobre {self.case.area}: {self.case.summary}"
    case_embedding, _ = await legal_embedding_service_v2.generate_legal_embedding(
        case_context, "case"
    )
    
    # Calcular relevÃ¢ncia de cada publicaÃ§Ã£o
    relevance_scores = []
    for parecer in self.lawyer.pareceres:
        if hasattr(parecer, 'embedding') and parecer.embedding:
            relevance = legal_embedding_service_v2.get_similarity(
                case_embedding, parecer.embedding
            )
            relevance_scores.append(relevance)
    
    # Score de relevÃ¢ncia (mÃ©dia dos top 3 mais relevantes)
    if relevance_scores:
        top_relevances = sorted(relevance_scores, reverse=True)[:3]
        score_relevance = sum(top_relevances) / len(top_relevances)
    else:
        score_relevance = 0.0
    
    # CombinaÃ§Ã£o: 40% quantidade + 60% relevÃ¢ncia
    final_score = (0.4 * score_qty) + (0.6 * score_relevance)
    
    return np.clip(final_score, 0, 1)
```

#### **B. Geo Score com Contexto JurÃ­dico**

```python
async def enhanced_geo_score(self) -> float:
    """
    ğŸ†• Score geogrÃ¡fico que considera especializaÃ§Ã£o local/regional.
    
    NÃ£o apenas distÃ¢ncia fÃ­sica, mas conhecimento de leis locais e prÃ¡ticas regionais.
    """
    # Score de distÃ¢ncia tradicional
    distance_score = super().geo_score()  # ImplementaÃ§Ã£o atual
    
    # ğŸ†• Score de especializaÃ§Ã£o local
    local_expertise_score = 0.0
    
    if hasattr(self.case, 'jurisdiction') and self.case.jurisdiction:
        # Criar embedding para jurisdiÃ§Ã£o especÃ­fica
        jurisdiction_context = f"Especialista em processos de {self.case.jurisdiction}"
        jurisdiction_embedding, _ = await legal_embedding_service_v2.generate_legal_embedding(
            jurisdiction_context, "lawyer_cv"
        )
        
        # Calcular similaridade com perfil do advogado
        if hasattr(self.lawyer, 'cv_embedding_v2') and self.lawyer.cv_embedding_v2:
            local_expertise_score = legal_embedding_service_v2.get_similarity(
                jurisdiction_embedding, self.lawyer.cv_embedding_v2
            )
    
    # CombinaÃ§Ã£o: 70% distÃ¢ncia + 30% expertise local
    final_score = (0.7 * distance_score) + (0.3 * local_expertise_score)
    
    return np.clip(final_score, 0, 1)
```

---

## ğŸ¯ **SUGESTÃƒO 4: Sistema de Cache Inteligente para Embeddings**

### **Problema Atual**
- Gerar embeddings V2 em tempo real pode ser lento
- NÃ£o reutiliza embeddings similares jÃ¡ calculados
- NÃ£o otimiza para consultas frequentes

### **Melhoria Proposta: Cache HierÃ¡rquico**

```python
class SmartEmbeddingCache:
    """
    ğŸ†• Cache inteligente para embeddings V2 com mÃºltiplos nÃ­veis.
    
    NÃ­veis de cache:
    1. L1: Embeddings exatos (texto idÃªntico)
    2. L2: Embeddings similares (fuzzy matching)
    3. L3: Embeddings por contexto/categoria
    """
    
    def __init__(self):
        self.l1_cache = {}  # Cache exato
        self.l2_similarity_threshold = 0.95  # Threshold para cache fuzzy
        self.l3_context_cache = {}  # Cache por contexto jurÃ­dico
    
    async def get_or_generate_embedding(
        self, 
        text: str, 
        context: str, 
        force_refresh: bool = False
    ) -> Tuple[List[float], str, bool]:  # embedding, provider, from_cache
        
        # L1: Cache exato
        cache_key = hashlib.md5(f"{text}:{context}".encode()).hexdigest()
        if not force_refresh and cache_key in self.l1_cache:
            cached = self.l1_cache[cache_key]
            return cached["embedding"], cached["provider"], True
        
        # L2: Cache fuzzy (para textos muito similares)
        if not force_refresh:
            similar_embedding = await self._find_similar_cached_embedding(text, context)
            if similar_embedding:
                return similar_embedding["embedding"], similar_embedding["provider"], True
        
        # L3: Gerar novo embedding
        embedding, provider = await legal_embedding_service_v2.generate_legal_embedding(
            text, context
        )
        
        # Armazenar em cache
        self.l1_cache[cache_key] = {
            "embedding": embedding,
            "provider": provider,
            "text": text,
            "context": context,
            "timestamp": time.time()
        }
        
        # Limpar cache antigo se necessÃ¡rio
        await self._cleanup_old_cache_entries()
        
        return embedding, provider, False
    
    async def _find_similar_cached_embedding(
        self, 
        text: str, 
        context: str
    ) -> Optional[Dict]:
        """Busca embedding similar no cache L2."""
        
        # Criar embedding simples para comparaÃ§Ã£o (usando cache L3 se disponÃ­vel)
        text_embedding = await self._get_simple_text_embedding(text)
        
        for cache_entry in self.l1_cache.values():
            if cache_entry["context"] != context:
                continue
            
            # Comparar similaridade do texto
            cached_text_embedding = await self._get_simple_text_embedding(
                cache_entry["text"]
            )
            
            similarity = cosine_similarity(text_embedding, cached_text_embedding)
            
            if similarity >= self.l2_similarity_threshold:
                return cache_entry
        
        return None
    
    async def _get_simple_text_embedding(self, text: str) -> List[float]:
        """Gera embedding simples para comparaÃ§Ã£o de cache (usando sentence-transformers local)."""
        
        # Usar Arctic Embed L local para comparaÃ§Ãµes rÃ¡pidas
        from sentence_transformers import SentenceTransformer
        
        if not hasattr(self, '_local_model'):
            self._local_model = SentenceTransformer('Snowflake/snowflake-arctic-embed-l')
        
        return self._local_model.encode(text).tolist()
```

---

## ğŸ¯ **SUGESTÃƒO 5: AnÃ¡lise de Compatibilidade SemÃ¢ntica AvanÃ§ada**

### **Nova Feature: Compatibility Score**

```python
async def semantic_compatibility_score(self) -> Dict[str, float]:
    """
    ğŸ†• AnÃ¡lise avanÃ§ada de compatibilidade usando embeddings V2.
    
    Avalia mÃºltiplas dimensÃµes de compatibilidade:
    1. Compatibilidade tÃ©cnica (conhecimento especÃ­fico)
    2. Compatibilidade processual (experiÃªncia em procedimentos)
    3. Compatibilidade cultural (estilo de comunicaÃ§Ã£o)
    4. Compatibilidade estratÃ©gica (abordagem jurÃ­dica)
    
    Returns:
        Dict com scores detalhados de compatibilidade
    """
    results = {
        "technical_compatibility": 0.0,
        "procedural_compatibility": 0.0,
        "cultural_compatibility": 0.0,
        "strategic_compatibility": 0.0,
        "overall_compatibility": 0.0
    }
    
    # 1. Compatibilidade TÃ©cnica
    # Avaliar se o advogado tem conhecimento tÃ©cnico especÃ­fico para o caso
    case_technical_aspects = f"Conhecimento tÃ©cnico necessÃ¡rio: {self.case.summary}"
    lawyer_technical_profile = f"CompetÃªncias tÃ©cnicas: {' '.join(self.lawyer.tags_expertise or [])}"
    
    case_tech_emb, _ = await legal_embedding_service_v2.generate_legal_embedding(
        case_technical_aspects, "case"
    )
    lawyer_tech_emb, _ = await legal_embedding_service_v2.generate_legal_embedding(
        lawyer_technical_profile, "lawyer_cv"
    )
    
    results["technical_compatibility"] = legal_embedding_service_v2.get_similarity(
        case_tech_emb, lawyer_tech_emb
    )
    
    # 2. Compatibilidade Processual
    # Avaliar experiÃªncia em procedimentos similares
    if hasattr(self.case, 'procedimento') and self.case.procedimento:
        case_procedure = f"Procedimento: {self.case.procedimento}"
        
        # Buscar casos histÃ³ricos similares do advogado
        if hasattr(self.lawyer, 'casos_historicos') and self.lawyer.casos_historicos:
            procedure_similarities = []
            
            for caso_historico in self.lawyer.casos_historicos[-10:]:  # Ãšltimos 10 casos
                if hasattr(caso_historico, 'procedimento'):
                    hist_procedure = f"Procedimento: {caso_historico.procedimento}"
                    
                    case_proc_emb, _ = await legal_embedding_service_v2.generate_legal_embedding(
                        case_procedure, "precedent"
                    )
                    hist_proc_emb, _ = await legal_embedding_service_v2.generate_legal_embedding(
                        hist_procedure, "precedent"
                    )
                    
                    similarity = legal_embedding_service_v2.get_similarity(
                        case_proc_emb, hist_proc_emb
                    )
                    procedure_similarities.append(similarity)
            
            if procedure_similarities:
                results["procedural_compatibility"] = max(procedure_similarities)
    
    # 3. Compatibilidade Cultural/Comunicativa
    # Analisar estilo de comunicaÃ§Ã£o baseado em reviews e feedback
    if hasattr(self.lawyer, 'review_texts') and self.lawyer.review_texts:
        client_feedback = " ".join(self.lawyer.review_texts[-5:])  # Ãšltimos 5 reviews
        
        case_communication_need = f"Estilo de comunicaÃ§Ã£o para caso: {self.case.area}"
        
        case_comm_emb, _ = await legal_embedding_service_v2.generate_legal_embedding(
            case_communication_need, "case"
        )
        lawyer_comm_emb, _ = await legal_embedding_service_v2.generate_legal_embedding(
            client_feedback, "lawyer_cv"
        )
        
        results["cultural_compatibility"] = legal_embedding_service_v2.get_similarity(
            case_comm_emb, lawyer_comm_emb
        )
    
    # 4. Compatibilidade EstratÃ©gica
    # Analisar abordagem jurÃ­dica baseada em pareceres
    if hasattr(self.lawyer, 'pareceres') and self.lawyer.pareceres:
        strategic_approaches = []
        
        for parecer in self.lawyer.pareceres[-3:]:  # Ãšltimos 3 pareceres
            if hasattr(parecer, 'conteudo'):
                parecer_approach = f"Abordagem jurÃ­dica: {parecer.conteudo}"
                
                case_strategy_need = f"EstratÃ©gia necessÃ¡ria para: {self.case.summary}"
                
                case_strat_emb, _ = await legal_embedding_service_v2.generate_legal_embedding(
                    case_strategy_need, "case"
                )
                parecer_strat_emb, _ = await legal_embedding_service_v2.generate_legal_embedding(
                    parecer_approach, "legal_opinion"
                )
                
                similarity = legal_embedding_service_v2.get_similarity(
                    case_strat_emb, parecer_strat_emb
                )
                strategic_approaches.append(similarity)
        
        if strategic_approaches:
            results["strategic_compatibility"] = sum(strategic_approaches) / len(strategic_approaches)
    
    # 5. Score Geral de Compatibilidade (ponderado)
    weights = {
        "technical": 0.35,
        "procedural": 0.25,
        "cultural": 0.20,
        "strategic": 0.20
    }
    
    results["overall_compatibility"] = (
        weights["technical"] * results["technical_compatibility"] +
        weights["procedural"] * results["procedural_compatibility"] +
        weights["cultural"] * results["cultural_compatibility"] +
        weights["strategic"] * results["strategic_compatibility"]
    )
    
    return results
```

---

## ğŸ“Š **SUGESTÃƒO 6: MÃ©tricas e Observabilidade dos Embeddings**

### **Sistema de Monitoramento da Qualidade SemÃ¢ntica**

```python
class EmbeddingQualityMetrics:
    """
    ğŸ†• Sistema de mÃ©tricas para monitorar qualidade dos embeddings V2.
    
    Monitora:
    - DistribuiÃ§Ã£o de similaridades
    - Performance por contexto jurÃ­dico
    - Efetividade do cache
    - Qualidade das prediÃ§Ãµes
    """
    
    def __init__(self):
        self.metrics = {
            "similarity_distribution": [],
            "context_performance": {},
            "cache_hit_rate": 0.0,
            "prediction_accuracy": {}
        }
    
    async def track_similarity_score(
        self, 
        similarity: float, 
        context: str,
        case_outcome: Optional[str] = None
    ):
        """Rastreia scores de similaridade para anÃ¡lise."""
        
        self.metrics["similarity_distribution"].append({
            "similarity": similarity,
            "context": context,
            "timestamp": time.time(),
            "outcome": case_outcome
        })
        
        # Atualizar performance por contexto
        if context not in self.metrics["context_performance"]:
            self.metrics["context_performance"][context] = {
                "scores": [],
                "avg_similarity": 0.0,
                "std_similarity": 0.0
            }
        
        context_metrics = self.metrics["context_performance"][context]
        context_metrics["scores"].append(similarity)
        
        # Calcular estatÃ­sticas
        scores = context_metrics["scores"]
        context_metrics["avg_similarity"] = sum(scores) / len(scores)
        
        if len(scores) > 1:
            mean = context_metrics["avg_similarity"]
            variance = sum((x - mean) ** 2 for x in scores) / len(scores)
            context_metrics["std_similarity"] = math.sqrt(variance)
    
    def generate_quality_report(self) -> Dict[str, Any]:
        """Gera relatÃ³rio de qualidade dos embeddings."""
        
        report = {
            "summary": {
                "total_similarities": len(self.metrics["similarity_distribution"]),
                "avg_similarity": 0.0,
                "contexts_analyzed": len(self.metrics["context_performance"])
            },
            "context_breakdown": self.metrics["context_performance"],
            "recommendations": []
        }
        
        # Calcular mÃ©tricas gerais
        if self.metrics["similarity_distribution"]:
            similarities = [m["similarity"] for m in self.metrics["similarity_distribution"]]
            report["summary"]["avg_similarity"] = sum(similarities) / len(similarities)
        
        # Gerar recomendaÃ§Ãµes
        for context, metrics in self.metrics["context_performance"].items():
            avg_sim = metrics["avg_similarity"]
            
            if avg_sim < 0.3:
                report["recommendations"].append(
                    f"âš ï¸  Contexto '{context}' tem baixa similaridade mÃ©dia ({avg_sim:.3f}). "
                    f"Considere ajustar prompts ou revisar embeddings."
                )
            elif avg_sim > 0.8:
                report["recommendations"].append(
                    f"âœ… Contexto '{context}' tem alta similaridade mÃ©dia ({avg_sim:.3f}). "
                    f"Performance excelente!"
                )
        
        return report
```

---

## ğŸš€ **SUGESTÃƒO 7: IntegraÃ§Ã£o Completa no Algoritmo Principal**

### **AtualizaÃ§Ã£o da Classe FeatureCalculator**

```python
class EnhancedFeatureCalculator(FeatureCalculator):
    """
    ğŸ†• FeatureCalculator aprimorado com embeddings V2 especializados.
    
    Substitui gradualmente features bÃ¡sicas por versÃµes semÃ¢nticamente inteligentes.
    """
    
    def __init__(self, case: Case, lawyer: Lawyer, cv: dict):
        super().__init__(case, lawyer, cv)
        self.embedding_cache = SmartEmbeddingCache()
        self.quality_metrics = EmbeddingQualityMetrics()
        
        # Flag para habilitar features V2 gradualmente
        self.enable_v2_features = os.getenv("ENABLE_V2_FEATURES", "false").lower() == "true"
    
    async def calculate_all_features(self) -> Dict[str, float]:
        """
        Calcula todas as features com possÃ­vel upgrade para V2.
        
        EstratÃ©gia: Calcular features V1 e V2 em paralelo, usar flag para escolher.
        """
        
        # Features V1 (atuais)
        v1_features = super().calculate_all_features()
        
        if not self.enable_v2_features:
            return v1_features
        
        # Features V2 aprimoradas
        v2_features = await self._calculate_v2_features()
        
        # Mesclar features (V2 sobrescreve V1 quando disponÃ­vel)
        final_features = {**v1_features, **v2_features}
        
        # Rastrear mÃ©tricas de qualidade
        await self._track_feature_quality(v1_features, v2_features)
        
        return final_features
    
    async def _calculate_v2_features(self) -> Dict[str, float]:
        """Calcula features aprimoradas com embeddings V2."""
        
        features = {}
        
        # Paralelizar cÃ¡lculos de features V2
        tasks = [
            self.enhanced_academic_score(),
            self.enhanced_geo_score(),
            self.enhanced_semantic_similarity(),
            self.semantic_compatibility_score()
        ]
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Processar resultados
        if not isinstance(results[0], Exception):
            features["A"] = results[0]  # Academic V2
        
        if not isinstance(results[1], Exception):
            features["G"] = results[1]  # Geo V2
        
        if not isinstance(results[2], Exception):
            semantic_results = results[2]
            features["S"] = semantic_results["weighted_final"]  # Semantic V2
        
        if not isinstance(results[3], Exception):
            compatibility_results = results[3]
            features["C"] = compatibility_results["overall_compatibility"]  # Compatibility (nova)
        
        return features
    
    async def _track_feature_quality(
        self, 
        v1_features: Dict[str, float], 
        v2_features: Dict[str, float]
    ):
        """Rastreia qualidade e diferenÃ§as entre features V1 e V2."""
        
        for feature_name in v2_features:
            if feature_name in v1_features:
                v1_score = v1_features[feature_name]
                v2_score = v2_features[feature_name]
                
                # Rastrear diferenÃ§a para anÃ¡lise
                difference = abs(v2_score - v1_score)
                
                await self.quality_metrics.track_similarity_score(
                    similarity=v2_score,
                    context=f"feature_{feature_name}",
                    case_outcome=f"v1_diff_{difference:.3f}"
                )
```

---

## ğŸ“‹ **CRONOGRAMA DE IMPLEMENTAÃ‡ÃƒO SUGERIDO**

### **Fase 1: FundaÃ§Ã£o (Semana 1-2)**
1. âœ… Sistema V2 bÃ¡sico jÃ¡ implementado
2. ğŸ”„ Implementar `SmartEmbeddingCache` 
3. ğŸ”„ Implementar `EmbeddingQualityMetrics`

### **Fase 2: Features Core (Semana 3-4)**
1. ğŸ”„ Implementar `enhanced_semantic_similarity()`
2. ğŸ”„ Implementar peso adaptativo para similaridade
3. ğŸ”„ Atualizar `firm_reputation()` com nova lÃ³gica

### **Fase 3: Features AvanÃ§adas (Semana 5-6)**
1. ğŸ”„ Implementar `enhanced_academic_score()`
2. ğŸ”„ Implementar `enhanced_geo_score()`
3. ğŸ”„ Implementar `semantic_compatibility_score()`

### **Fase 4: IntegraÃ§Ã£o (Semana 7-8)**
1. ğŸ”„ Integrar `EnhancedFeatureCalculator`
2. ğŸ”„ Implementar sistema de A/B testing V1 vs V2
3. ğŸ”„ Deploy gradual com feature flags

### **Fase 5: OtimizaÃ§Ã£o (Semana 9-10)**
1. ğŸ”„ Otimizar performance do cache
2. ğŸ”„ Ajustar pesos baseado em mÃ©tricas reais
3. ğŸ”„ Documentar melhorias e ROI

---

## ğŸ¯ **IMPACTO ESPERADO DAS MELHORIAS**

### **MÃ©tricas de Sucesso**
- **PrecisÃ£o do Matching**: +40-50% (vs atual +35-40%)
- **SatisfaÃ§Ã£o do Cliente**: +25% (casos mais bem-matchados)
- **ReduÃ§Ã£o de Mal-matches**: -60% (vs atual -50%)
- **Tempo de Resposta**: Manter <2s com cache inteligente

### **BenefÃ­cios por Contexto JurÃ­dico**
- **Direito Empresarial**: +50% precisÃ£o (alta complexidade tÃ©cnica)
- **Direito Trabalhista**: +45% precisÃ£o (procedimentos padronizados)
- **Direito Civil**: +35% precisÃ£o (casos diversos)
- **Direito Criminal**: +40% precisÃ£o (especializaÃ§Ã£o crÃ­tica)

---

## ğŸ”§ **CONFIGURAÃ‡ÃƒO E FEATURE FLAGS**

```bash
# .env - ConfiguraÃ§Ãµes para controle gradual
ENABLE_V2_FEATURES=false                    # Feature flag principal
ENABLE_SEMANTIC_CACHE=true                  # Cache inteligente
ENABLE_ADAPTIVE_WEIGHTS=false               # Pesos adaptativos
ENABLE_COMPATIBILITY_ANALYSIS=false         # AnÃ¡lise de compatibilidade

# ConfiguraÃ§Ãµes de performance
EMBEDDING_CACHE_TTL_HOURS=24               # TTL do cache
EMBEDDING_SIMILARITY_THRESHOLD=0.95        # Threshold para cache fuzzy
SEMANTIC_WEIGHT_MIN=0.2                    # Peso mÃ­nimo semÃ¢ntico
SEMANTIC_WEIGHT_MAX=0.8                    # Peso mÃ¡ximo semÃ¢ntico

# MÃ©tricas e observabilidade
ENABLE_EMBEDDING_METRICS=true              # Rastreamento de qualidade
METRICS_EXPORT_INTERVAL_MINUTES=60         # Intervalo de export de mÃ©tricas
```

---

**CONCLUSÃƒO**: Essas melhorias aproveitam completamente o potencial dos embeddings V2 1024D especializados, transformando o algoritmo de um sistema de matching bÃ¡sico em uma plataforma de inteligÃªncia jurÃ­dica avanÃ§ada. A implementaÃ§Ã£o gradual com feature flags permite deployment seguro e otimizaÃ§Ã£o contÃ­nua baseada em dados reais.
 
 