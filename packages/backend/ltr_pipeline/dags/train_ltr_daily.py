from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.operators.bash import BashOperator
from airflow.operators.email import EmailOperator
from airflow.models import Variable
from airflow.utils.trigger_rule import TriggerRule
from datetime import datetime, timedelta
import sys, pathlib
import os

BASE = pathlib.Path(__file__).resolve().parents[2] / "src"
sys.path.append(str(BASE))

from etl import extract_raw_parquet
from preprocess import build_matrix
from train import train_lgbm
from evaluate import eval_lgbm
from registry import publish_model

# ‚ö° CHAVE 2: Configura√ß√£o para automa√ß√£o completa
default_args = {
    "owner": "mlops",
    "depends_on_past": False,
    "email": ["ml-alerts@litgo.com"],
    "email_on_failure": True,
    "email_on_retry": False,
    "retries": 2,
    "retry_delay": timedelta(minutes=15),
    "execution_timeout": timedelta(hours=2),
}

# ‚ö° CHAVE 2: Gate de qualidade configur√°vel via Airflow Variables
QUALITY_GATE_NDCG_MIN = float(Variable.get("ltr_ndcg_min", 0.65))
QUALITY_GATE_FAIRNESS_MAX = float(Variable.get("ltr_fairness_max", 0.05))
MINIMUM_TRAINING_SAMPLES = int(Variable.get("ltr_min_samples", 100))

def quality_gate_check():
    """
    ‚ö° CHAVE 2: Gate de qualidade autom√°tico.
    
    Verifica se o modelo atende crit√©rios m√≠nimos:
    - nDCG@5 >= threshold
    - Fair-Gap <= threshold  
    - Lat√™ncia p95 < 15ms
    - Amostras de treino >= m√≠nimo
    """
    import json
    from pathlib import Path
    
    # Carregar m√©tricas do evaluate
    metrics_file = Path("packages/backend/ltr_pipeline/data/processed/evaluation_metrics.json")
    
    if not metrics_file.exists():
        raise Exception("‚ùå Arquivo de m√©tricas n√£o encontrado")
    
    with open(metrics_file, 'r') as f:
        metrics = json.load(f)
    
    # Verifica√ß√µes do gate de qualidade
    ndcg = metrics.get("ndcg_at_5", 0.0)
    fairness_gap = metrics.get("fairness_gap", 1.0)
    latency_p95 = metrics.get("latency_p95_ms", 999)
    training_samples = metrics.get("training_samples", 0)
    
    print(f"üìä M√©tricas do modelo:")
    print(f"   nDCG@5: {ndcg:.3f} (min: {QUALITY_GATE_NDCG_MIN})")
    print(f"   Fair-Gap: {fairness_gap:.3f} (max: {QUALITY_GATE_FAIRNESS_MAX})")
    print(f"   Lat√™ncia p95: {latency_p95:.1f}ms (max: 15ms)")
    print(f"   Amostras: {training_samples} (min: {MINIMUM_TRAINING_SAMPLES})")
    
    # Valida√ß√µes
    if ndcg < QUALITY_GATE_NDCG_MIN:
        raise Exception(f"‚ùå nDCG muito baixo: {ndcg:.3f} < {QUALITY_GATE_NDCG_MIN}")
    
    if fairness_gap > QUALITY_GATE_FAIRNESS_MAX:
        raise Exception(f"‚ùå Fairness gap muito alto: {fairness_gap:.3f} > {QUALITY_GATE_FAIRNESS_MAX}")
    
    if latency_p95 > 15:
        raise Exception(f"‚ùå Lat√™ncia muito alta: {latency_p95:.1f}ms > 15ms")
    
    if training_samples < MINIMUM_TRAINING_SAMPLES:
        raise Exception(f"‚ùå Poucas amostras: {training_samples} < {MINIMUM_TRAINING_SAMPLES}")
    
    print("‚úÖ Todas as verifica√ß√µes de qualidade passaram!")
    return True

def notify_success():
    """Notifica sucesso do pipeline LTR."""
    print("üéâ Pipeline LTR executado com sucesso!")
    print("üìà Novo modelo foi promovido para produ√ß√£o")
    
    # Aqui voc√™ pode adicionar webhooks, Slack, etc.
    # slack_webhook = Variable.get("slack_webhook", None)
    # if slack_webhook:
    #     send_slack_notification(slack_webhook, "‚úÖ LTR Pipeline conclu√≠do")

def handle_failure():
    """Lida com falhas do pipeline."""
    print("‚ùå Pipeline LTR falhou - modelo anterior mantido")
    
    # Log para an√°lise
    import logging
    logging.error("LTR Pipeline failure - previous model retained")

# ‚ö° CHAVE 2: DAG com automa√ß√£o completa
with DAG(
    dag_id="train_ltr_daily",
    description="üöÄ Pipeline LTR 100% Automatizado com Gate de Qualidade",
    start_date=datetime(2025, 1, 15),
    schedule_interval="15 2 * * *",  # 02:15 UTC di√°rio
    catchup=False,
    default_args=default_args,
    tags=["ltr", "ml", "automated"],
    max_active_runs=1,  # Evitar sobreposi√ß√£o
) as dag:

    # Task Group: Extra√ß√£o e Prepara√ß√£o
    extract_task = PythonOperator(
        task_id="extract_events",
        python_callable=extract_raw_parquet,
        doc_md="üîç Extrai eventos do Kafka (primary) ou arquivo local (fallback)"
    )
    
    preprocess_task = PythonOperator(
        task_id="preprocess_data", 
        python_callable=build_matrix,
        doc_md="üîÑ Transforma dados brutos em matriz de treinamento"
    )
    
    # Task Group: Treinamento e Avalia√ß√£o
    train_task = PythonOperator(
        task_id="train_model",
        python_callable=train_lgbm,
        doc_md="üß† Treina modelo LightGBM LambdaMART"
    )
    
    evaluate_task = PythonOperator(
        task_id="evaluate_model",
        python_callable=eval_lgbm,
        doc_md="üìä Avalia modelo: nDCG, MRR, fairness, lat√™ncia"
    )
    
    # ‚ö° CHAVE 2: Gate de Qualidade Autom√°tico
    quality_gate = PythonOperator(
        task_id="quality_gate",
        python_callable=quality_gate_check,
        doc_md="üö™ Gate de qualidade: valida m√©tricas antes da publica√ß√£o"
    )
    
    # ‚ö° CHAVE 3: Publica√ß√£o Versionada
    publish_task = PythonOperator(
        task_id="publish_model",
        python_callable=publish_model,
        trigger_rule=TriggerRule.ALL_SUCCESS,
        doc_md="üì¶ Publica pesos versionados local + S3"
    )
    
    # ‚ö° CHAVE 4: Trigger para recarga autom√°tica
    trigger_reload = BashOperator(
        task_id="trigger_weight_reload",
        bash_command="""
        # Notifica FastAPI para recarregar pesos (background task detectar√° mudan√ßa)
        echo "‚úÖ Pesos publicados - background task detectar√° mudan√ßa automaticamente"
        echo "üîÑ Polling configurado para $(echo ${WEIGHTS_POLL_SECONDS:-300})s"
        
        # Opcional: webhook para for√ßar reload imediato
        if [ -n "$FASTAPI_RELOAD_WEBHOOK" ]; then
            curl -f -X POST "$FASTAPI_RELOAD_WEBHOOK" || true
        fi
        """,
        trigger_rule=TriggerRule.ALL_SUCCESS
    )
    
    # Notifica√ß√µes
    success_notification = PythonOperator(
        task_id="notify_success",
        python_callable=notify_success,
        trigger_rule=TriggerRule.ALL_SUCCESS
    )
    
    failure_notification = PythonOperator(
        task_id="handle_failure", 
        python_callable=handle_failure,
        trigger_rule=TriggerRule.ONE_FAILED
    )
    
    # ‚ö° Fluxo automatizado completo
    extract_task >> preprocess_task >> train_task >> evaluate_task
    evaluate_task >> quality_gate >> publish_task >> trigger_reload >> success_notification
    
    # Lidar com falhas em qualquer ponto
    [extract_task, preprocess_task, train_task, evaluate_task, quality_gate, publish_task] >> failure_notification 