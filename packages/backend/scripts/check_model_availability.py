#!/usr/bin/env python3
"""
Script de Verifica√ß√£o de Disponibilidade de Modelos - LITIG-1
=============================================================

Verifica se todos os IDs de modelo do plano de evolu√ß√£o est√£o dispon√≠veis
e funcionando corretamente no OpenRouter.

Baseado em: PLANO_EVOLUCAO_COMPLETO_OPENROUTER_LANGGRAPH.md
"""

import asyncio
import json
import os
import sys
from typing import Dict, List, Tuple
import time

# Adicionar o diret√≥rio pai ao path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

try:
    import openai
    from config import Settings
except ImportError as e:
    print(f"‚ùå Erro de importa√ß√£o: {e}")
    print("Execute: pip3 install --break-system-packages openai python-dotenv")
    sys.exit(1)

class ModelAvailabilityChecker:
    """Verificador de disponibilidade de modelos conforme plano de evolu√ß√£o."""
    
    def __init__(self):
        self.settings = Settings()
        
        # IDs de modelos conforme PLANO_EVOLUCAO_COMPLETO (Julho 2025)
        self.models_to_check = {
            "gemini_25_pro": {
                "id": "google/gemini-2.5-pro",
                "service": "Lawyer Profile Analysis + Partnership Enhancement",
                "cost_input": 1.25,
                "cost_output": 10.0,
                "context": "1M tokens"
            },
            "claude_sonnet_4": {
                "id": "anthropic/claude-sonnet-4", 
                "service": "Case Context Analysis",
                "cost_input": 3.0,
                "cost_output": 15.0,
                "context": "200k tokens"
            },
            "grok_4": {
                "id": "x-ai/grok-4",
                "service": "LEX-9000 + Cluster Labeling", 
                "cost_input": 3.0,
                "cost_output": 15.0,
                "context": "256k tokens"
            },
            "gpt_41_mini": {
                "id": "openai/gpt-4.1-mini",
                "service": "OCR Validation",
                "cost_input": 0.40,
                "cost_output": 1.60,
                "context": "1M tokens"
            },
            "openrouter_auto": {
                "id": "openrouter/auto",
                "service": "Fallback Autom√°tico (N√≠vel 2)",
                "cost_input": "vari√°vel",
                "cost_output": "vari√°vel"
            }
        }
        
        # Inicializar clientes
        self.openrouter_client = None
        self.direct_clients = {}
        self._init_clients()
    
    def _init_clients(self):
        """Inicializa clientes OpenRouter e diretos."""
        
        # Cliente OpenRouter
        if self.settings.OPENROUTER_API_KEY:
            self.openrouter_client = openai.AsyncOpenAI(
                base_url="https://openrouter.ai/api/v1",
                api_key=self.settings.OPENROUTER_API_KEY,
                default_headers={
                    "HTTP-Referer": "https://litig-1.com",
                    "X-Title": "LITIG-1"
                }
            )
            print("üåê Cliente OpenRouter inicializado")
        else:
            print("‚ö†Ô∏è OPENROUTER_API_KEY n√£o configurada")
        
        # Clientes diretos para fallback (N√≠veis 3-4)
        if self.settings.GEMINI_API_KEY:
            print("‚úÖ GEMINI_API_KEY configurada")
            # Cliente direto seria inicializado aqui
        
        if self.settings.ANTHROPIC_API_KEY:
            print("‚úÖ ANTHROPIC_API_KEY configurada")
        else:
            print("‚ö†Ô∏è ANTHROPIC_API_KEY n√£o configurada")
        
        if self.settings.OPENAI_API_KEY:
            print("‚úÖ OPENAI_API_KEY configurada")
        else:
            print("‚ö†Ô∏è OPENAI_API_KEY n√£o configurada")
    
    async def check_model_availability(self, model_key: str, model_info: Dict) -> Dict:
        """Verifica se um modelo espec√≠fico est√° dispon√≠vel."""
        
        model_id = model_info["id"]
        start_time = time.time()
        
        result = {
            "model_key": model_key,
            "model_id": model_id,
            "service": model_info["service"],
            "available": False,
            "response_time_ms": 0,
            "error": None,
            "test_response": None
        }
        
        if not self.openrouter_client:
            result["error"] = "Cliente OpenRouter n√£o inicializado"
            return result
        
        try:
            # Teste b√°sico com prompt m√≠nimo
            test_messages = [
                {
                    "role": "user", 
                    "content": "Responda apenas: OK"
                }
            ]
            
            # Headers especiais para Claude 4
            kwargs = {"max_tokens": 10}
            if "headers" in model_info:
                kwargs["extra_headers"] = model_info["headers"]
            
            response = await asyncio.wait_for(
                self.openrouter_client.chat.completions.create(
                    model=model_id,
                    messages=test_messages,
                    **kwargs
                ),
                timeout=30
            )
            
            response_time = int((time.time() - start_time) * 1000)
            
            result.update({
                "available": True,
                "response_time_ms": response_time,
                "test_response": response.choices[0].message.content[:50]
            })
            
            print(f"‚úÖ {model_key} ({model_id}) - DISPON√çVEL ({response_time}ms)")
            
        except asyncio.TimeoutError:
            result["error"] = "Timeout (>30s)"
            print(f"‚è±Ô∏è {model_key} ({model_id}) - TIMEOUT")
            
        except Exception as e:
            result["error"] = str(e)
            print(f"‚ùå {model_key} ({model_id}) - ERRO: {e}")
        
        return result
    
    async def test_function_calling(self, model_key: str, model_info: Dict) -> Dict:
        """Testa Function Calling em um modelo espec√≠fico."""
        
        if not self.openrouter_client:
            return {"error": "Cliente n√£o inicializado"}
        
        # Tool de teste simples
        test_tool = {
            "type": "function",
            "function": {
                "name": "extract_test_data",
                "description": "Extract simple test data",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "status": {
                            "type": "string",
                            "enum": ["success", "failure"],
                            "description": "Test status"
                        },
                        "confidence": {
                            "type": "number",
                            "minimum": 0,
                            "maximum": 1,
                            "description": "Confidence score"
                        }
                    },
                    "required": ["status", "confidence"]
                }
            }
        }
        
        result = {
            "model_key": model_key,
            "function_calling_supported": False,
            "error": None,
            "parsed_result": None
        }
        
        try:
            model_id = model_info["id"]
            
            # Headers especiais para Claude 4
            kwargs = {"max_tokens": 100}
            if "headers" in model_info:
                kwargs["extra_headers"] = model_info["headers"]
            
            response = await asyncio.wait_for(
                self.openrouter_client.chat.completions.create(
                    model=model_id,
                    messages=[{
                        "role": "user", 
                        "content": "Use the function to return status='success' and confidence=0.95"
                    }],
                    tools=[test_tool],
                    tool_choice={"type": "function", "function": {"name": "extract_test_data"}},
                    **kwargs
                ),
                timeout=30
            )
            
            # Verificar se retornou function call
            if response.choices[0].message.tool_calls:
                tool_call = response.choices[0].message.tool_calls[0]
                parsed_args = json.loads(tool_call.function.arguments)
                
                result.update({
                    "function_calling_supported": True,
                    "parsed_result": parsed_args
                })
                
                print(f"üõ†Ô∏è {model_key} - Function Calling OK: {parsed_args}")
            else:
                result["error"] = "N√£o retornou function call"
                print(f"‚ùå {model_key} - Function Calling FALHOU")
                
        except Exception as e:
            result["error"] = str(e)
            print(f"‚ùå {model_key} - Function Calling ERRO: {e}")
        
        return result
    
    async def check_all_models(self) -> Dict:
        """Verifica todos os modelos do plano."""
        
        print("üî¨ VERIFICA√á√ÉO DE MODELOS - PLANO DE EVOLU√á√ÉO LITIG-1")
        print("=" * 60)
        print("Verificando disponibilidade conforme PLANO_EVOLUCAO_COMPLETO_OPENROUTER_LANGGRAPH.md")
        print("")
        
        availability_results = []
        function_calling_results = []
        
        # Testar disponibilidade b√°sica
        print("üì° TESTANDO DISPONIBILIDADE B√ÅSICA...")
        print("-" * 40)
        
        for model_key, model_info in self.models_to_check.items():
            result = await self.check_model_availability(model_key, model_info)
            availability_results.append(result)
            
            # Pequena pausa entre testes
            await asyncio.sleep(1)
        
        print("")
        
        # Testar Function Calling nos modelos dispon√≠veis
        print("üõ†Ô∏è TESTANDO FUNCTION CALLING...")
        print("-" * 40)
        
        available_models = [r for r in availability_results if r["available"]]
        
        for result in available_models:
            if result["model_key"] != "openrouter_auto":  # Auto n√£o precisa de function calling
                model_info = self.models_to_check[result["model_key"]]
                fc_result = await self.test_function_calling(result["model_key"], model_info)
                function_calling_results.append(fc_result)
                
                await asyncio.sleep(1)
        
        return {
            "timestamp": time.time(),
            "availability_results": availability_results,
            "function_calling_results": function_calling_results,
            "summary": self._generate_summary(availability_results, function_calling_results)
        }
    
    def _generate_summary(self, availability_results: List, function_calling_results: List) -> Dict:
        """Gera resumo dos testes."""
        
        total_models = len(availability_results)
        available_models = len([r for r in availability_results if r["available"]])
        
        total_fc_tests = len(function_calling_results)
        working_fc = len([r for r in function_calling_results if r["function_calling_supported"]])
        
        # Calcular score de sa√∫de
        availability_score = (available_models / total_models) * 100
        fc_score = (working_fc / total_fc_tests) * 100 if total_fc_tests > 0 else 0
        overall_score = (availability_score + fc_score) / 2
        
        return {
            "availability": {
                "total": total_models,
                "available": available_models,
                "percentage": availability_score
            },
            "function_calling": {
                "total": total_fc_tests,
                "working": working_fc,
                "percentage": fc_score
            },
            "overall_health_score": overall_score,
            "status": "excellent" if overall_score >= 90 else "good" if overall_score >= 70 else "needs_attention"
        }
    
    async def generate_report(self, results: Dict):
        """Gera relat√≥rio final formatado."""
        
        print("\n" + "=" * 60)
        print("üìä RELAT√ìRIO FINAL DE VERIFICA√á√ÉO")
        print("=" * 60)
        
        summary = results["summary"]
        
        print(f"\nüéØ SCORE GERAL DE SA√öDE: {summary['overall_health_score']:.1f}%")
        print(f"üì∂ Status: {summary['status'].upper()}")
        
        print(f"\nüì° DISPONIBILIDADE DE MODELOS:")
        print(f"   ‚úÖ Dispon√≠veis: {summary['availability']['available']}/{summary['availability']['total']}")
        print(f"   üìä Taxa: {summary['availability']['percentage']:.1f}%")
        
        print(f"\nüõ†Ô∏è FUNCTION CALLING:")
        print(f"   ‚úÖ Funcionando: {summary['function_calling']['working']}/{summary['function_calling']['total']}")
        print(f"   üìä Taxa: {summary['function_calling']['percentage']:.1f}%")
        
        print(f"\nüìã DETALHES POR MODELO:")
        for result in results["availability_results"]:
            status = "‚úÖ" if result["available"] else "‚ùå"
            print(f"   {status} {result['model_key']} - {result['service']}")
            if result["error"]:
                print(f"      ‚ö†Ô∏è Erro: {result['error']}")
        
        print(f"\nüîß RECOMENDA√á√ïES:")
        
        if summary["overall_health_score"] >= 90:
            print("   üöÄ Sistema pronto para migra√ß√£o!")
            print("   ‚úÖ Todos os modelos funcionando conforme esperado")
        elif summary["overall_health_score"] >= 70:
            print("   ‚ö†Ô∏è Sistema funcional, mas com algumas limita√ß√µes")
            print("   üîß Verificar modelos com falha antes da migra√ß√£o")
        else:
            print("   üö® Sistema requer aten√ß√£o antes da migra√ß√£o")
            print("   ‚ùå M√∫ltiplos modelos indispon√≠veis")
        
        # Verificar configura√ß√µes espec√≠ficas
        if not self.settings.OPENROUTER_API_KEY:
            print("   üîë Configure OPENROUTER_API_KEY no .env")
        
        if not self.settings.ANTHROPIC_API_KEY:
            print("   üîë Configure ANTHROPIC_API_KEY para fallback direto")
        
        if not self.settings.OPENAI_API_KEY:
            print("   üîë Configure OPENAI_API_KEY para fallback direto")

async def main():
    """Fun√ß√£o principal."""
    checker = ModelAvailabilityChecker()
    
    try:
        results = await checker.check_all_models()
        await checker.generate_report(results)
        
        # Salvar relat√≥rio em arquivo
        timestamp = int(time.time())
        report_file = f"model_availability_report_{timestamp}.json"
        
        with open(report_file, "w") as f:
            json.dump(results, f, indent=2)
        
        print(f"\nüíæ Relat√≥rio salvo em: {report_file}")
        
        return 0 if results["summary"]["overall_health_score"] >= 70 else 1
        
    except Exception as e:
        print(f"\n‚ùå Erro durante verifica√ß√£o: {str(e)}")
        return 1

if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code) 
 