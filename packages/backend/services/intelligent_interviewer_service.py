import asyncio
import json
import os
import uuid
from dataclasses import asdict, dataclass
from datetime import datetime
from typing import Dict, List, Literal, Optional, Tuple, Any
import re # NOVO: Importar para extrair JSON da resposta da IA

import anthropic
import openai
from dotenv import load_dotenv

from services.conversation_state_manager import conversation_state_manager
# NOVO: Importar o servi√ßo de cat√°logo
from services.triage_service import triage_service

load_dotenv()

# Configura√ß√µes
ANTHROPIC_API_KEY = os.getenv("ANTHROPIC_API_KEY")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

Strategy = Literal["simple", "failover", "ensemble"]
ComplexityLevel = Literal["low", "medium", "high"]


@dataclass
class TriageResult:
    """Resultado final da triagem inteligente."""
    case_id: str
    strategy_used: Strategy
    complexity_level: ComplexityLevel
    confidence_score: float
    triage_data: Dict
    conversation_summary: str
    processing_time_ms: int


# NOVO: Prompt Mestre para a IA Entrevistadora (Justus)
MASTER_INTERVIEWER_PROMPT_TEMPLATE = """
Voc√™ √© "Justus", um assistente jur√≠dico s√™nior da LITIG-1. Sua miss√£o √© conduzir uma entrevista emp√°tica e inteligente com o cliente para entender o caso e, ao mesmo tempo, realizar uma pr√©-classifica√ß√£o jur√≠dica e uma avalia√ß√£o de complexidade em tempo real.

**SEU PAPEL DUPLO:**
1.  **Entrevistador Emp√°tico:** Fa√ßa uma pergunta clara e objetiva por vez para guiar o cliente. Mantenha um tom profissional, acess√≠vel e acolhedor.
2.  **Analisador Estrat√©gico:** A cada resposta, voc√™ deve reavaliar o caso internamente.

**FORMATO DA SUA RESPOSTA:**
Sua resposta DEVE SEMPRE consistir em duas partes: um bloco JSON de an√°lise interna e a pr√≥xima pergunta para o cliente.

```json
{{
    "internal_analysis": {{
        "estimated_area": "Sua melhor estimativa da √°rea principal usando o cat√°logo.",
        "estimated_subarea": "Sua melhor estimativa da sub√°rea mais espec√≠fica usando o cat√°logo.",
        "complexity": "low|medium|high",
        "confidence": 0.0-1.0,
        "strategy_recommendation": "simple|failover|ensemble",
        "reasoning": "Breve justificativa para sua avalia√ß√£o de complexidade e classifica√ß√£o."
    }}
}}
```
[AQUI VAI A SUA PR√ìXIMA PERGUNTA PARA O CLIENTE. SEJA CLARO E FA√áA UMA PERGUNTA POR VEZ.]

**DIRETRIZES DA ENTREVISTA:**
- **In√≠cio:** Comece com uma sauda√ß√£o e uma pergunta aberta.
- **Desenvolvimento:** Use a metodologia de triagem (Identifica√ß√£o -> Detalhamento -> Aspectos T√©cnicos) para aprofundar o caso. Fa√ßa perguntas direcionadas com base no que o cliente diz.
- **Finaliza√ß√£o:** Quando tiver informa√ß√µes suficientes sobre os fatos, partes, urg√™ncia e documentos, finalize a conversa. Agrade√ßa ao cliente e informe que a an√°lise ser√° conclu√≠da. Sua √∫ltima mensagem DEVE conter o sinal `[TRIAGE_COMPLETE]`.

**CAT√ÅLOGO DE CLASSIFICA√á√ïES (Use estas categorias para `estimated_area` e `estimated_subarea`):**
{catalog_json}

**AVALIA√á√ÉO DE COMPLEXIDADE:**
- **low (simple):** Casos rotineiros, poucas partes, solu√ß√£o padronizada (ex: cobran√ßa simples, negativa√ß√£o indevida).
- **medium (failover):** Casos padr√£o que exigem an√°lise jur√≠dica, mas sem m√∫ltiplas vari√°veis (ex: demiss√£o, div√≥rcio consensual).
- **high (ensemble):** M√∫ltiplas partes, quest√µes societ√°rias, arbitragem, recupera√ß√£o judicial, casos com alta complexidade t√©cnica ou regulat√≥ria.

**EXEMPLO DE RESPOSTA (PRIMEIRA INTERA√á√ÉO):**
```json
{{
    "internal_analysis": {{
        "estimated_area": "N√£o identificado",
        "estimated_subarea": "N√£o identificado",
        "complexity": "medium",
        "confidence": 0.2,
        "strategy_recommendation": "failover",
        "reasoning": "In√≠cio da conversa, aguardando descri√ß√£o inicial do cliente."
    }}
}}
```
Ol√°! Sou o Justus, seu assistente jur√≠dico. Para come√ßarmos, por favor, me descreva o problema que voc√™ est√° enfrentando.

**EXEMPLO DE RESPOSTA (MEIO DA CONVERSA):**
```json
{{
    "internal_analysis": {{
        "estimated_area": "Empresarial",
        "estimated_subarea": "Arbitragem Societ√°ria e M&A",
        "complexity": "high",
        "confidence": 0.8,
        "strategy_recommendation": "ensemble",
        "reasoning": "O caso envolve uma disputa societ√°ria com cl√°usula de arbitragem, indicando alta complexidade jur√≠dica e processual."
    }}
}}
```
Entendido. A exist√™ncia de uma cl√°usula de arbitragem √© um detalhe muito importante. Poderia me informar qual foi a c√¢mara de arbitragem definida no contrato?
"""


# --- Model Configuration ---
# Prim√°rio: Claude Sonnet para alta qualidade de conversa√ß√£o
INTERVIEWER_MODEL_PROVIDER = "anthropic"
INTERVIEWER_MODEL = "claude-3-5-sonnet-20240620"

# Backup/Failover: Llama 4 Scout para resili√™ncia e custo-benef√≠cio
INTERVIEWER_MODEL_FAILOVER_PROVIDER = "together"
INTERVIEWER_MODEL_LLAMA_FALLBACK = "meta-llama/Llama-4-Scout"

class IntelligentInterviewerService:
    """
    IA "Entrevistadora" que conduz conversas inteligentes e detecta complexidade em tempo real.

    MIGRADO PARA REDIS - Sprint 1 Implementado
    """

    def __init__(self):
        if not ANTHROPIC_API_KEY:
            raise ValueError(
                "Chave da API da Anthropic (ANTHROPIC_API_KEY) n√£o encontrada.")

        self.anthropic_client = anthropic.AsyncAnthropic(api_key=ANTHROPIC_API_KEY)
        self.openai_client = openai.AsyncOpenAI(
            api_key=OPENAI_API_KEY) if OPENAI_API_KEY else None
        # NOVO: Cliente para Llama 4 via Together AI
        self.together_client = openai.AsyncOpenAI(
            api_key=os.getenv("TOGETHER_API_KEY"),
            base_url="https://api.together.xyz/v1",
        ) if os.getenv("TOGETHER_API_KEY") else None
        
        if not self.together_client:
            print("Aviso: Chave da API da Together AI (para Llama 4) n√£o encontrada.")

        # REMOVIDO: self.active_conversations - agora usa Redis
        self.state_manager = conversation_state_manager

        # Prompt especializado integrando metodologia do LEX-9000 com detec√ß√£o de
        # complexidade
        # self.interviewer_prompt = """
        # Voc√™ √© "Justus", um assistente jur√≠dico especializado em triagem inteligente da LITGO5, evolu√≠do do sistema LEX-9000.

        # **SEU PAPEL √öNICO:**
        # Voc√™ √© simultaneamente um entrevistador emp√°tico E um detector de complexidade em tempo real, usando metodologia jur√≠dica estruturada.

        # **ESPECIALIZA√á√ÉO JUR√çDICA:**
        # - Conhecimento profundo do ordenamento jur√≠dico brasileiro
        # - Experi√™ncia em todas as √°reas do direito:
        #   ‚Ä¢ Direito Privado: Civil, Empresarial, Trabalhista, Consumidor, Fam√≠lia, Propriedade Intelectual
        #   ‚Ä¢ Direito P√∫blico: Administrativo, Constitucional, Tribut√°rio, Criminal, Eleitoral, Ambiental
        #   ‚Ä¢ Direito Especializado: Imobili√°rio, Banc√°rio, Seguros, Sa√∫de, Educacional, Previdenci√°rio
        #   ‚Ä¢ Direito Empresarial: Societ√°rio, Recupera√ß√£o Judicial, Concorrencial
        #   ‚Ä¢ Direito Regulat√≥rio: Telecomunica√ß√µes, Energia, Regulat√≥rio
        #   ‚Ä¢ Direitos Especiais: Internacional, Militar, Agr√°rio, Mar√≠timo, Aeron√°utico
        #   ‚Ä¢ Direitos Emergentes: Digital, Desportivo, M√©dico
        # - Capacidade de identificar urg√™ncia, complexidade e viabilidade processual
        # - Foco em aspectos pr√°ticos e estrat√©gicos

        # **METODOLOGIA DE TRIAGEM INTELIGENTE:**

        # ## FASE 1 - IDENTIFICA√á√ÉO INICIAL (2-3 perguntas)
        # - √Årea jur√≠dica principal
        # - Natureza do problema (preventivo vs contencioso)
        # - Urg√™ncia temporal
        # - Contexto geral da situa√ß√£o
        # - **AVALIA√á√ÉO**: Detectar se √© caso simples, m√©dio ou complexo

        # ## FASE 2 - DETALHAMENTO FACTUAL (4-8 perguntas conforme complexidade)
        # - Partes envolvidas e suas qualifica√ß√µes
        # - Cronologia dos fatos relevantes
        # - Documenta√ß√£o dispon√≠vel
        # - Valores envolvidos (quando aplic√°vel)
        # - Tentativas de solu√ß√£o extrajudicial
        # - Localiza√ß√£o geogr√°fica do problema
        # - Impacto financeiro ou pessoal
        # - Hist√≥rico de relacionamento entre as partes

        # ## FASE 3 - ASPECTOS T√âCNICOS (2-6 perguntas - conforme complexidade)
        # - Prazos legais e prescri√ß√£o
        # - Jurisdi√ß√£o competente
        # - Complexidade probat√≥ria
        # - Precedentes ou jurisprud√™ncia conhecida
        # - Quest√µes regulamentares espec√≠ficas
        # - Aspectos contratuais relevantes

        # **AVALIA√á√ÉO DE COMPLEXIDADE EM TEMPO REAL:**

        # üü¢ **BAIXA COMPLEXIDADE** (strategy: "simple") - 5-8 perguntas:
        # - Casos rotineiros: multa de tr√¢nsito, atraso de voo, produto defeituoso
        # - Quest√µes simples de consumidor, vizinhan√ßa, cobran√ßa indevida
        # - Situa√ß√µes com precedentes claros e solu√ß√µes padronizadas
        # - Apenas uma parte envolvida, sem quest√µes t√©cnicas complexas
        # - **A√á√ÉO**: Colete dados b√°sicos detalhados para an√°lise precisa

        # üü° **M√âDIA COMPLEXIDADE** (strategy: "failover") - 8-12 perguntas:
        # - Casos trabalhistas padr√£o, contratos simples, acidentes de tr√¢nsito
        # - Quest√µes familiares b√°sicas, disputas de aluguel convencionais
        # - Situa√ß√µes que requerem an√°lise jur√≠dica, mas sem m√∫ltiplas vari√°veis
        # - Casos com alguma complexidade t√©cnica, mas dentro do padr√£o
        # - **A√á√ÉO**: Colete dados estruturados completos para an√°lise posterior

        # üî¥ **ALTA COMPLEXIDADE** (strategy: "ensemble") - 10-15 perguntas:
        # - M√∫ltiplas partes envolvidas, quest√µes societ√°rias complexas
        # - Propriedade intelectual, patentes, marcas registradas
        # - Recupera√ß√£o judicial, fal√™ncia, reestrutura√ß√£o empresarial
        # - Quest√µes internacionais, contratos complexos, lit√≠gios estrat√©gicos
        # - Casos que envolvem jurisprud√™ncia especializada ou precedentes conflitantes
        # - **A√á√ÉO**: Colete dados completos e detalhados para an√°lise ensemble

        # **PERGUNTAS INTELIGENTES:**
        # - Seja espec√≠fico conforme a √°rea identificada
        # - Adapte as perguntas ao tipo de caso (ex: trabalhista vs civil)
        # - Priorize informa√ß√µes que impactam viabilidade e estrat√©gia
        # - Considere aspectos econ√¥micos e temporais

        # **CRIT√âRIOS PARA FINALIZA√á√ÉO:**
        # Termine a entrevista quando tiver informa√ß√µes suficientes sobre:
        # ‚úÖ √Årea jur√≠dica e instituto espec√≠fico
        # ‚úÖ Fatos essenciais e cronologia detalhada
        # ‚úÖ Partes envolvidas e suas qualifica√ß√µes
        # ‚úÖ Urg√™ncia e prazos espec√≠ficos
        # ‚úÖ Viabilidade preliminar do caso
        # ‚úÖ Documenta√ß√£o dispon√≠vel e necess√°ria
        # ‚úÖ Valores e impactos financeiros envolvidos
        # ‚úÖ Localiza√ß√£o geogr√°fica relevante
        # ‚úÖ Tentativas anteriores de solu√ß√£o
        # ‚úÖ Contexto e hist√≥rico do relacionamento
        # ‚úÖ Expectativas e objetivos do cliente
        # ‚úÖ Informa√ß√µes sobre a parte contr√°ria (quando aplic√°vel)

        # **FINALIZA√á√ÉO POR COMPLEXIDADE:**
        # - **Baixa**: Voc√™ mesmo pode gerar a an√°lise final (economia de recursos)
        # - **M√©dia/Alta**: Prepare dados estruturados para an√°lise posterior

        # **SINAL DE FINALIZA√á√ÉO:**
        # Quando a conversa estiver completa, termine com: [TRIAGE_COMPLETE:STRATEGY_X:CONFIDENCE_Y]
        # Onde X = simple/failover/ensemble e Y = 0.0-1.0

        # **DIRETRIZES DE CONVERSA:**
        # - Uma pergunta por vez, seja emp√°tico e profissional
        # - Mantenha linguagem profissional mas acess√≠vel
        # - Seja objetivo e pr√°tico nas perguntas
        # - Considere sempre o contexto brasileiro
        # - N√£o mencione "complexidade" ou "estrat√©gias" para o cliente
        # - Foque em entender o problema completamente
        # - Use linguagem acess√≠vel, evite jarg√µes jur√≠dicos
        # """

    async def start_conversation(self, user_id: str) -> Tuple[str, str]:
        """
        Inicia uma nova conversa de triagem inteligente - MIGRADO PARA REDIS.

        Returns:
            Tuple[case_id, primeira_mensagem_ia]
        """
        case_id = str(uuid.uuid4())

        # Estado inicial da conversa
        initial_state = {
            "user_id": user_id,
            "messages": [],
            "complexity_level": "medium",
            "confidence_score": 0.0,
            "collected_data": {},
            "is_complete": False,
            "strategy_recommended": "failover",
            "completion_reason": "",
            "status": "active",
            "created_at": datetime.now().isoformat()
        }

        # Gerar primeira mensagem
        first_message = "Ol√°! Sou o Justus, seu assistente jur√≠dico da LITGO5. Estou aqui para entender seu caso e ajud√°-lo da melhor forma poss√≠vel. Para come√ßarmos, voc√™ poderia me descrever o problema que est√° enfrentando?"

        # Adicionar primeira mensagem ao estado
        initial_state["messages"].append({
            "role": "assistant",
            "content": first_message,
            "timestamp": datetime.now().isoformat()
        })

        # Salvar no Redis
        await self.state_manager.save_conversation_state(case_id, initial_state)

        return case_id, first_message

    async def continue_conversation(
            self, case_id: str, user_message: str) -> Tuple[str, bool]:
        """
        Continua uma conversa existente - MIGRADO PARA REDIS.

        Returns:
            Tuple[resposta_ia, conversa_finalizada]
        """
        # Recuperar estado do Redis
        state = await self.state_manager.get_conversation_state(case_id)
        if not state:
            raise ValueError(f"Conversa {case_id} n√£o encontrada")

        # Adicionar mensagem do usu√°rio
        state["messages"].append({
            "role": "user",
            "content": user_message,
            "timestamp": datetime.now().isoformat()
        })

        # Gerar resposta da IA
        ai_response = await self._generate_ai_response(state)

        # Verificar se a conversa foi finalizada
        if "[TRIAGE_COMPLETE:" in ai_response:
            return await self._finalize_conversation(case_id, ai_response, state)

        # Salvar estado atualizado no Redis
        state["updated_at"] = datetime.now().isoformat()
        await self.state_manager.save_conversation_state(case_id, state)

        return ai_response, False

    async def _generate_ai_response(self, state: Dict) -> str:
        """Gera resposta da IA usando Claude com o prompt mestre unificado."""
        messages = [] # O prompt de sistema agora √© formatado diretamente

        for msg in state["messages"]:
            messages.append({"role": msg["role"], "content": msg["content"]})

        try:
            catalog = await triage_service._get_area_catalog() # Reutiliza a fun√ß√£o do triage_service
            system_prompt = MASTER_INTERVIEWER_PROMPT_TEMPLATE.format(catalog_json=catalog)
            
            # Adiciona o system prompt no in√≠cio do hist√≥rico da conversa
            messages_with_system = [{"role": "user", "content": system_prompt}] + messages

            response = await self.anthropic_client.messages.create(
                model="claude-3-5-sonnet-20240620",
                max_tokens=2048,
                temperature=0.7,
                # system=system_prompt, # Claude n√£o usa 'system' como OpenAI, ent√£o inclu√≠mos como primeira mensagem
                messages=messages_with_system
            )
            
            ai_full_response = response.content[0].text
            
            # Extrair o JSON e a mensagem de texto
            json_part, text_part = self._extract_json_and_text(ai_full_response)

            if json_part:
                # Atualizar o estado com a an√°lise interna da IA
                analysis = json_part.get("internal_analysis", {})
                state["complexity_level"] = analysis.get("complexity", state["complexity_level"])
                state["confidence_score"] = analysis.get("confidence", state["confidence_score"])
                state["strategy_recommended"] = analysis.get("strategy_recommendation", state["strategy_recommended"])
                state["estimated_area"] = analysis.get("estimated_area") # NOVO
                state["estimated_subarea"] = analysis.get("estimated_subarea") # NOVO

            # Adicionar resposta ao hist√≥rico
            state["messages"].append({
                "role": "assistant",
                "content": text_part, # Salva apenas a parte do texto para o cliente
                "timestamp": datetime.now().isoformat(),
                "internal_analysis": json_part # Salva a an√°lise interna para auditoria
            })

            return text_part

        except Exception as e:
            print(f"Erro na gera√ß√£o de resposta: {e}")
            fallback_response = "Desculpe, estou com problemas t√©cnicos. Voc√™ poderia repetir sua √∫ltima mensagem?"
            state["messages"].append({
                "role": "assistant",
                "content": fallback_response,
                "timestamp": datetime.now().isoformat()
            })
            return fallback_response

    def _extract_json_and_text(self, response_text: str) -> Tuple[Optional[Dict], str]:
        """Extrai o bloco JSON e a mensagem de texto da resposta da IA."""
        try:
            json_match = re.search(r'```json\s*(\{.*?\})\s*```', response_text, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
                json_data = json.loads(json_str)
                # O texto para o usu√°rio √© o que vem depois do bloco JSON
                text_part = response_text[json_match.end():].strip()
                return json_data, text_part
            else:
                # Fallback se o formato n√£o for encontrado
                return None, response_text
        except (json.JSONDecodeError, IndexError) as e:
            print(f"Erro ao extrair JSON da resposta da IA: {e}")
            return None, response_text

    # REMOVER a fun√ß√£o _evaluate_complexity, pois agora est√° unificada
    
    async def _finalize_conversation(
            self, case_id: str, ai_response: str, state: Dict) -> Tuple[str, bool]:
        """Finaliza a conversa e processa o resultado."""

        # Extrair informa√ß√µes do sinal de finaliza√ß√£o
        if "[TRIAGE_COMPLETE:" in ai_response:
            # Remover o sinal da resposta do usu√°rio
            clean_response = ai_response.split("[TRIAGE_COMPLETE:")[0].strip()

            # Extrair estrat√©gia e confian√ßa do sinal
            signal_part = ai_response.split("[TRIAGE_COMPLETE:")[1].replace("]", "")
            parts = signal_part.split(":")

            if len(parts) >= 2:
                strategy = parts[0].replace("STRATEGY_", "").lower()
                confidence = float(parts[1].replace("CONFIDENCE_", ""))

                state["strategy_recommended"] = strategy
                state["confidence_score"] = confidence
        else:
            clean_response = ai_response

        # Marcar como completa
        state["is_complete"] = True
        state["completion_reason"] = "natural_end"
        state["status"] = "completed"
        state["completed_at"] = datetime.now().isoformat()

        # Processar resultado baseado na estrat√©gia
        if state["strategy_recommended"] == "simple":
            # Para casos simples, gerar resultado diretamente
            await self._process_simple_case(state)
        else:
            # Para casos complexos, preparar dados para an√°lise posterior
            await self._prepare_complex_case_data(state)

        # Salvar estado final no Redis
        await self.state_manager.save_conversation_state(case_id, state)

        return clean_response, True

    async def _process_simple_case(self, state: Dict):
        """Processa casos simples diretamente, sem an√°lise posterior."""

        # Prompt para gerar an√°lise completa de caso simples
        simple_analysis_prompt = """
        Voc√™ √© um assistente jur√≠dico especializado. Analise a conversa a seguir e gere uma an√°lise completa do caso.

        Responda APENAS com um JSON no formato:
        {
            "area": "√°rea jur√≠dica principal",
            "subarea": "sub√°rea espec√≠fica",
            "urgency_h": n√∫mero_de_horas_para_a√ß√£o,
            "summary": "resumo conciso do caso",
            "keywords": ["palavra1", "palavra2"],
            "sentiment": "Positivo|Neutro|Negativo",
            "analysis": {
                "viability": "Alta|M√©dia|Baixa",
                "complexity": "Baixa",
                "recommended_action": "a√ß√£o recomendada",
                "estimated_cost": "estimativa de custo",
                "next_steps": ["passo1", "passo2"]
            }
        }
        """

        conversation_text = "\n".join([
            f"{msg['role'].upper()}: {msg['content']}"
            for msg in state["messages"]
        ])

        try:
            response = await self.anthropic_client.messages.create(
                model="claude-3-5-sonnet-20240620",
                max_tokens=1000,
                temperature=0.3,
                messages=[
                    {"role": "system", "content": simple_analysis_prompt},
                    {"role": "user", "content": f"Conversa completa:\n{conversation_text}"}
                ]
            )

            # Extrair JSON da resposta
            response_text = response.content[0].text
            if "{" in response_text and "}" in response_text:
                json_start = response_text.find("{")
                json_end = response_text.rfind("}") + 1
                analysis_data = json.loads(response_text[json_start:json_end])

                state["collected_data"] = analysis_data

        except Exception as e:
            print(f"Erro na an√°lise de caso simples: {e}")
            # Fallback b√°sico
            state["collected_data"] = {
                "area": "N√£o identificado",
                "subarea": "Geral",
                "urgency_h": 72,
                "summary": "An√°lise pendente",
                "keywords": [],
                "sentiment": "Neutro",
                "analysis": {
                    "viability": "M√©dia",
                    "complexity": "Baixa",
                    "recommended_action": "Consultar advogado",
                    "estimated_cost": "A definir",
                    "next_steps": ["Reunir documenta√ß√£o"]
                }
            }

    async def _prepare_complex_case_data(self, state: Dict):
        """Prepara dados estruturados para casos complexos usando schema LEX-9000."""

        # Implementa√ß√£o simplificada - vers√£o completa seria muito extensa
        conversation_text = "\n".join([
            f"{msg['role'].upper()}: {msg['content']}"
            for msg in state["messages"]
        ])

        # Dados b√°sicos para casos complexos
        state["collected_data"] = {
            "basic_info": {
                "area": "An√°lise pendente",
                "subarea": "An√°lise pendente",
                "urgency_h": 72,
                "summary": f"Caso complexo identificado - {len(state['messages'])} mensagens coletadas"
            },
            "conversation_summary": conversation_text,
            "complexity_factors": ["M√∫ltiplas vari√°veis", "An√°lise especializada requerida"],
            "keywords": [],
            "sentiment": "Neutro",
            "entities": {
                "parties": [],
                "dates": [],
                "amounts": [],
                "locations": []
            }
        }

    async def get_triage_result(self, case_id: str) -> Optional[TriageResult]:
        """
        Obt√©m resultado final da triagem - MIGRADO PARA REDIS.
        """
        state = await self.state_manager.get_conversation_state(case_id)
        if not state or not state.get("is_complete"):
            return None

        # Gerar resumo da conversa
        conversation_summary = f"Conversa com {
            len(
                state.get(
                    'messages',
                    []))} mensagens"

        return TriageResult(
            case_id=case_id,
            strategy_used=state.get("strategy_recommended", "failover"),
            complexity_level=state.get("complexity_level", "medium"),
            confidence_score=state.get("confidence_score", 0.5),
            triage_data=state.get("collected_data", {}),
            conversation_summary=conversation_summary,
            processing_time_ms=0  # Ser√° calculado pelo orquestrador
        )

    def cleanup_conversation(self, case_id: str):
        """
        Remove conversa - MIGRADO PARA REDIS.
        """
        # Execu√ß√£o ass√≠ncrona para n√£o bloquear
        asyncio.create_task(
            self.state_manager.delete_conversation_state(case_id)
        )

    async def get_conversation_status(self, case_id: str) -> Optional[Dict]:
        """
        Obt√©m status da conversa - MIGRADO PARA REDIS.
        """
        state = await self.state_manager.get_conversation_state(case_id)
        if not state:
            return None

        return {
            "case_id": case_id,
            "status": state.get("status", "unknown"),
            "complexity_level": state.get("complexity_level", "unknown"),
            "confidence_score": state.get("confidence_score", 0.0),
            "message_count": len(state.get("messages", [])),
            "created_at": state.get("created_at"),
            "updated_at": state.get("updated_at"),
            "is_complete": state.get("is_complete", False)
        }

    async def generate_response(self, conversation_history: List[Dict[str, str]]) -> str:
        """
        Gera uma resposta da IA com l√≥gica de failover.
        Tenta o provedor prim√°rio (Anthropic) e usa o backup (Llama 4) em caso de falha.
        """
        try:
            # Tentativa com o provedor prim√°rio (Claude Sonnet)
            if INTERVIEWER_MODEL_PROVIDER == "anthropic" and self.anthropic_client:
                return await self._ask_anthropic(conversation_history, INTERVIEWER_MODEL)
        except Exception as e:
            print(f"Erro com o provedor prim√°rio '{INTERVIEWER_MODEL_PROVIDER}' ({INTERVIEWER_MODEL}): {e}. Acionando failover.")
            
            # L√≥gica de Failover
            try:
                if INTERVIEWER_MODEL_FAILOVER_PROVIDER == "together" and self.together_client:
                     return await self._ask_llama(conversation_history, INTERVIEWER_MODEL_LLAMA_FALLBACK)
            except Exception as e_failover:
                print(f"Erro com o provedor de failover '{INTERVIEWER_MODEL_FAILOVER_PROVIDER}' ({INTERVIEWER_MODEL_LLAMA_FALLBACK}): {e_failover}.")
                return "Desculpe, nosso assistente inteligente est√° temporariamente indispon√≠vel. Por favor, tente novamente em alguns instantes."

        return "Erro de configura√ß√£o: Nenhum provedor de IA dispon√≠vel para o entrevistador."

    async def _ask_anthropic(self, conversation_history: List[Dict[str, str]], model: str) -> str:
        """Chama a API da Anthropic para obter uma resposta."""
        if not self.anthropic_client:
            raise ValueError("Cliente da Anthropic n√£o inicializado.")

        # L√≥gica para chamar a API da Anthropic...
        # Exemplo:
        system_prompt = "Voc√™ √© Justus, um assistente jur√≠dico emp√°tico e eficiente..." # Seu prompt de sistema aqui
        response = await self.anthropic_client.messages.create(
            model=model,
            max_tokens=1024,
            system=system_prompt,
            messages=conversation_history
        )
        return response.content[0].text

    async def _ask_openai(self, conversation_history: List[Dict[str, str]], model: str) -> str:
        """Chama a API da OpenAI para obter uma resposta."""
        if not self.openai_client:
            raise ValueError("Cliente da OpenAI n√£o inicializado.")

        # L√≥gica para chamar a API da OpenAI...
        # Exemplo:
        system_prompt = "Voc√™ √© Justus, um assistente jur√≠dico emp√°tico e eficiente..." # Seu prompt de sistema aqui
        messages_for_openai = [{"role": "system", "content": system_prompt}] + conversation_history
        
        response = await self.openai_client.chat.completions.create(
            model=model,
            max_tokens=1024,
            messages=messages_for_openai
        )
        return response.choices[0].message.content

    async def _ask_llama(self, conversation_history: List[Dict[str, str]], model: str) -> str:
        """Chama um modelo Llama 4 via Together AI para obter uma resposta."""
        if not self.together_client:
            raise ValueError("Cliente da Together AI n√£o inicializado.")

        system_prompt = "Voc√™ √© Justus, um assistente jur√≠dico emp√°tico e eficiente..." # Seu prompt de sistema aqui
        messages_for_llama = [{"role": "system", "content": system_prompt}] + conversation_history
        
        response = await self.together_client.chat.completions.create(
            model=model,
            max_tokens=1024,
            messages=messages_for_llama
        )
        return response.choices[0].message.content


# Inst√¢ncia √∫nica do servi√ßo
intelligent_interviewer_service = IntelligentInterviewerService()
