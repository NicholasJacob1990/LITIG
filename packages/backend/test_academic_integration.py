#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
test_academic_integration.py

Script de teste para validar a integraÃ§Ã£o completa do enriquecimento acadÃªmico.
Testa a classe AcademicEnricher, integraÃ§Ã£o com Escavador e APIs externas.
"""

import asyncio
import logging
import os
import sys
from datetime import datetime
from typing import Dict, Any

# Adicionar path para imports
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Carregar variÃ¡veis de ambiente
from dotenv import load_dotenv
load_dotenv()

async def test_escavador_curriculum():
    """Testa a busca de currÃ­culo via Escavador."""
    logger.info("ğŸ§ª Testando busca de currÃ­culo no Escavador...")
    
    try:
        from services.escavador_integration import EscavadorClient
        
        api_key = os.getenv("ESCAVADOR_API_KEY")
        if not api_key or api_key == "your_escavador_api_key_here":
            logger.warning("âš ï¸ Chave do Escavador nÃ£o configurada - pulando teste")
            return False
        
        client = EscavadorClient(api_key=api_key)
        
        # Teste com nome fictÃ­cio (substituir por nome real para teste)
        test_name = "JosÃ© da Silva"
        test_oab = "123456"
        
        curriculum_data = await client.get_curriculum_data(
            person_name=test_name,
            oab_number=test_oab
        )
        
        if curriculum_data:
            logger.info("âœ… CurrÃ­culo encontrado!")
            logger.info(f"   - Anos de experiÃªncia: {curriculum_data.get('anos_experiencia', 0)}")
            logger.info(f"   - PÃ³s-graduaÃ§Ãµes: {len(curriculum_data.get('pos_graduacoes', []))}")
            logger.info(f"   - PublicaÃ§Ãµes: {len(curriculum_data.get('publicacoes', []))}")
            logger.info(f"   - Tem currÃ­culo Lattes: {curriculum_data.get('tem_curriculo', False)}")
            return True
        else:
            logger.warning("âš ï¸ Nenhum currÃ­culo encontrado")
            return False
            
    except Exception as e:
        logger.error(f"âŒ Erro no teste do Escavador: {e}")
        return False

async def test_academic_enricher():
    """Testa a classe AcademicEnricher."""
    logger.info("ğŸ§ª Testando AcademicEnricher...")
    
    try:
        # Import do algoritmo
        from Algoritmo.algoritmo_match import AcademicEnricher, RedisCache, REDIS_URL
        
        # Configurar cache
        cache = RedisCache(REDIS_URL)
        enricher = AcademicEnricher(cache)
        
        # Teste bÃ¡sico de universidades
        test_universities = ["Universidade de SÃ£o Paulo", "Harvard Law School"]
        logger.info(f"Testando universidades: {test_universities}")
        
        uni_scores = await enricher.score_universities(test_universities)
        logger.info(f"âœ… Scores de universidades: {uni_scores}")
        
        # Teste bÃ¡sico de periÃ³dicos
        test_journals = ["Revista de Direito Administrativo", "Harvard Law Review"]
        logger.info(f"Testando periÃ³dicos: {test_journals}")
        
        jour_scores = await enricher.score_journals(test_journals)
        logger.info(f"âœ… Scores de periÃ³dicos: {jour_scores}")
        
        # Fechar cache
        await cache.close()
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ Erro no teste do AcademicEnricher: {e}")
        return False

async def test_feature_calculator_integration():
    """Testa a integraÃ§Ã£o no FeatureCalculator."""
    logger.info("ğŸ§ª Testando integraÃ§Ã£o no FeatureCalculator...")
    
    try:
        # Imports do algoritmo
        from Algoritmo.algoritmo_match import (
            FeatureCalculator, Case, Lawyer, KPI, 
            EMBEDDING_DIM, ProfessionalMaturityData
        )
        import numpy as np
        
        # Criar caso de teste
        case = Case(
            id="test_case",
            area="Trabalhista",
            subarea="RescisÃ£o",
            urgency_h=48,
            coords=(-23.5505, -46.6333),
            complexity="MEDIUM",
            summary_embedding=np.random.rand(EMBEDDING_DIM),
        )
        
        # Criar advogado de teste com currÃ­culo acadÃªmico
        lawyer = Lawyer(
            id="test_lawyer",
            nome="Dr. JoÃ£o Silva",
            tags_expertise=["trabalhista", "civil"],
            geo_latlon=(-23.5505, -46.6333),
            curriculo_json={
                "anos_experiencia": 15,
                "pos_graduacoes": [
                    {
                        "nivel": "mestrado",
                        "titulo": "Mestrado em Direito do Trabalho",
                        "instituicao": "Universidade de SÃ£o Paulo",
                        "area": "Trabalhista",
                        "ano_inicio": 2010,
                        "ano_fim": 2012
                    }
                ],
                "publicacoes": [
                    {
                        "ano": 2020,
                        "titulo": "Direitos Trabalhistas Modernos",
                        "journal": "Revista de Direito do Trabalho",
                        "tipo": "artigo"
                    }
                ],
                "num_publicacoes": 1,
                "areas_de_atuacao": "Direito do Trabalho, Direito Civil",
                "fonte": "escavador_lattes",
                "tem_curriculo": True
            },
            kpi=KPI(
                success_rate=0.85,
                cases_30d=20,
                avaliacao_media=4.5,
                tempo_resposta_h=24,
                cv_score=0.8,
                success_status="V"
            ),
            max_concurrent_cases=25,
            diversity=None,
            kpi_subarea={"Trabalhista/RescisÃ£o": 0.9},
            kpi_softskill=0.8,
            case_outcomes=[True, True, False, True],
            review_texts=["Excelente profissional", "Muito competente"],
            casos_historicos_embeddings=[np.random.rand(EMBEDDING_DIM) for _ in range(3)],
            maturity_data=ProfessionalMaturityData(
                experience_years=15,
                network_strength=150,
                reputation_signals=25,
                responsiveness_hours=12
            )
        )
        
        # Testar FeatureCalculator
        calculator = FeatureCalculator(case, lawyer)
        
        # Teste sÃ­ncrono (fallback)
        logger.info("Testando qualification_score (sÃ­ncrono)...")
        qual_score_sync = calculator.qualification_score()
        logger.info(f"âœ… Qualification Score (sync): {qual_score_sync:.3f}")
        
        # Teste assÃ­ncrono (com enriquecimento acadÃªmico)
        logger.info("Testando qualification_score_async (com enriquecimento)...")
        qual_score_async = await calculator.qualification_score_async()
        logger.info(f"âœ… Qualification Score (async): {qual_score_async:.3f}")
        
        # Teste de todas as features
        logger.info("Testando all_async (todas as features)...")
        all_features = await calculator.all_async()
        logger.info("âœ… Todas as features calculadas:")
        for feature, score in all_features.items():
            logger.info(f"   - {feature}: {score:.3f}")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ Erro no teste do FeatureCalculator: {e}")
        return False

async def test_api_keys_configuration():
    """Testa se as chaves das APIs estÃ£o configuradas."""
    logger.info("ğŸ§ª Testando configuraÃ§Ã£o das APIs...")
    
    tests_passed = 0
    total_tests = 3
    
    # Teste Escavador
    escavador_key = os.getenv("ESCAVADOR_API_KEY")
    if escavador_key and escavador_key != "your_escavador_api_key_here":
        logger.info("âœ… Chave do Escavador configurada")
        tests_passed += 1
    else:
        logger.warning("âš ï¸ Chave do Escavador nÃ£o configurada")
    
    # Teste Perplexity
    perplexity_key = os.getenv("PERPLEXITY_API_KEY")
    if perplexity_key and perplexity_key != "your_perplexity_api_key_here":
        logger.info("âœ… Chave do Perplexity configurada")
        tests_passed += 1
    else:
        logger.warning("âš ï¸ Chave do Perplexity nÃ£o configurada")
    
    # Teste OpenAI (opcional)
    openai_key = os.getenv("OPENAI_DEEP_KEY")
    if openai_key and openai_key != "your_openai_api_key_here":
        logger.info("âœ… Chave do OpenAI configurada")
        tests_passed += 1
    else:
        logger.warning("âš ï¸ Chave do OpenAI nÃ£o configurada (opcional)")
        tests_passed += 1  # Considerar como passado pois Ã© opcional
    
    logger.info(f"ğŸ“Š APIs configuradas: {tests_passed}/{total_tests}")
    return tests_passed >= 2  # Precisa de pelo menos 2/3 (Escavador Ã© obrigatÃ³rio)

def create_sample_env_file():
    """Cria arquivo .env de exemplo se nÃ£o existir."""
    env_file = ".env"
    config_file = "config_academic_apis.env"
    
    if not os.path.exists(env_file) and os.path.exists(config_file):
        logger.info("ğŸ“ Criando arquivo .env de exemplo...")
        
        import shutil
        shutil.copy(config_file, env_file)
        
        logger.info(f"âœ… Arquivo .env criado a partir de {config_file}")
        logger.info("âš ï¸ IMPORTANTE: Configure suas chaves reais no arquivo .env")
        return True
    
    return False

async def main():
    """FunÃ§Ã£o principal de teste."""
    logger.info("ğŸš€ Iniciando testes de integraÃ§Ã£o acadÃªmica...")
    logger.info("=" * 60)
    
    # EstatÃ­sticas dos testes
    tests_results = []
    
    # Criar .env se necessÃ¡rio
    create_sample_env_file()
    
    # 1. Testar configuraÃ§Ã£o das APIs
    logger.info("\n1ï¸âƒ£ TESTE DE CONFIGURAÃ‡ÃƒO DAS APIS")
    result1 = await test_api_keys_configuration()
    tests_results.append(("ConfiguraÃ§Ã£o APIs", result1))
    
    # 2. Testar AcademicEnricher
    logger.info("\n2ï¸âƒ£ TESTE DO ACADEMIC ENRICHER")
    result2 = await test_academic_enricher()
    tests_results.append(("AcademicEnricher", result2))
    
    # 3. Testar integraÃ§Ã£o Escavador
    logger.info("\n3ï¸âƒ£ TESTE DE INTEGRAÃ‡ÃƒO ESCAVADOR")
    result3 = await test_escavador_curriculum()
    tests_results.append(("IntegraÃ§Ã£o Escavador", result3))
    
    # 4. Testar FeatureCalculator
    logger.info("\n4ï¸âƒ£ TESTE DO FEATURE CALCULATOR")
    result4 = await test_feature_calculator_integration()
    tests_results.append(("FeatureCalculator", result4))
    
    # RelatÃ³rio final
    logger.info("\n" + "=" * 60)
    logger.info("ğŸ“Š RELATÃ“RIO FINAL DOS TESTES")
    logger.info("=" * 60)
    
    passed_tests = 0
    total_tests = len(tests_results)
    
    for test_name, result in tests_results:
        status = "âœ… PASSOU" if result else "âŒ FALHOU"
        logger.info(f"{test_name}: {status}")
        if result:
            passed_tests += 1
    
    logger.info("-" * 60)
    logger.info(f"Testes passados: {passed_tests}/{total_tests}")
    
    if passed_tests == total_tests:
        logger.info("ğŸ‰ TODOS OS TESTES PASSARAM!")
        logger.info("âœ… IntegraÃ§Ã£o acadÃªmica estÃ¡ funcionando corretamente")
    elif passed_tests >= total_tests // 2:
        logger.info("âš ï¸ ALGUNS TESTES FALHARAM")
        logger.info("ğŸ”§ Verifique as configuraÃ§Ãµes e dependÃªncias")
    else:
        logger.info("âŒ MUITOS TESTES FALHARAM")
        logger.info("ğŸš¨ Verifique se as APIs estÃ£o configuradas corretamente")
    
    logger.info("\nğŸ“š PRÃ“XIMOS PASSOS:")
    logger.info("1. Configure as chaves das APIs no arquivo .env")
    logger.info("2. Instale Redis: brew install redis (macOS) ou docker run -p 6379:6379 redis")
    logger.info("3. Execute: redis-server")
    logger.info("4. Execute novamente este teste: python test_academic_integration.py")
    
    return passed_tests == total_tests

if __name__ == "__main__":
    try:
        success = asyncio.run(main())
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        logger.info("\nâ¹ï¸ Teste interrompido pelo usuÃ¡rio")
        sys.exit(1)
    except Exception as e:
        logger.error(f"\nğŸ’¥ Erro inesperado: {e}")
        sys.exit(1) 
# -*- coding: utf-8 -*-
"""
test_academic_integration.py

Script de teste para validar a integraÃ§Ã£o completa do enriquecimento acadÃªmico.
Testa a classe AcademicEnricher, integraÃ§Ã£o com Escavador e APIs externas.
"""

import asyncio
import logging
import os
import sys
from datetime import datetime
from typing import Dict, Any

# Adicionar path para imports
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Carregar variÃ¡veis de ambiente
from dotenv import load_dotenv
load_dotenv()

async def test_escavador_curriculum():
    """Testa a busca de currÃ­culo via Escavador."""
    logger.info("ğŸ§ª Testando busca de currÃ­culo no Escavador...")
    
    try:
        from services.escavador_integration import EscavadorClient
        
        api_key = os.getenv("ESCAVADOR_API_KEY")
        if not api_key or api_key == "your_escavador_api_key_here":
            logger.warning("âš ï¸ Chave do Escavador nÃ£o configurada - pulando teste")
            return False
        
        client = EscavadorClient(api_key=api_key)
        
        # Teste com nome fictÃ­cio (substituir por nome real para teste)
        test_name = "JosÃ© da Silva"
        test_oab = "123456"
        
        curriculum_data = await client.get_curriculum_data(
            person_name=test_name,
            oab_number=test_oab
        )
        
        if curriculum_data:
            logger.info("âœ… CurrÃ­culo encontrado!")
            logger.info(f"   - Anos de experiÃªncia: {curriculum_data.get('anos_experiencia', 0)}")
            logger.info(f"   - PÃ³s-graduaÃ§Ãµes: {len(curriculum_data.get('pos_graduacoes', []))}")
            logger.info(f"   - PublicaÃ§Ãµes: {len(curriculum_data.get('publicacoes', []))}")
            logger.info(f"   - Tem currÃ­culo Lattes: {curriculum_data.get('tem_curriculo', False)}")
            return True
        else:
            logger.warning("âš ï¸ Nenhum currÃ­culo encontrado")
            return False
            
    except Exception as e:
        logger.error(f"âŒ Erro no teste do Escavador: {e}")
        return False

async def test_academic_enricher():
    """Testa a classe AcademicEnricher."""
    logger.info("ğŸ§ª Testando AcademicEnricher...")
    
    try:
        # Import do algoritmo
        from Algoritmo.algoritmo_match import AcademicEnricher, RedisCache, REDIS_URL
        
        # Configurar cache
        cache = RedisCache(REDIS_URL)
        enricher = AcademicEnricher(cache)
        
        # Teste bÃ¡sico de universidades
        test_universities = ["Universidade de SÃ£o Paulo", "Harvard Law School"]
        logger.info(f"Testando universidades: {test_universities}")
        
        uni_scores = await enricher.score_universities(test_universities)
        logger.info(f"âœ… Scores de universidades: {uni_scores}")
        
        # Teste bÃ¡sico de periÃ³dicos
        test_journals = ["Revista de Direito Administrativo", "Harvard Law Review"]
        logger.info(f"Testando periÃ³dicos: {test_journals}")
        
        jour_scores = await enricher.score_journals(test_journals)
        logger.info(f"âœ… Scores de periÃ³dicos: {jour_scores}")
        
        # Fechar cache
        await cache.close()
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ Erro no teste do AcademicEnricher: {e}")
        return False

async def test_feature_calculator_integration():
    """Testa a integraÃ§Ã£o no FeatureCalculator."""
    logger.info("ğŸ§ª Testando integraÃ§Ã£o no FeatureCalculator...")
    
    try:
        # Imports do algoritmo
        from Algoritmo.algoritmo_match import (
            FeatureCalculator, Case, Lawyer, KPI, 
            EMBEDDING_DIM, ProfessionalMaturityData
        )
        import numpy as np
        
        # Criar caso de teste
        case = Case(
            id="test_case",
            area="Trabalhista",
            subarea="RescisÃ£o",
            urgency_h=48,
            coords=(-23.5505, -46.6333),
            complexity="MEDIUM",
            summary_embedding=np.random.rand(EMBEDDING_DIM),
        )
        
        # Criar advogado de teste com currÃ­culo acadÃªmico
        lawyer = Lawyer(
            id="test_lawyer",
            nome="Dr. JoÃ£o Silva",
            tags_expertise=["trabalhista", "civil"],
            geo_latlon=(-23.5505, -46.6333),
            curriculo_json={
                "anos_experiencia": 15,
                "pos_graduacoes": [
                    {
                        "nivel": "mestrado",
                        "titulo": "Mestrado em Direito do Trabalho",
                        "instituicao": "Universidade de SÃ£o Paulo",
                        "area": "Trabalhista",
                        "ano_inicio": 2010,
                        "ano_fim": 2012
                    }
                ],
                "publicacoes": [
                    {
                        "ano": 2020,
                        "titulo": "Direitos Trabalhistas Modernos",
                        "journal": "Revista de Direito do Trabalho",
                        "tipo": "artigo"
                    }
                ],
                "num_publicacoes": 1,
                "areas_de_atuacao": "Direito do Trabalho, Direito Civil",
                "fonte": "escavador_lattes",
                "tem_curriculo": True
            },
            kpi=KPI(
                success_rate=0.85,
                cases_30d=20,
                avaliacao_media=4.5,
                tempo_resposta_h=24,
                cv_score=0.8,
                success_status="V"
            ),
            max_concurrent_cases=25,
            diversity=None,
            kpi_subarea={"Trabalhista/RescisÃ£o": 0.9},
            kpi_softskill=0.8,
            case_outcomes=[True, True, False, True],
            review_texts=["Excelente profissional", "Muito competente"],
            casos_historicos_embeddings=[np.random.rand(EMBEDDING_DIM) for _ in range(3)],
            maturity_data=ProfessionalMaturityData(
                experience_years=15,
                network_strength=150,
                reputation_signals=25,
                responsiveness_hours=12
            )
        )
        
        # Testar FeatureCalculator
        calculator = FeatureCalculator(case, lawyer)
        
        # Teste sÃ­ncrono (fallback)
        logger.info("Testando qualification_score (sÃ­ncrono)...")
        qual_score_sync = calculator.qualification_score()
        logger.info(f"âœ… Qualification Score (sync): {qual_score_sync:.3f}")
        
        # Teste assÃ­ncrono (com enriquecimento acadÃªmico)
        logger.info("Testando qualification_score_async (com enriquecimento)...")
        qual_score_async = await calculator.qualification_score_async()
        logger.info(f"âœ… Qualification Score (async): {qual_score_async:.3f}")
        
        # Teste de todas as features
        logger.info("Testando all_async (todas as features)...")
        all_features = await calculator.all_async()
        logger.info("âœ… Todas as features calculadas:")
        for feature, score in all_features.items():
            logger.info(f"   - {feature}: {score:.3f}")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ Erro no teste do FeatureCalculator: {e}")
        return False

async def test_api_keys_configuration():
    """Testa se as chaves das APIs estÃ£o configuradas."""
    logger.info("ğŸ§ª Testando configuraÃ§Ã£o das APIs...")
    
    tests_passed = 0
    total_tests = 3
    
    # Teste Escavador
    escavador_key = os.getenv("ESCAVADOR_API_KEY")
    if escavador_key and escavador_key != "your_escavador_api_key_here":
        logger.info("âœ… Chave do Escavador configurada")
        tests_passed += 1
    else:
        logger.warning("âš ï¸ Chave do Escavador nÃ£o configurada")
    
    # Teste Perplexity
    perplexity_key = os.getenv("PERPLEXITY_API_KEY")
    if perplexity_key and perplexity_key != "your_perplexity_api_key_here":
        logger.info("âœ… Chave do Perplexity configurada")
        tests_passed += 1
    else:
        logger.warning("âš ï¸ Chave do Perplexity nÃ£o configurada")
    
    # Teste OpenAI (opcional)
    openai_key = os.getenv("OPENAI_DEEP_KEY")
    if openai_key and openai_key != "your_openai_api_key_here":
        logger.info("âœ… Chave do OpenAI configurada")
        tests_passed += 1
    else:
        logger.warning("âš ï¸ Chave do OpenAI nÃ£o configurada (opcional)")
        tests_passed += 1  # Considerar como passado pois Ã© opcional
    
    logger.info(f"ğŸ“Š APIs configuradas: {tests_passed}/{total_tests}")
    return tests_passed >= 2  # Precisa de pelo menos 2/3 (Escavador Ã© obrigatÃ³rio)

def create_sample_env_file():
    """Cria arquivo .env de exemplo se nÃ£o existir."""
    env_file = ".env"
    config_file = "config_academic_apis.env"
    
    if not os.path.exists(env_file) and os.path.exists(config_file):
        logger.info("ğŸ“ Criando arquivo .env de exemplo...")
        
        import shutil
        shutil.copy(config_file, env_file)
        
        logger.info(f"âœ… Arquivo .env criado a partir de {config_file}")
        logger.info("âš ï¸ IMPORTANTE: Configure suas chaves reais no arquivo .env")
        return True
    
    return False

async def main():
    """FunÃ§Ã£o principal de teste."""
    logger.info("ğŸš€ Iniciando testes de integraÃ§Ã£o acadÃªmica...")
    logger.info("=" * 60)
    
    # EstatÃ­sticas dos testes
    tests_results = []
    
    # Criar .env se necessÃ¡rio
    create_sample_env_file()
    
    # 1. Testar configuraÃ§Ã£o das APIs
    logger.info("\n1ï¸âƒ£ TESTE DE CONFIGURAÃ‡ÃƒO DAS APIS")
    result1 = await test_api_keys_configuration()
    tests_results.append(("ConfiguraÃ§Ã£o APIs", result1))
    
    # 2. Testar AcademicEnricher
    logger.info("\n2ï¸âƒ£ TESTE DO ACADEMIC ENRICHER")
    result2 = await test_academic_enricher()
    tests_results.append(("AcademicEnricher", result2))
    
    # 3. Testar integraÃ§Ã£o Escavador
    logger.info("\n3ï¸âƒ£ TESTE DE INTEGRAÃ‡ÃƒO ESCAVADOR")
    result3 = await test_escavador_curriculum()
    tests_results.append(("IntegraÃ§Ã£o Escavador", result3))
    
    # 4. Testar FeatureCalculator
    logger.info("\n4ï¸âƒ£ TESTE DO FEATURE CALCULATOR")
    result4 = await test_feature_calculator_integration()
    tests_results.append(("FeatureCalculator", result4))
    
    # RelatÃ³rio final
    logger.info("\n" + "=" * 60)
    logger.info("ğŸ“Š RELATÃ“RIO FINAL DOS TESTES")
    logger.info("=" * 60)
    
    passed_tests = 0
    total_tests = len(tests_results)
    
    for test_name, result in tests_results:
        status = "âœ… PASSOU" if result else "âŒ FALHOU"
        logger.info(f"{test_name}: {status}")
        if result:
            passed_tests += 1
    
    logger.info("-" * 60)
    logger.info(f"Testes passados: {passed_tests}/{total_tests}")
    
    if passed_tests == total_tests:
        logger.info("ğŸ‰ TODOS OS TESTES PASSARAM!")
        logger.info("âœ… IntegraÃ§Ã£o acadÃªmica estÃ¡ funcionando corretamente")
    elif passed_tests >= total_tests // 2:
        logger.info("âš ï¸ ALGUNS TESTES FALHARAM")
        logger.info("ğŸ”§ Verifique as configuraÃ§Ãµes e dependÃªncias")
    else:
        logger.info("âŒ MUITOS TESTES FALHARAM")
        logger.info("ğŸš¨ Verifique se as APIs estÃ£o configuradas corretamente")
    
    logger.info("\nğŸ“š PRÃ“XIMOS PASSOS:")
    logger.info("1. Configure as chaves das APIs no arquivo .env")
    logger.info("2. Instale Redis: brew install redis (macOS) ou docker run -p 6379:6379 redis")
    logger.info("3. Execute: redis-server")
    logger.info("4. Execute novamente este teste: python test_academic_integration.py")
    
    return passed_tests == total_tests

if __name__ == "__main__":
    try:
        success = asyncio.run(main())
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        logger.info("\nâ¹ï¸ Teste interrompido pelo usuÃ¡rio")
        sys.exit(1)
    except Exception as e:
        logger.error(f"\nğŸ’¥ Erro inesperado: {e}")
        sys.exit(1) 
# -*- coding: utf-8 -*-
"""
test_academic_integration.py

Script de teste para validar a integraÃ§Ã£o completa do enriquecimento acadÃªmico.
Testa a classe AcademicEnricher, integraÃ§Ã£o com Escavador e APIs externas.
"""

import asyncio
import logging
import os
import sys
from datetime import datetime
from typing import Dict, Any

# Adicionar path para imports
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Carregar variÃ¡veis de ambiente
from dotenv import load_dotenv
load_dotenv()

async def test_escavador_curriculum():
    """Testa a busca de currÃ­culo via Escavador."""
    logger.info("ğŸ§ª Testando busca de currÃ­culo no Escavador...")
    
    try:
        from services.escavador_integration import EscavadorClient
        
        api_key = os.getenv("ESCAVADOR_API_KEY")
        if not api_key or api_key == "your_escavador_api_key_here":
            logger.warning("âš ï¸ Chave do Escavador nÃ£o configurada - pulando teste")
            return False
        
        client = EscavadorClient(api_key=api_key)
        
        # Teste com nome fictÃ­cio (substituir por nome real para teste)
        test_name = "JosÃ© da Silva"
        test_oab = "123456"
        
        curriculum_data = await client.get_curriculum_data(
            person_name=test_name,
            oab_number=test_oab
        )
        
        if curriculum_data:
            logger.info("âœ… CurrÃ­culo encontrado!")
            logger.info(f"   - Anos de experiÃªncia: {curriculum_data.get('anos_experiencia', 0)}")
            logger.info(f"   - PÃ³s-graduaÃ§Ãµes: {len(curriculum_data.get('pos_graduacoes', []))}")
            logger.info(f"   - PublicaÃ§Ãµes: {len(curriculum_data.get('publicacoes', []))}")
            logger.info(f"   - Tem currÃ­culo Lattes: {curriculum_data.get('tem_curriculo', False)}")
            return True
        else:
            logger.warning("âš ï¸ Nenhum currÃ­culo encontrado")
            return False
            
    except Exception as e:
        logger.error(f"âŒ Erro no teste do Escavador: {e}")
        return False

async def test_academic_enricher():
    """Testa a classe AcademicEnricher."""
    logger.info("ğŸ§ª Testando AcademicEnricher...")
    
    try:
        # Import do algoritmo
        from Algoritmo.algoritmo_match import AcademicEnricher, RedisCache, REDIS_URL
        
        # Configurar cache
        cache = RedisCache(REDIS_URL)
        enricher = AcademicEnricher(cache)
        
        # Teste bÃ¡sico de universidades
        test_universities = ["Universidade de SÃ£o Paulo", "Harvard Law School"]
        logger.info(f"Testando universidades: {test_universities}")
        
        uni_scores = await enricher.score_universities(test_universities)
        logger.info(f"âœ… Scores de universidades: {uni_scores}")
        
        # Teste bÃ¡sico de periÃ³dicos
        test_journals = ["Revista de Direito Administrativo", "Harvard Law Review"]
        logger.info(f"Testando periÃ³dicos: {test_journals}")
        
        jour_scores = await enricher.score_journals(test_journals)
        logger.info(f"âœ… Scores de periÃ³dicos: {jour_scores}")
        
        # Fechar cache
        await cache.close()
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ Erro no teste do AcademicEnricher: {e}")
        return False

async def test_feature_calculator_integration():
    """Testa a integraÃ§Ã£o no FeatureCalculator."""
    logger.info("ğŸ§ª Testando integraÃ§Ã£o no FeatureCalculator...")
    
    try:
        # Imports do algoritmo
        from Algoritmo.algoritmo_match import (
            FeatureCalculator, Case, Lawyer, KPI, 
            EMBEDDING_DIM, ProfessionalMaturityData
        )
        import numpy as np
        
        # Criar caso de teste
        case = Case(
            id="test_case",
            area="Trabalhista",
            subarea="RescisÃ£o",
            urgency_h=48,
            coords=(-23.5505, -46.6333),
            complexity="MEDIUM",
            summary_embedding=np.random.rand(EMBEDDING_DIM),
        )
        
        # Criar advogado de teste com currÃ­culo acadÃªmico
        lawyer = Lawyer(
            id="test_lawyer",
            nome="Dr. JoÃ£o Silva",
            tags_expertise=["trabalhista", "civil"],
            geo_latlon=(-23.5505, -46.6333),
            curriculo_json={
                "anos_experiencia": 15,
                "pos_graduacoes": [
                    {
                        "nivel": "mestrado",
                        "titulo": "Mestrado em Direito do Trabalho",
                        "instituicao": "Universidade de SÃ£o Paulo",
                        "area": "Trabalhista",
                        "ano_inicio": 2010,
                        "ano_fim": 2012
                    }
                ],
                "publicacoes": [
                    {
                        "ano": 2020,
                        "titulo": "Direitos Trabalhistas Modernos",
                        "journal": "Revista de Direito do Trabalho",
                        "tipo": "artigo"
                    }
                ],
                "num_publicacoes": 1,
                "areas_de_atuacao": "Direito do Trabalho, Direito Civil",
                "fonte": "escavador_lattes",
                "tem_curriculo": True
            },
            kpi=KPI(
                success_rate=0.85,
                cases_30d=20,
                avaliacao_media=4.5,
                tempo_resposta_h=24,
                cv_score=0.8,
                success_status="V"
            ),
            max_concurrent_cases=25,
            diversity=None,
            kpi_subarea={"Trabalhista/RescisÃ£o": 0.9},
            kpi_softskill=0.8,
            case_outcomes=[True, True, False, True],
            review_texts=["Excelente profissional", "Muito competente"],
            casos_historicos_embeddings=[np.random.rand(EMBEDDING_DIM) for _ in range(3)],
            maturity_data=ProfessionalMaturityData(
                experience_years=15,
                network_strength=150,
                reputation_signals=25,
                responsiveness_hours=12
            )
        )
        
        # Testar FeatureCalculator
        calculator = FeatureCalculator(case, lawyer)
        
        # Teste sÃ­ncrono (fallback)
        logger.info("Testando qualification_score (sÃ­ncrono)...")
        qual_score_sync = calculator.qualification_score()
        logger.info(f"âœ… Qualification Score (sync): {qual_score_sync:.3f}")
        
        # Teste assÃ­ncrono (com enriquecimento acadÃªmico)
        logger.info("Testando qualification_score_async (com enriquecimento)...")
        qual_score_async = await calculator.qualification_score_async()
        logger.info(f"âœ… Qualification Score (async): {qual_score_async:.3f}")
        
        # Teste de todas as features
        logger.info("Testando all_async (todas as features)...")
        all_features = await calculator.all_async()
        logger.info("âœ… Todas as features calculadas:")
        for feature, score in all_features.items():
            logger.info(f"   - {feature}: {score:.3f}")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ Erro no teste do FeatureCalculator: {e}")
        return False

async def test_api_keys_configuration():
    """Testa se as chaves das APIs estÃ£o configuradas."""
    logger.info("ğŸ§ª Testando configuraÃ§Ã£o das APIs...")
    
    tests_passed = 0
    total_tests = 3
    
    # Teste Escavador
    escavador_key = os.getenv("ESCAVADOR_API_KEY")
    if escavador_key and escavador_key != "your_escavador_api_key_here":
        logger.info("âœ… Chave do Escavador configurada")
        tests_passed += 1
    else:
        logger.warning("âš ï¸ Chave do Escavador nÃ£o configurada")
    
    # Teste Perplexity
    perplexity_key = os.getenv("PERPLEXITY_API_KEY")
    if perplexity_key and perplexity_key != "your_perplexity_api_key_here":
        logger.info("âœ… Chave do Perplexity configurada")
        tests_passed += 1
    else:
        logger.warning("âš ï¸ Chave do Perplexity nÃ£o configurada")
    
    # Teste OpenAI (opcional)
    openai_key = os.getenv("OPENAI_DEEP_KEY")
    if openai_key and openai_key != "your_openai_api_key_here":
        logger.info("âœ… Chave do OpenAI configurada")
        tests_passed += 1
    else:
        logger.warning("âš ï¸ Chave do OpenAI nÃ£o configurada (opcional)")
        tests_passed += 1  # Considerar como passado pois Ã© opcional
    
    logger.info(f"ğŸ“Š APIs configuradas: {tests_passed}/{total_tests}")
    return tests_passed >= 2  # Precisa de pelo menos 2/3 (Escavador Ã© obrigatÃ³rio)

def create_sample_env_file():
    """Cria arquivo .env de exemplo se nÃ£o existir."""
    env_file = ".env"
    config_file = "config_academic_apis.env"
    
    if not os.path.exists(env_file) and os.path.exists(config_file):
        logger.info("ğŸ“ Criando arquivo .env de exemplo...")
        
        import shutil
        shutil.copy(config_file, env_file)
        
        logger.info(f"âœ… Arquivo .env criado a partir de {config_file}")
        logger.info("âš ï¸ IMPORTANTE: Configure suas chaves reais no arquivo .env")
        return True
    
    return False

async def main():
    """FunÃ§Ã£o principal de teste."""
    logger.info("ğŸš€ Iniciando testes de integraÃ§Ã£o acadÃªmica...")
    logger.info("=" * 60)
    
    # EstatÃ­sticas dos testes
    tests_results = []
    
    # Criar .env se necessÃ¡rio
    create_sample_env_file()
    
    # 1. Testar configuraÃ§Ã£o das APIs
    logger.info("\n1ï¸âƒ£ TESTE DE CONFIGURAÃ‡ÃƒO DAS APIS")
    result1 = await test_api_keys_configuration()
    tests_results.append(("ConfiguraÃ§Ã£o APIs", result1))
    
    # 2. Testar AcademicEnricher
    logger.info("\n2ï¸âƒ£ TESTE DO ACADEMIC ENRICHER")
    result2 = await test_academic_enricher()
    tests_results.append(("AcademicEnricher", result2))
    
    # 3. Testar integraÃ§Ã£o Escavador
    logger.info("\n3ï¸âƒ£ TESTE DE INTEGRAÃ‡ÃƒO ESCAVADOR")
    result3 = await test_escavador_curriculum()
    tests_results.append(("IntegraÃ§Ã£o Escavador", result3))
    
    # 4. Testar FeatureCalculator
    logger.info("\n4ï¸âƒ£ TESTE DO FEATURE CALCULATOR")
    result4 = await test_feature_calculator_integration()
    tests_results.append(("FeatureCalculator", result4))
    
    # RelatÃ³rio final
    logger.info("\n" + "=" * 60)
    logger.info("ğŸ“Š RELATÃ“RIO FINAL DOS TESTES")
    logger.info("=" * 60)
    
    passed_tests = 0
    total_tests = len(tests_results)
    
    for test_name, result in tests_results:
        status = "âœ… PASSOU" if result else "âŒ FALHOU"
        logger.info(f"{test_name}: {status}")
        if result:
            passed_tests += 1
    
    logger.info("-" * 60)
    logger.info(f"Testes passados: {passed_tests}/{total_tests}")
    
    if passed_tests == total_tests:
        logger.info("ğŸ‰ TODOS OS TESTES PASSARAM!")
        logger.info("âœ… IntegraÃ§Ã£o acadÃªmica estÃ¡ funcionando corretamente")
    elif passed_tests >= total_tests // 2:
        logger.info("âš ï¸ ALGUNS TESTES FALHARAM")
        logger.info("ğŸ”§ Verifique as configuraÃ§Ãµes e dependÃªncias")
    else:
        logger.info("âŒ MUITOS TESTES FALHARAM")
        logger.info("ğŸš¨ Verifique se as APIs estÃ£o configuradas corretamente")
    
    logger.info("\nğŸ“š PRÃ“XIMOS PASSOS:")
    logger.info("1. Configure as chaves das APIs no arquivo .env")
    logger.info("2. Instale Redis: brew install redis (macOS) ou docker run -p 6379:6379 redis")
    logger.info("3. Execute: redis-server")
    logger.info("4. Execute novamente este teste: python test_academic_integration.py")
    
    return passed_tests == total_tests

if __name__ == "__main__":
    try:
        success = asyncio.run(main())
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        logger.info("\nâ¹ï¸ Teste interrompido pelo usuÃ¡rio")
        sys.exit(1)
    except Exception as e:
        logger.error(f"\nğŸ’¥ Erro inesperado: {e}")
        sys.exit(1) 